{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af4e725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiongyan/anaconda3/envs/gyro_mbrl/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "  \"update your install command.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import gym, ray\n",
    "import ray.rllib.agents.ddpg as ddpg\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import argparse\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.logger import pretty_print\n",
    "from ray.tune.registry import register_env\n",
    "from os import path\n",
    "from scipy.integrate import solve_ivp\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "from functools import partial\n",
    "from ray.rllib.utils.framework import try_import_torch\n",
    "from ray.rllib.env.env_context import EnvContext\n",
    "from ray.tune.registry import register_env\n",
    "from datetime import datetime\n",
    "\n",
    "#from custom_functions.custom_functions import env_fn \n",
    "#from custom_functions.custom_functions import create_env\n",
    "#from custom_functions.custom_functions import load_agent\n",
    "#from custom_functions.custom_functions import test_agent\n",
    "#from custom_functions.custom_functions import plot_test\n",
    "#from custom_functions.custom_functions import evaluate_control\n",
    "#from custom_functions.custom_functions import read_progress\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from GyroEnv0 import GyroscopeEnvV0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c11fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义环境 --- Custom environment #\n",
    "\n",
    "'''\n",
    "Difference with GyroscopeEnvV0:\n",
    "-- Gimbal voelocity no longer clipped into [-max velocity, max velocity] range\n",
    "-- Add several reward functions: exponential, power, sparse, etc...\n",
    "-- Add a termination condition for sparse reward funciton\n",
    "'''\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "from os import path\n",
    "from scipy.integrate import solve_ivp\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "\n",
    "class GyroscopeEnvV1(gym.Env):\n",
    "\n",
    "    \"\"\"\n",
    "    GyroscopeEnv:\n",
    "        GyroscopeEnv is a GYM environment for Quanser 3-DOF gyroscope. The gyroscope consists of a disk mounted \n",
    "        inside an inner gimbal which in turn is mounted inside an outer gimbal.\n",
    "        The two gimbals are controlled by a RL controller, and the disk is controlled by a PID controller.\n",
    "    \n",
    "    State:   # 状态值 --- 7D   都是原始值？？？？？？？\n",
    "        state = [x1, x2, x3, x4, x1_ref, x3_ref, w] (7 dimensions)   # 状态空间\n",
    "        Outer red gimbal:   # 外部红色的万向节\n",
    "            x1, or theta: angular position [rad]   # 角度位置\n",
    "            x2, or dot(theta): angular velocity [rad/s]   # 角速度\n",
    "            x1_ref: angular position reference [rad]   # 目标角度位置\n",
    "            u1: motor voltage [V]   # 电机电压\n",
    "        Inner blue gimbal:   # 内部蓝色万向节\n",
    "            x3, or phi: angular position [rad]   # 角度位置\n",
    "            x4, or dot(phi): angular velocity [rad/s]   # 角速度\n",
    "            x3_ref: angular position reference [rad]   # 目标角度位置\n",
    "            u2: motor voltage [V]   # 电机电压\n",
    "        Golden disk:   # 金黄色转盘\n",
    "            w: angular velocity [rad/s]   # 角速度\n",
    "            u3: motor voltage [V]   # 电机电压\n",
    "        Mechanical constraints:   # 机械约束，参数边界\n",
    "            motor voltage: [-10, 10] [V]   # 电机电压\n",
    "            gimbal velocity: [-100, 100] [rpm]   # 万向节转速\n",
    "            disk velocity: [-300, 300] [rpm]   # 转盘转速\n",
    "    \n",
    "    Observation:   # 观测值 --- 9D   所有数字需要归一化？？？？？？？\n",
    "        observation = [cos(x1), sin(x1), x2, cos(x3), sin(x3), x4, x1_ref, x3_ref, w] (9 dimensions)   # 观测空间\n",
    "        The angles have been replaced with their cosine and sine to prevent the discontinuity at -pi and pi.\n",
    "        The observation space is thus larger than the state space.\n",
    "        \n",
    "    Action:   # 动作空间\n",
    "        action = [a1, a2]   # 动作空间\n",
    "        Note: a1, a2 are normalized voltages   # 归一化电压\n",
    "              u1, u2 = 10*a1, 10*a2 are actual voltages   # 实际电压指\n",
    "              T1, T2 = KtotRed*u1, KtotBlue*u2 are motor torques   # 电机扭矩，KtoRed和KtoBlue是电机属性参数\n",
    "        \n",
    "    Initialization:   # 初始化\n",
    "        Some versions of Gym may not support initialization with arguments, so initialize it manully with: \n",
    "        # create env   # 创建环境\n",
    "        env = GyroscopeEnv()\n",
    "        env.init(simu_args = simu_args, reward_func = reward_func, reward_args = reward_args)\n",
    "        # simu_args, with optional simulation step (dt), episode length (ep_len), and random seed (seed)   # 仿真三个基本参数\n",
    "        simu_args = {'dt': 0.05, 'ep_len': 100, 'seed': 2， ‘friction’: False}   # 未考虑摩擦\n",
    "        # reward_func, optional reward function, default value is 'Quadratic'   # 奖励函数，修改后没有默认值，必须附值\n",
    "        reward_func = 'Quadratic'\n",
    "        # reward_args, optional reward parameters  # 用于计算奖励函数的权重参数\n",
    "        reward_args = {'qx1': 1, 'qx2': 0.01, 'qx3': 1, 'qx4': 0.01, 'pu1': 0, 'pu2': 0}\n",
    "    \"\"\"\n",
    "    \n",
    "    # ---------------------------------------------------------------------------------------------------- #\n",
    "    # ------------------------------------------ Initialization ------------------------------------------ #\n",
    "    # ---------------------------------------------------------------------------------------------------- #        \n",
    "                \n",
    "    def __init__(self, env_config):\n",
    "        \n",
    "        # Initialize mechanical parameters of the gyroscope   # 初始化Gyro机械参数\n",
    "        self.init_gyro()\n",
    "        \n",
    "        # Initialize simulation parameters   # 初始化仿真参数\n",
    "        self.init_simu(**env_config[\"simu_args\"])\n",
    "        \n",
    "        # Initialize reward parameters   # 初始化奖励函数参数，用于选择奖励函数类型\n",
    "        self.init_reward(env_config[\"reward_func\"], env_config[\"reward_args\"])\n",
    "        \n",
    "        # State space, 7D   # 状态空间初始化设置\n",
    "        self.state_bound = np.array([self.maxAngle, self.maxGimbalSpeed, self.maxAngle, self.maxGimbalSpeed, \n",
    "                                   self.maxAngle, self.maxAngle, self.maxDiskSpeed], dtype = np.float32)   # 状态空间初始化空间大小，设置最大值\n",
    "        self.state_space = spaces.Box(low = -self.state_bound, high = self.state_bound, dtype = np.float32)   # 状态空间上下限设置\n",
    "        \n",
    "        # Observation space (normalized), 9D   # 观测空间初始化设置（归一化）\n",
    "        self.observation_bound = np.array([1.0] * 9, dtype = np.float32)   # 观测空间初始化空间大小，设置空间维数 \n",
    "        self.observation_space = spaces.Box(low = -self.observation_bound, high = self.observation_bound, \n",
    "                                            dtype = np.float32)   # 观测空间上下限设置\n",
    "#         print(\"self.observation_bound：\", self.observation_bound)\n",
    "#         print(\"self.observation_space：\", self.observation_space)\n",
    "        \n",
    "        # Action space (normalized), 2D   # 动作空间（归一化）\n",
    "        self.action_bound = np.array([1.0] * 2, dtype = np.float32)   # 动作空间设置，设置空间维数大小\n",
    "        self.action_space = spaces.Box(low = -self.action_bound, high = self.action_bound, dtype = np.float32)   # 动作空间上下限设置\n",
    "    \n",
    "    # Initialize fixed parameters of the gyroscope   # 初始化Gyro的特定机械参数\n",
    "    def init_gyro(self):\n",
    "        \n",
    "        # Inertias in Kg*m2, from SP report page 23, table 2   # 设备固定参数\n",
    "        self.Jrx1 = 0.0179\n",
    "        self.Jbx1 = 0.0019\n",
    "        self.Jbx2 = 0.0008\n",
    "        self.Jbx3 = 0.0012\n",
    "        self.Jdx1 = 0.0028\n",
    "        self.Jdx2 = 0.0056\n",
    "        self.Jdx3 = 0.0056\n",
    "#         print(\"Gyro的特定机械参数：\")\n",
    "#         print(\"self.Jrx1=\" + str(self.Jrx1),\n",
    "#              \"self.Jbx1=\" + str(self.Jbx1),\n",
    "#              \"self.Jbx2\" + str(self.Jbx2),\n",
    "#              \"self.Jbx3\" + str(self.Jbx3),\n",
    "#              \"self.Jdx1\" + str(self.Jdx1),\n",
    "#              \"self.Jdx2\" + str(self.Jdx2),\n",
    "#              \"self.Jdx3\" + str(self.Jdx3))\n",
    "    \n",
    "\n",
    "        # Combined inertias to simplify equations, from SP report page 22, state space equations   # 状态空间空间方程，组合惯量\n",
    "        self.J1 = self.Jbx1 - self.Jbx3 + self.Jdx1 - self.Jdx3\n",
    "        self.J2 = self.Jbx1 + self.Jdx1 + self.Jrx1\n",
    "        self.J3 = self.Jbx2 + self.Jdx1\n",
    "\n",
    "        # Motor constants, from SP report page 23, table 1   # 电机参数\n",
    "        self.Kamp = 0.5 # current gain, A/V   # 电流增益\n",
    "        self.Ktorque = 0.0704 # motor gain, Nm/A   # 电机增益\n",
    "        self.eff = 0.86 # motor efficiency   # 电机效率\n",
    "        self.nRed = 1.5 # red gearbox eatio   # 红色万向节变速箱传动比\n",
    "        self.nBlue = 1 # blue gearbox eatio   # 蓝色万向节变速箱传动比\n",
    "        self.KtotRed = self.Kamp * self.Ktorque * self.eff * self.nRed # Nm/V   # 红色万向节扭矩，特定计算公式\n",
    "        self.KtotBlue = self.Kamp * self.Ktorque * self.eff * self.nBlue # Nm/V   # 蓝色万向节扭矩，特定计算公式\n",
    "        \n",
    "        # Mechanical constraints   机械系统约束\n",
    "        self.maxVoltage = 10 # V   # 最大电压\n",
    "        self.maxAngle = np.pi # rad   # 最大角度\n",
    "        self.maxGimbalSpeed = 100 * 2 * np.pi / 60 # rad/s   # 最大万向节转速\n",
    "        self.maxDiskSpeed = 300 * 2 * np.pi / 60 # rad/s   # 最大转盘转速\n",
    "#         print(\"Max speed of Gimbal:\", self.maxGimbalSpeed )\n",
    "#         print(\"Max speed of Disk:\", self.maxDiskSpeed)\n",
    "        \n",
    "    # Initialize simulation parameters   # 初始化仿真参数\n",
    "    def init_simu(self, dt = 0.05, ep_len = 100, seed = 2, friction = False):\n",
    "        \n",
    "        # Gyroscope state and observation   # Gyro状态空间与观测值空间\n",
    "        self.state = np.array([0] * 7)   # Gyro状态空间\n",
    "        self.observe()   # Gyro观测空间   自动打印出观测空间？？？？？？\n",
    "\n",
    "        # Time step in s   # 时间步长\n",
    "        self.dt = dt\n",
    "        self.eval_per_dt = int(dt / 0.01) # run evaluation every 0.01s   # ??????????????????????????????????\n",
    "        \n",
    "        # Episode length and current episode   # 剧集长度，一个epoch由多个episode组成，所有episode运行结束进行一次判断\n",
    "        self.ep_len = ep_len   # 剧集长度设置\n",
    "        self.ep_cur = 0   # 当前剧集数\n",
    "#         print(\"ep_len：\" + str(ep_len))\n",
    "        \n",
    "        # Seed for random number generation   # 用于指定随机数生成时所用算法开始的整数值，如果使用相同的seed()值，则每次生成的随即数都相同，如果不设置这个值，则系统根据时间来自己选择这个值，此时每次生成的随机数因时间差异而不同。\n",
    "        self.seed(seed)\n",
    "        self.viewer = None\n",
    "#         print(\"seed：\" + str(seed))\n",
    "        \n",
    "        # Friction   摩擦力\n",
    "        self.fvr = 0.002679 if friction else 0   # 存在选项，如果考虑摩擦，则赋值，如果不考虑摩擦则归零\n",
    "        self.fcr = 0\n",
    "        self.fvb = 0.005308 if friction else 0   # 存在选项，如果考虑摩擦，则赋值，如果不考虑摩擦则归零\n",
    "        self.fcb = 0\n",
    "        \n",
    "    # Initialize reward parameters   # 初始化奖励参数，用于定义各类奖励函数的ID，便于调用\n",
    "    def init_reward(self, reward_func, reward_args):\n",
    "                \n",
    "        reward_dict = {\n",
    "            # continuous reward functions, part one   # 连续奖励函数，part one\n",
    "            'Quadratic': self.quad_reward,\n",
    "            'Quadratic with bonus':self.quad_bon_reward,\n",
    "            'Quadratic with exponential': self.quad_exp_reward,\n",
    "            'Quadratic with ending penalty': self.quad_end_pen_reward,\n",
    "            'Quadratic with penalty': self.quad_pen_reward,\n",
    "            'Absolute': self.abs_reward,\n",
    "            'Normalized': self.norm_reward,\n",
    "            'Normalized with bonus': self.norm_bon_reward,\n",
    "            # continuous reward functions, part two   # 连续奖励函数，part two\n",
    "            'Power':self.power_reward,\n",
    "            'Exponential': self.exp_reward,\n",
    "            'PE': self.power_exp_reward,\n",
    "            # sparse reward functions   # 稀疏奖励函数\n",
    "            'Sparse':self.sparse_reward,\n",
    "            'Sparse with exp': self.sparse_reward_with_exp,\n",
    "            'Sparse with exp 2': self.sparse_reward_with_exp_2\n",
    "        }\n",
    "        if reward_func in ['Sparse']: # 'Sparse with exp'\n",
    "            self.sparse = True\n",
    "        else:\n",
    "            self.sparse = False\n",
    "        self.reward_func = reward_dict[reward_func]\n",
    "        self.reward_args = reward_args\n",
    "#         print(\"reward_dict[reward_func]:\" + str(reward_dict[reward_func]))\n",
    "#         print(\"reward_args:\" + str(reward_args))\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------- #\n",
    "    # ----------------------------------------------- Step ----------------------------------------------- #\n",
    "    # ---------------------------------------------------------------------------------------------------- #\n",
    "    \n",
    "    # Simulate the environment fot one step dt   # 计算一个步长(step)的仿真环境，也就是计算了ep_len(100)次\n",
    "    def step(self, a):\n",
    "        \n",
    "        # extract states and actions   # 提取状态值和动作值\n",
    "        x1, x2, x3, x4, x1_ref, x3_ref, w = self.state   # 状态空间取值\n",
    "        a1, a2 = a   # 动作空间取值\n",
    "        u1, u2 = self.maxVoltage * a1, self.maxVoltage * a2   # 输出电压赋值\n",
    "\n",
    "        # Increment episode   # 递增量，每次递增1\n",
    "        self.ep_cur += 1\n",
    "#         print('/'+'-'*42+f'{datetime.now()} 开始训练' + '-'*36 + '\\\\')\n",
    "#         print(f\"Episode {self.ep_cur}\\n >> >> >> >> >> >> >>\")\n",
    "        \n",
    "\n",
    "        # For quad_end_pen_reward, check if terminal state is reached   # 检查是否达到终止状态\n",
    "        if self.reward_func == self.quad_end_pen_reward and self.ep_cur == self.ep_len:   # ？？？？？？\n",
    "            self.reward_args['end_horizon'] = 1   # ？？？？？？？？？？\n",
    "            \n",
    "#         print(self.quad_end_pen_reward)   # ???????\n",
    "\n",
    "        # run simulation for a step   # 跑一个步长的仿真\n",
    "        results = solve_ivp(   # solve_ivp, 该函数对给定初始值的常微分方程组进行数值积分, https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.solve_ivp.html\n",
    "                    fun = self.dxdt,    # 调用函数fun(t, y)\n",
    "                    t_span = (0, self.dt), # solver starts with t = 0 and integrates until it reaches t = self.dt\n",
    "                    y0 = [x1, x2, x3, x4], # initial state\n",
    "                    method = 'RK45',   # ODE solver --- Explicit Runge-Kutta method of order 5(4)\n",
    "                    t_eval = np.linspace(0, self.dt, self.eval_per_dt), # times at which to store the computed solution\n",
    "                    args = (u1, u2) \n",
    "                )\n",
    "        # print(\"results:\", results)   # 计算了ep_len(100)次，\n",
    "        \n",
    "        # evaluated states, each contains eval_per_dt points   # 已评估的状态，每个都包含eval_per_dt点\n",
    "        x1_eval = results.y[0]\n",
    "        x2_eval = results.y[1]\n",
    "        x3_eval = results.y[2]\n",
    "        x4_eval = results.y[3]\n",
    "#         print(\"已评估的状态：\")\n",
    "#         print(\"x2_eval：\" + str(x2_eval))\n",
    "#         print(\"x4_eval：\" + str(x4_eval))\n",
    "\n",
    "        # change in velocity, or acceleration   # 速度变化，评估值与状态值之间的变化\n",
    "        dx2 = x2_eval[-1] - x2\n",
    "        dx4 = x4_eval[-1] - x4\n",
    "#         print(\"万向节转速变化：\")\n",
    "#         print(\"x2_eval[-1]：\" +str(x2_eval[-1]))\n",
    "#         print(\"x2：\" + str(x2))\n",
    "#         print(\"dx2：\" + str(dx2))\n",
    "#         print(\"x4_eval[-1]：\" +str(x4_eval[-1]))\n",
    "#         print(\"x4：\" + str(x4))\n",
    "#         print(\"dx4：\" + str(dx4))        \n",
    "        \n",
    "        \n",
    "        # keep only the last evaluation value   # 只保留最后的评估值\n",
    "        x1 = x1_eval[-1]\n",
    "        x2 = x2_eval[-1]\n",
    "        x3 = x3_eval[-1]\n",
    "        x4 = x4_eval[-1]\n",
    "#         print(\"只保留最后的评估值：\")\n",
    "#         print(\"x2_eval[-1]:\" + str(x2_eval[-1]))\n",
    "#         print(\"x4_eval[-1]:\" + str(x4_eval[-1]))\n",
    "        \n",
    "        # Angle error (normalized between pi and -pi to get smallest distance)   # 角度误差（在pi和-pi之间归一化，以得到最小的距离\n",
    "        x1_diff = self.angle_normalize(x1 - x1_ref)\n",
    "        x3_diff = self.angle_normalize(x3 - x3_ref)\n",
    "#         print(\"角度误差归一化：\")\n",
    "#         print(\"x1_diff:\" + str(x1_diff))\n",
    "#         print(\"x3_diff:\" + str(x3_diff))\n",
    "        \n",
    "        # update state and observation   # 更新状态空间和观测空间，其中的观测空间应该归一化？？？？？？？\n",
    "        self.state = np.array([x1, x2, x3, x4, x1_ref, x3_ref, w])   # 状态空间\n",
    "        self.observe()   # 观测空间，自动打印出观测空间？？？？？？\n",
    "#         print(\"更新状态空间和观测空间：\")\n",
    "#         print(\"self.state：\" + str(self.state))\n",
    "#         print(\"self.observe():\" + str(self.observe()))\n",
    "\n",
    "        # Reward(float), normalized everything in advance\n",
    "        reward = self.reward_func(x1_diff/self.maxAngle, x3_diff/self.maxAngle, \n",
    "                                  x2/self.maxGimbalSpeed, x4/self.maxGimbalSpeed, \n",
    "                                  dx2/self.maxGimbalSpeed, dx4/self.maxGimbalSpeed,\n",
    "                                  a1, a2, **self.reward_args)\n",
    "#         print(\"奖励函数类型：\" + str(env_config[\"reward_func\"]))\n",
    "#         print(\"reward：\" + str(reward))\n",
    "#         print('/'+'-'*42+f'{datetime.now()} 训练结束' + '-'*36 + '\\\\')\n",
    "        \n",
    "        # Done(bool): whether it’s time to reset the environment again.\n",
    "        if self.sparse:\n",
    "            # in sparse reward functions, terminate the episode when the speed is too large\n",
    "            # otherwise the exploration will happen mainly in high speed area, which is not desired\n",
    "            done = self.ep_cur > self.ep_len or x2 > 2*self.maxGimbalSpeed or x4 > 2 * self.maxGimbalSpeed\n",
    "        else:\n",
    "            # in other reward functions, terminating the episode early will encourage the agent to \n",
    "            # speed up the gyroscope and end the episode, because the reward is negative\n",
    "            done = self.ep_cur > self.ep_len\n",
    "        \n",
    "        # Info(dict): diagnostic information useful for debugging. \n",
    "        info = {'state': self.state, 'observation': self.observation}\n",
    "        \n",
    "        return self.scaled_observation(), reward, done, info #return self.observation, reward, done, info\n",
    "    \n",
    "    # Compute the derivative of the state, here u is NOT normalized   # 计算状态值的导数，此处的u未归一化\n",
    "    def dxdt(self, t, x, u1, u2):\n",
    "\n",
    "        J1, J2, J3, Jdx3 = self.J1, self.J2, self.J3, self.Jdx3\n",
    "        w = self.state[-1]\n",
    "\n",
    "        # Convert input voltage to input torque   # 将输入电压转换为输入扭矩\n",
    "        T1, T2 = self.KtotRed * u1, self.KtotBlue * u2   # 此处的计算方式是设备固定特定计算公式\n",
    "        \n",
    "        # Friction   # 摩擦力\n",
    "        T1 = T1 - self.fvr*x[1] - self.fcr*np.sign(x[1])\n",
    "        T2 = T2 - self.fvb*x[3] - self.fcb*np.sign(x[3])\n",
    "        \n",
    "        # Equations of motion   # 运动方程\n",
    "        dx_dt = [0, 0, 0, 0]\n",
    "        dx_dt[0] = x[1]\n",
    "        dx_dt[1] = (T1+J1*np.sin(2*x[2])*x[1]*x[3]-Jdx3*np.cos(x[2])*x[3]*w)/(J2 + J1*np.power(np.sin(x[2]),2))\n",
    "        dx_dt[2] = x[3]\n",
    "        dx_dt[3] = (T2-J1*np.cos(x[2])*np.sin(x[2])*np.power(x[1],2)+Jdx3*np.cos(x[2])*x[1]*w)/J3\n",
    "        \n",
    "        return dx_dt\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------------------------------------------------- #\n",
    "    # ------------------------------------------ Reward Part I ------------------------------------------- #\n",
    "    # ---------------------------------------------------------------------------------------------------- #\n",
    "    \n",
    "    def abs_reward(self, x1_diff, x3_diff, x2, x4, dx2, dx4, u1, u2, qx1 = 1, qx2 = 0.01, qx3 = 1, qx4 = 0.01, pu1 = 0, pu2 = 0):\n",
    "        return -(qx1*abs(x1_diff) + qx3*abs(x3_diff) + qx2*abs(x2) + qx4*abs(x4) + pu1*abs(u1) + pu2*abs(u2))\n",
    "\n",
    "    def norm_reward(self, x1_diff, x3_diff, x2, x4, dx2, dx4, u1, u2, k = 0.2, qx2 = 0, qx4 = 0, pu1 = 0, pu2 = 0):\n",
    "        return -((abs(x1_diff)/k)/(1 + (abs(x1_diff)/k)) + (abs(x3_diff)/k)/(1 + (abs(x3_diff)/k)) + qx2*(x2**2) + qx4*(x4**2) + pu1*(u1**2) + pu2*(u2**2))\n",
    "\n",
    "    def norm_bon_reward(self, x1_diff, x3_diff, x2, x4, dx2, dx4, u1, u2, k = 0.2, qx2 = 0, qx4 = 0, pu1 = 0, pu2 = 0, bound = 0.001, bonus = 1):\n",
    "        return -((abs(x1_diff)/k)/(1 + (abs(x1_diff)/k)) + (abs(x3_diff)/k)/(1 + (abs(x3_diff)/k)) + qx2*(x2**2) + qx4*(x4**2) + pu1*(u1**2) + pu2*(u2**2)) + bonus*(abs(x1_diff) <= bound or abs(x3_diff) <= bound)\n",
    "\n",
    "    def quad_reward(self, x1_diff, x3_diff, x2, x4, dx2, dx4, u1, u2, qx1 = 1, qx2 = 0.01, qx3 = 1, qx4 = 0.01, pu1 = 0, pu2 = 0):\n",
    "        return -(qx1*(x1_diff**2) + qx3*(x3_diff**2) + qx2*(x2**2) + qx4*(x4**2) + pu1*(u1**2) + pu2*(u2**2))\n",
    "\n",
    "    def quad_exp_reward(self, x1_diff, x3_diff, x2, x4, dx2, dx4, u1, u2, qx1 = 1, qx2 = 0.01, qx3 = 1, qx4 = 0.01, pu1 = 0, pu2 = 0, eax1 = 10, ebx1 = 10, eax3 = 10, ebx3 = 10):\n",
    "        return -(qx1*(x1_diff**2) + qx3*(x3_diff**2) + qx2*(x2**2) + qx4*(x4**2) + pu1*(u1**2) + pu2*(u2**2) + eax1*(1-np.exp(-ebx1*(x1_diff**2))) + eax3*(1-np.exp(-ebx3*(x3_diff**2))))\n",
    "\n",
    "    def quad_end_pen_reward(self, x1_diff, x3_diff, x2, x4, dx2, dx4, u1, u2, qx1 = 1, qx2 = 0.01, qx3 = 1, qx4 = 0.01, pu1 = 0, pu2 = 0, sx1 = 10, sx3 = 10, end_horizon = 0):\n",
    "        return -(qx1*(x1_diff**2) + qx3*(x3_diff**2) + qx2*(x2**2) + qx4*(x4**2) + pu1*(u1**2) + pu2*(u2**2) + end_horizon*(sx1*(x1_diff**2)+sx3*(x3_diff**2)))\n",
    "\n",
    "    def quad_pen_reward(self, x1_diff, x3_diff, x2, x4, dx2, dx4, u1, u2, qx1 = 1, qx2 = 0.01, qx3 = 1, qx4 = 0.01, pu1 = 0, pu2 = 0, bound = 0.1, penalty = 50):\n",
    "        return -(qx1*(x1_diff**2) + qx3*(x3_diff**2) + qx2*(x2**2) + qx4*(x4**2) + pu1*(u1**2) + pu2*(u2**2)) - penalty*(abs(x1_diff) >= bound or abs(x3_diff) >= bound)\n",
    "\n",
    "    def quad_bon_reward(self, x1_diff, x3_diff, x2, x4, dx2, dx4, u1, u2, qx1 = 1, qx2 = 0.01, qx3 = 1, qx4 = 0.01, pu1 = 0, pu2 = 0, bound = 0.1, bonus = 5):\n",
    "        return -(qx1*(x1_diff**2) + qx3*(x3_diff**2) + qx2*(x2**2) + qx4*(x4**2) + pu1*(u1**2) + pu2*(u2**2)) + bonus*(abs(x1_diff) <= bound or abs(x3_diff) <= bound)\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------- #\n",
    "    # ------------------------------------------ Reward Part II ------------------------------------------ #\n",
    "    # ---------------------------------------------------------------------------------------------------- #\n",
    "    \n",
    "    def power_reward(self, x1_diff, x3_diff, x2, x4, dx2, dx4, u1, u2, qx1 = 1, qx2 = 1, qx3 = 1, qx4 = 1, pu1 = 0, pu2 = 0, p = 0.5):\n",
    "        return -(qx1*abs(x1_diff)**p + qx3*abs(x3_diff)**p + qx2*abs(x2)**p + qx4*abs(x4)**p + pu1*abs(u1)**p + pu2*abs(u2)**p)\n",
    "        \n",
    "    def exp_reward(self, x1_diff, x3_diff, x2, x4, dx2, dx4, u1, u2, qx1 = 1, qx2 = 1, qx3 = 1, qx4 = 1, pu1 = 0, pu2 = 0, e = 10):\n",
    "        return -(qx1*(1-np.exp(-e*abs(x1_diff))) + qx3*(1-np.exp(-e*abs(x3_diff))) + qx2*(1-np.exp(-e*abs(x2))) + qx4*(1-np.exp(-e*abs(x4))) + pu1*(1-np.exp(-e*abs(u1))) + pu2*(1-np.exp(-e*abs(u2))))\n",
    "    \n",
    "    def power_exp_reward(self, x1_diff, x3_diff, x2, x4, dx2, dx4, u1, u2, qx1 = 1, qx2 = 1, qx3 = 1, qx4 = 1, pu1 = 0, pu2 = 0, p = 0.1, e = 10):\n",
    "        return -(qx1*abs(x1_diff)**p + qx3*abs(x3_diff)**p + qx2*abs(x2)**p + qx4*abs(x4)**p + pu1*abs(u1)**p + pu2*abs(u2)**p) -(qx1*(1-np.exp(-e*abs(x1_diff))) + qx3*(1-np.exp(-e*abs(x3_diff))) + qx2*(1-np.exp(-e*abs(x2))) + qx4*(1-np.exp(-e*abs(x4))) + pu1*(1-np.exp(-e*abs(u1))) + pu2*(1-np.exp(-e*abs(u2))))\n",
    "    \n",
    "    # ---------------------------------------------------------------------------------------------------- #\n",
    "    # ------------------------------------------ Reward Part III ----------------------------------------- #\n",
    "    # ---------------------------------------------------------------------------------------------------- #\n",
    "        \n",
    "    def sparse_reward(self, x1_diff, x3_diff, x2, x4, dx2, dx4, u1, u2, bx = 0.01, rx = 1, bv = 0.01, rv = 0, bu = 0.01, ru = 0):\n",
    "        r = 0\n",
    "        if abs(x1_diff) <= bx and abs(x3_diff) <= bx:\n",
    "            if abs(x2) <= bv and abs(x4) <= bv:\n",
    "                r += rv\n",
    "            if abs(dx2) <= bu and abs(dx4) <= bu:\n",
    "                r += ru\n",
    "            r += rx\n",
    "        return r\n",
    "\n",
    "    def sparse_reward_with_exp(self, x1_diff, x3_diff, x2, x4, dx2, dx4, u1, u2, qx1 = 1, qx2 = 1, qx3 = 1, qx4 = 1, pu1 = 0, pu2 = 0, e = 10, bound = 0.01, reward = 1):\n",
    "        return -(qx1*(1-np.exp(-e*abs(x1_diff))) + qx3*(1-np.exp(-e*abs(x3_diff))) + qx2*(1-np.exp(-e*abs(x2))) + qx4*(1-np.exp(-e*abs(x4))) + pu1*(1-np.exp(-e*abs(u1))) + pu2*(1-np.exp(-e*abs(u2)))) + reward*(abs(x1_diff) <= bound and abs(x3_diff) <= bound)\n",
    "    \n",
    "    def sparse_reward_with_exp_2(self, x1_diff, x3_diff, x2, x4, dx2, dx4, u1, u2, qx1 = 1, qx2 = 1, qx3 = 1, qx4 = 1, pu1 = 0, pu2 = 0, e = 10, bound = 0.01, reward = 1):\n",
    "        return -(qx1*(1-np.exp(-e*abs(x1_diff))) + qx3*(1-np.exp(-e*abs(x3_diff))) + qx2*(1-np.exp(-e*abs(x2))) + qx4*(1-np.exp(-e*abs(x4))) + pu1*(1-np.exp(-e*abs(u1))) + pu2*(1-np.exp(-e*abs(u2)))) + reward*(abs(x1_diff) <= bound) + reward*(abs(x3_diff) <= bound)\n",
    "    \n",
    "    # ---------------------------------------------------------------------------------------------------- #\n",
    "    # ---------------------------------------------- Helper ---------------------------------------------- #\n",
    "    # ---------------------------------------------------------------------------------------------------- #\n",
    "    \n",
    "    # reset system to a given or random initial state\n",
    "    def reset(self, x_0 = None):\n",
    "        \n",
    "        # reset state\n",
    "        if x_0 is None:\n",
    "            self.state = self.state_space.sample()\n",
    "        else:\n",
    "            self.state = x_0\n",
    "        # update observation\n",
    "        self.observe()\n",
    "        #print(self.observe())\n",
    "        # reset counter\n",
    "        self.ep_cur = 0\n",
    "        \n",
    "        return self.observation\n",
    "        \n",
    "    # return normalized observation  返回归一化观测值，从状态空间求解得到观测值空间\n",
    "    def observe(self):\n",
    "        s = self.state\n",
    "        self.observation = np.array([np.cos(s[0]), np.sin(s[0]), s[1]/self.maxGimbalSpeed, \n",
    "                                     np.cos(s[2]), np.sin(s[2]), s[3]/self.maxGimbalSpeed, \n",
    "                                     s[4]/self.maxAngle, s[5]/self.maxAngle, s[6]/self.maxDiskSpeed])\n",
    "#         print(\"s[1]:\" + str(s[1]))\n",
    "#         print(\"self.maxGimbalSpeed:\" + str(self.maxGimbalSpeed))\n",
    "#         print(\"s[3]:\" + str(s[3]))\n",
    "#         print(\"self.maxGimbalSpeed:\" + str(self.maxGimbalSpeed))\n",
    "#         print(\"self.observation:\", self.observation)\n",
    "#         print(\"self.observation_space:\", self.observation_space)\n",
    "        return self.observation\n",
    "    \n",
    "    def scaled_observation(self):\n",
    "        return self.observation * 0.01  # Keep the angles between -lim and lim   # 将角度设定在上下限之间，归一化，是否可以采用其他归一化方法呢？？？？？？\n",
    "    \n",
    "    def angle_normalize(self, x, lim = np.pi):\n",
    "        return ((x + lim) % (2 * lim)) - lim   # % --- 取模 - 返回除法的余数\n",
    "    \n",
    "    def seed(self, seed=None):   # # 用于指定随机数生成时所用算法开始的整数值，如果使用相同的seed()值，则每次生成的随即数都相同，如果不设置这个值，则系统根据时间来自己选择这个值，此时每次生成的随机数因时间差异而不同。\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        return None\n",
    "\n",
    "    def close(self):\n",
    "        if self.viewer:\n",
    "            \n",
    "            self.viewer.close()\n",
    "            self.viewer = None\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575e4bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6c180bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-05 17:50:53,984\tINFO services.py:1274 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "# 给自定义环境定义id\n",
    "env_name = \"GyroscopeEnv-v1\"        # gym.make(\"GyroscopeEnvV0\")\n",
    "\n",
    "# 设置初始化参数 --- config\n",
    "config = {\n",
    "    \"env_config\":{\n",
    "    \"simu_args\": {\n",
    "        'dt': 0.05,\n",
    "        'ep_len': 100,\n",
    "        'seed': 2\n",
    "    },\n",
    "    \"reward_func\": 'Quadratic',\n",
    "    \"reward_args\": {\n",
    "        'qx1': 1,\n",
    "        'qx2': 0,\n",
    "        'qx3': 1,\n",
    "        'qx4': 0,\n",
    "        'pu1': 0,\n",
    "        'pu2': 0}\n",
    "    },\n",
    "    #\"env\": \"GyroscopeEnv-v1\",\n",
    "    \"num_workers\": 0,  # parallelism\n",
    "    \"lr\": 0.01,\n",
    "    # Use GPUs iff `RLLIB_NUM_GPUS` env var set to > 0.\n",
    "    \"num_gpus\": int(os.environ.get(\"RLLIB_NUM_GPUS\", \"0\")),\n",
    "    \"actor_hiddens\": [128, 32],\n",
    "    \"actor_hidden_activation\": \"relu\",\n",
    "    \"critic_hiddens\": [128, 32],\n",
    "    \"critic_hidden_activation\": \"relu\",\n",
    "    \"buffer_size\": 1000000,\n",
    "    \"timesteps_per_iteration\": 1500,\n",
    "    \"evaluation_num_episodes\": 100,\n",
    "    \"train_batch_size\": 100,\n",
    "    \"target_noise\": 0.1,\n",
    "    \"gamma\": 0.99,\n",
    "    \"critic_lr\": 0.0025,\n",
    "    \"actor_lr\": 0.0025,\n",
    "    #\"framework\": \"torch\",   # 用于选择tensorflow/pytorch\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# 自动判断停止训练的条件\n",
    "stop = {\n",
    "    \"training_iteration\": 50,\n",
    "    \"timesteps_total\": 10000,\n",
    "    \"episode_reward_mean\": 0.1,\n",
    "}\n",
    "\n",
    "\n",
    "# 定义新建环境函数 --- env-creator\n",
    "def env_creator(env_config):\n",
    "    return GyroscopeEnvV1(env_config)  # return an env instance\n",
    "\n",
    "\n",
    "\n",
    "# Initialisation   初始化\n",
    "ray.init()\n",
    "\n",
    "\n",
    "# 注册环境 --- register_env\n",
    "#register_env(\"my_env\", env_creator(env_config))   # env_config\n",
    "\n",
    "#register_env(\"my_env\", env_creator(config))   # env_config\n",
    "\n",
    "#register_env(env_name, lambda config: GyroscopeEnvV1(config))   #lambda config: gym.make('GyroscopeEnv-v1')\n",
    "\n",
    "#register_env(\"GyroscopeEnv-v1\", lambda config: GyroscopeEnvV1(config)) \n",
    "\n",
    "\n",
    "\n",
    "register_env(\"GyroscopeEnv-v1\", lambda config: env_creator(config))   # 第一版生效\n",
    "\n",
    "#register_env(\"GyroscopeEnv-v1\", lambda config: env_creator(env_config)) \n",
    "\n",
    "#register_env(\"GyroscopeEnv-v1\", lambda : gym.make('GyroscopeEnvV1'))\n",
    "\n",
    "#register_env(\"GyroscopeEnv-v1\", lambda config: gym.make('GyroscopeEnvV1'))\n",
    "\n",
    "#register_env(env_name, lambda config: gym.make('GyroscopeEnvV1'))\n",
    "\n",
    "#返回指向本行代码，错误提示：AttributeError: 'NoneType' object has no attribute 'shape'\n",
    "#一直还没搞清楚怎么回事？？？？？？？？？？？？？？？？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b91a621c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-05 17:50:55,878\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "2021-07-05 17:50:55,879\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2021-07-05 17:50:55,880\tWARNING ddpg.py:182 -- `simple_optimizer` must be True (or unset) for DDPG!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xiongyan/anaconda3/envs/gyro_mbrl/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-05 17:50:56,121\tWARNING deprecation.py:34 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "# 定义Trainer\n",
    "trainer = ddpg.DDPGTrainer(\n",
    "    config=config,\n",
    "    env = env_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b93770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faeaf24c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1: Min/Mean/Max reward: -104.1594/-74.1634/-44.2976, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000001/checkpoint-1\n",
      "  2: Min/Mean/Max reward: -121.1620/-71.8575/-36.2930, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000002/checkpoint-2\n",
      "  3: Min/Mean/Max reward: -121.1620/-69.1280/-36.2930, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000003/checkpoint-3\n",
      "  4: Min/Mean/Max reward: -121.1620/-69.0178/-36.2930, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000004/checkpoint-4\n",
      "  5: Min/Mean/Max reward: -121.1620/-69.0002/-36.2930, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000005/checkpoint-5\n",
      "  6: Min/Mean/Max reward: -121.1620/-68.4065/-36.2930, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000006/checkpoint-6\n",
      "  7: Min/Mean/Max reward: -121.1620/-68.1430/-33.2750, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000007/checkpoint-7\n",
      "  8: Min/Mean/Max reward: -121.1620/-67.0635/-33.2750, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000008/checkpoint-8\n",
      "  9: Min/Mean/Max reward: -106.4238/-67.6965/-33.2750, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000009/checkpoint-9\n",
      " 10: Min/Mean/Max reward: -106.4238/-68.2944/-33.2750, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000010/checkpoint-10\n",
      " 11: Min/Mean/Max reward: -106.4238/-67.5125/-33.2750, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000011/checkpoint-11\n",
      " 12: Min/Mean/Max reward: -118.7614/-67.7548/-33.2750, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000012/checkpoint-12\n",
      " 13: Min/Mean/Max reward: -118.7614/-68.4257/-33.2750, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000013/checkpoint-13\n",
      " 14: Min/Mean/Max reward: -118.7614/-69.3978/-34.5492, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000014/checkpoint-14\n",
      " 15: Min/Mean/Max reward: -118.7614/-68.1177/-34.5492, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000015/checkpoint-15\n",
      " 16: Min/Mean/Max reward: -118.7614/-67.7282/-35.6686, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000016/checkpoint-16\n",
      " 17: Min/Mean/Max reward: -118.7614/-67.7877/-35.6686, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000017/checkpoint-17\n",
      " 18: Min/Mean/Max reward: -116.1952/-67.9320/-35.6686, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000018/checkpoint-18\n",
      " 19: Min/Mean/Max reward: -116.1952/-68.5221/-37.9147, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000019/checkpoint-19\n",
      " 20: Min/Mean/Max reward: -116.1952/-67.7861/-37.9147, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000020/checkpoint-20\n",
      " 21: Min/Mean/Max reward: -116.1952/-68.3067/-37.9147, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000021/checkpoint-21\n",
      " 22: Min/Mean/Max reward: -116.1952/-68.6177/-37.9147, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000022/checkpoint-22\n",
      " 23: Min/Mean/Max reward: -116.1952/-69.2213/-37.9147, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000023/checkpoint-23\n",
      " 24: Min/Mean/Max reward: -116.1952/-68.7692/-37.9147, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000024/checkpoint-24\n",
      " 25: Min/Mean/Max reward: -110.5607/-69.0841/-38.4832, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000025/checkpoint-25\n",
      " 26: Min/Mean/Max reward: -110.5607/-68.4715/-37.6925, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000026/checkpoint-26\n",
      " 27: Min/Mean/Max reward: -110.5607/-68.4046/-36.6730, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000027/checkpoint-27\n",
      " 28: Min/Mean/Max reward: -110.5607/-67.6703/-36.6730, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000028/checkpoint-28\n",
      " 29: Min/Mean/Max reward: -110.5607/-68.0430/-36.6730, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000029/checkpoint-29\n",
      " 30: Min/Mean/Max reward: -107.9952/-67.1523/-36.6730, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000030/checkpoint-30\n",
      " 31: Min/Mean/Max reward: -107.9952/-68.0199/-33.3967, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000031/checkpoint-31\n",
      " 32: Min/Mean/Max reward: -107.9952/-68.1138/-33.3967, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000032/checkpoint-32\n",
      " 33: Min/Mean/Max reward: -106.2744/-67.3598/-33.3967, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000033/checkpoint-33\n",
      " 34: Min/Mean/Max reward: -106.2744/-67.6579/-33.3967, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000034/checkpoint-34\n",
      " 35: Min/Mean/Max reward: -106.2744/-67.7263/-33.3967, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000035/checkpoint-35\n",
      " 36: Min/Mean/Max reward: -106.2744/-67.3345/-33.3967, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000036/checkpoint-36\n",
      " 37: Min/Mean/Max reward: -106.2744/-66.8932/-33.3967, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000037/checkpoint-37\n",
      " 38: Min/Mean/Max reward: -97.1356/-65.9354/-35.1837, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000038/checkpoint-38\n",
      " 39: Min/Mean/Max reward: -88.9214/-66.2249/-37.7476, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000039/checkpoint-39\n",
      " 40: Min/Mean/Max reward: -88.9214/-67.3182/-37.7476, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000040/checkpoint-40\n",
      " 41: Min/Mean/Max reward: -88.9214/-67.1716/-37.7476, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000041/checkpoint-41\n",
      " 42: Min/Mean/Max reward: -88.9214/-66.5327/-34.1140, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000042/checkpoint-42\n",
      " 43: Min/Mean/Max reward: -88.9214/-66.6556/-34.1140, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000043/checkpoint-43\n",
      " 44: Min/Mean/Max reward: -109.8198/-66.2744/-34.1140, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000044/checkpoint-44\n",
      " 45: Min/Mean/Max reward: -126.8499/-66.5054/-30.1589, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000045/checkpoint-45\n",
      " 46: Min/Mean/Max reward: -126.8499/-66.8766/-30.1589, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000046/checkpoint-46\n",
      " 47: Min/Mean/Max reward: -126.8499/-66.3091/-30.1589, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000047/checkpoint-47\n",
      " 48: Min/Mean/Max reward: -126.8499/-66.1815/-30.1589, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000048/checkpoint-48\n",
      " 49: Min/Mean/Max reward: -126.8499/-67.2531/-30.1589, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000049/checkpoint-49\n",
      " 50: Min/Mean/Max reward: -126.8499/-67.2866/-30.1589, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000050/checkpoint-50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 51: Min/Mean/Max reward: -126.8499/-67.5504/-30.1589, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000051/checkpoint-51\n",
      " 52: Min/Mean/Max reward: -113.1912/-67.6759/-33.1137, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000052/checkpoint-52\n",
      " 53: Min/Mean/Max reward: -113.1912/-67.5599/-33.1137, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000053/checkpoint-53\n",
      " 54: Min/Mean/Max reward: -113.1912/-67.9155/-36.5464, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000054/checkpoint-54\n",
      " 55: Min/Mean/Max reward: -113.1912/-67.8183/-36.5464, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000055/checkpoint-55\n",
      " 56: Min/Mean/Max reward: -116.1495/-68.4793/-36.5464, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000056/checkpoint-56\n",
      " 57: Min/Mean/Max reward: -116.1495/-68.4846/-36.5464, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000057/checkpoint-57\n",
      " 58: Min/Mean/Max reward: -117.1489/-68.4207/-37.8464, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000058/checkpoint-58\n",
      " 59: Min/Mean/Max reward: -117.1489/-69.0281/-40.3743, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000059/checkpoint-59\n",
      " 60: Min/Mean/Max reward: -117.1489/-68.8231/-38.1128, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000060/checkpoint-60\n",
      " 61: Min/Mean/Max reward: -117.1489/-68.1099/-35.0697, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000061/checkpoint-61\n",
      " 62: Min/Mean/Max reward: -117.1489/-67.4018/-35.0697, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000062/checkpoint-62\n",
      " 63: Min/Mean/Max reward: -117.1489/-66.4369/-35.0697, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000063/checkpoint-63\n",
      " 64: Min/Mean/Max reward: -116.8126/-67.5248/-35.0697, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000064/checkpoint-64\n",
      " 65: Min/Mean/Max reward: -115.7514/-66.4117/-35.0697, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000065/checkpoint-65\n",
      " 66: Min/Mean/Max reward: -115.7514/-66.1730/-35.0697, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000066/checkpoint-66\n",
      " 67: Min/Mean/Max reward: -115.7514/-66.1826/-35.0697, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000067/checkpoint-67\n",
      " 68: Min/Mean/Max reward: -115.7514/-66.2008/-35.5742, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000068/checkpoint-68\n",
      " 69: Min/Mean/Max reward: -115.7514/-68.3141/-35.5742, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000069/checkpoint-69\n",
      " 70: Min/Mean/Max reward: -115.7514/-68.6744/-36.8012, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000070/checkpoint-70\n",
      " 71: Min/Mean/Max reward: -115.4940/-68.0218/-36.8012, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000071/checkpoint-71\n",
      " 72: Min/Mean/Max reward: -115.4940/-68.7901/-39.4617, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000072/checkpoint-72\n",
      " 73: Min/Mean/Max reward: -115.4940/-68.7259/-39.4617, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000073/checkpoint-73\n",
      " 74: Min/Mean/Max reward: -115.4940/-68.4520/-36.6069, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000074/checkpoint-74\n",
      " 75: Min/Mean/Max reward: -115.4940/-67.9488/-36.0525, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000075/checkpoint-75\n",
      " 76: Min/Mean/Max reward: -115.4940/-66.6823/-36.0525, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000076/checkpoint-76\n",
      " 77: Min/Mean/Max reward: -100.1643/-66.0042/-36.0525, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000077/checkpoint-77\n",
      " 78: Min/Mean/Max reward: -92.5887/-66.1495/-36.0525, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000078/checkpoint-78\n",
      " 79: Min/Mean/Max reward: -92.5887/-65.9981/-36.0525, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000079/checkpoint-79\n",
      " 80: Min/Mean/Max reward: -86.5550/-65.8201/-36.0525, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000080/checkpoint-80\n",
      " 81: Min/Mean/Max reward: -86.5550/-65.6845/-36.0525, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000081/checkpoint-81\n",
      " 82: Min/Mean/Max reward: -95.7309/-66.0204/-38.2381, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000082/checkpoint-82\n",
      " 83: Min/Mean/Max reward: -95.7309/-66.3836/-38.2381, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000083/checkpoint-83\n",
      " 84: Min/Mean/Max reward: -95.7309/-66.7573/-38.2381, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000084/checkpoint-84\n",
      " 85: Min/Mean/Max reward: -95.7309/-66.1139/-38.2381, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000085/checkpoint-85\n",
      " 86: Min/Mean/Max reward: -102.7512/-66.3333/-38.2381, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000086/checkpoint-86\n",
      " 87: Min/Mean/Max reward: -102.7512/-66.3878/-38.2381, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000087/checkpoint-87\n",
      " 88: Min/Mean/Max reward: -102.7512/-67.0515/-39.9404, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000088/checkpoint-88\n",
      " 89: Min/Mean/Max reward: -102.7512/-67.1349/-39.9404, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000089/checkpoint-89\n",
      " 90: Min/Mean/Max reward: -102.7512/-66.4534/-39.8719, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000090/checkpoint-90\n",
      " 91: Min/Mean/Max reward: -102.7512/-67.3917/-39.8719, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000091/checkpoint-91\n",
      " 92: Min/Mean/Max reward: -99.8689/-67.1485/-39.8719, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000092/checkpoint-92\n",
      " 93: Min/Mean/Max reward: -99.8689/-67.1231/-39.8719, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000093/checkpoint-93\n",
      " 94: Min/Mean/Max reward: -99.1966/-67.0934/-39.8719, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000094/checkpoint-94\n",
      " 95: Min/Mean/Max reward: -99.1966/-67.7572/-39.8719, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000095/checkpoint-95\n",
      " 96: Min/Mean/Max reward: -99.1966/-67.4715/-37.2630, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000096/checkpoint-96\n",
      " 97: Min/Mean/Max reward: -105.4301/-67.2156/-37.2630, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000097/checkpoint-97\n",
      " 98: Min/Mean/Max reward: -105.4301/-67.2111/-37.2630, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000098/checkpoint-98\n",
      " 99: Min/Mean/Max reward: -105.4301/-67.4557/-37.2630, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000099/checkpoint-99\n",
      "100: Min/Mean/Max reward: -105.4301/-66.8299/-36.2685, len mean: 101.0000. Checkpoint saved to results/gyro_train/ddpg002-tf-quadratic/checkpoint_000100/checkpoint-100\n",
      "总耗时： 2006.6230528354645 s\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "#result = trainer.train()\n",
    "\n",
    "N_ITER = 100\n",
    "results = []\n",
    "episode_data = []\n",
    "episode_json = []\n",
    "rewards_space = []\n",
    "checkpoint_root = \"results/gyro_train/ddpg002-tf-quadratic\"\n",
    "shutil.rmtree(checkpoint_root, ignore_errors=True, onerror=None)   # clean up old runs\n",
    "\n",
    "start = time.time()\n",
    "for n in range(N_ITER):\n",
    "    result = agent.train()\n",
    "    results.append(result)\n",
    "    \n",
    "    episode = {\n",
    "        \"n\": n, \n",
    "        \"episode_reward_min\": result[\"episode_reward_min\"], \n",
    "        \"episode_reward_mean\": result[\"episode_reward_mean\"], \n",
    "        \"episode_reward_max\": result[\"episode_reward_max\"], \n",
    "        \"episode_len_mean\": result[\"episode_len_mean\"],\n",
    "    }\n",
    "    \n",
    "    rewards_space.append(result[\"episode_reward_mean\"])\n",
    "    episode_data.append(episode)\n",
    "    episode_json.append(json.dumps(episode))\n",
    "    file_name = agent.save(checkpoint_root)\n",
    "    \n",
    "    print(f'{n+1:3d}: Min/Mean/Max reward: {result[\"episode_reward_min\"]:8.4f}/{result[\"episode_reward_mean\"]:8.4f}/{result[\"episode_reward_max\"]:8.4f}, len mean: {result[\"episode_len_mean\"]:8.4f}. Checkpoint saved to {file_name}')\n",
    "    \n",
    "end = time.time()\n",
    "time = end - start\n",
    "print(\"总耗时：\", time,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ce30475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'episode_reward_max': -44.29764357780588,\n",
       "  'episode_reward_min': -104.15944801994365,\n",
       "  'episode_reward_mean': -74.16342953198993,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 14,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-44.29764357780588,\n",
       "    -58.457792527484294,\n",
       "    -64.90832248467753,\n",
       "    -104.15944801994365,\n",
       "    -59.161750649202176,\n",
       "    -100.51041809315956,\n",
       "    -76.96754332001106,\n",
       "    -87.01396424635172,\n",
       "    -83.32981292295246,\n",
       "    -62.34427033478381,\n",
       "    -73.87525935698109,\n",
       "    -76.58711531018298,\n",
       "    -74.63565538675907,\n",
       "    -72.03901721756382],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.19480465730772586,\n",
       "   'mean_inference_ms': 0.6549083575020624,\n",
       "   'mean_action_processing_ms': 0.05530421532129622,\n",
       "   'mean_env_wait_ms': 0.8344485075135457,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 1500,\n",
       "  'agent_timesteps_total': 1500,\n",
       "  'timers': {'learn_time_ms': 316.306, 'learn_throughput': 316.149},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -0.029051071,\n",
       "     'max_q': 0.07472574,\n",
       "     'min_q': -0.20787054,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 1500,\n",
       "   'num_agent_steps_sampled': 1500,\n",
       "   'num_steps_trained': 100,\n",
       "   'num_agent_steps_trained': 100,\n",
       "   'last_target_update_ts': 1500,\n",
       "   'num_target_updates': 1},\n",
       "  'done': False,\n",
       "  'episodes_total': 14,\n",
       "  'training_iteration': 1,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-51-00',\n",
       "  'timestamp': 1625500260,\n",
       "  'time_this_iter_s': 3.367084503173828,\n",
       "  'time_total_s': 3.367084503173828,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 3.367084503173828,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 1,\n",
       "  'perf': {'cpu_util_percent': 14.079999999999998,\n",
       "   'ram_util_percent': 49.2,\n",
       "   'gpu_util_percent0': 0.196,\n",
       "   'vram_util_percent0': 0.5395039631807721}},\n",
       " {'episode_reward_max': -36.293007601338914,\n",
       "  'episode_reward_min': -121.16195954708573,\n",
       "  'episode_reward_mean': -71.8574517549739,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-44.29764357780588,\n",
       "    -58.457792527484294,\n",
       "    -64.90832248467753,\n",
       "    -104.15944801994365,\n",
       "    -59.161750649202176,\n",
       "    -100.51041809315956,\n",
       "    -76.96754332001106,\n",
       "    -87.01396424635172,\n",
       "    -83.32981292295246,\n",
       "    -62.34427033478381,\n",
       "    -73.87525935698109,\n",
       "    -76.58711531018298,\n",
       "    -74.63565538675907,\n",
       "    -72.03901721756382,\n",
       "    -56.87568713492629,\n",
       "    -65.43011531405466,\n",
       "    -44.57187720657699,\n",
       "    -99.26483493278697,\n",
       "    -42.024465280581154,\n",
       "    -88.993475107619,\n",
       "    -78.66486073801096,\n",
       "    -121.16195954708573,\n",
       "    -65.80555425566234,\n",
       "    -61.67969776945103,\n",
       "    -69.30172306403155,\n",
       "    -73.20777233509364,\n",
       "    -73.41541500975862,\n",
       "    -68.88764214940652,\n",
       "    -36.293007601338914],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.20215750461275908,\n",
       "   'mean_inference_ms': 0.6277198572932975,\n",
       "   'mean_action_processing_ms': 0.061043502290082804,\n",
       "   'mean_env_wait_ms': 0.9246790979047955,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 3000,\n",
       "  'agent_timesteps_total': 3000,\n",
       "  'timers': {'learn_time_ms': 1.365, 'learn_throughput': 73282.153},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -2.1299486,\n",
       "     'max_q': -1.5897915,\n",
       "     'min_q': -2.5299573,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 3000,\n",
       "   'num_agent_steps_sampled': 3000,\n",
       "   'num_steps_trained': 150100,\n",
       "   'num_agent_steps_trained': 150100,\n",
       "   'last_target_update_ts': 3000,\n",
       "   'num_target_updates': 1501},\n",
       "  'done': False,\n",
       "  'episodes_total': 29,\n",
       "  'training_iteration': 2,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-51-19',\n",
       "  'timestamp': 1625500279,\n",
       "  'time_this_iter_s': 19.238199472427368,\n",
       "  'time_total_s': 22.605283975601196,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 22.605283975601196,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 2,\n",
       "  'perf': {'cpu_util_percent': 12.688461538461537,\n",
       "   'ram_util_percent': 49.29999999999999,\n",
       "   'gpu_util_percent0': 0.21076923076923076,\n",
       "   'vram_util_percent0': 0.5259917786125917}},\n",
       " {'episode_reward_max': -36.293007601338914,\n",
       "  'episode_reward_min': -121.16195954708573,\n",
       "  'episode_reward_mean': -69.1280269839091,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-44.29764357780588,\n",
       "    -58.457792527484294,\n",
       "    -64.90832248467753,\n",
       "    -104.15944801994365,\n",
       "    -59.161750649202176,\n",
       "    -100.51041809315956,\n",
       "    -76.96754332001106,\n",
       "    -87.01396424635172,\n",
       "    -83.32981292295246,\n",
       "    -62.34427033478381,\n",
       "    -73.87525935698109,\n",
       "    -76.58711531018298,\n",
       "    -74.63565538675907,\n",
       "    -72.03901721756382,\n",
       "    -56.87568713492629,\n",
       "    -65.43011531405466,\n",
       "    -44.57187720657699,\n",
       "    -99.26483493278697,\n",
       "    -42.024465280581154,\n",
       "    -88.993475107619,\n",
       "    -78.66486073801096,\n",
       "    -121.16195954708573,\n",
       "    -65.80555425566234,\n",
       "    -61.67969776945103,\n",
       "    -69.30172306403155,\n",
       "    -73.20777233509364,\n",
       "    -73.41541500975862,\n",
       "    -68.88764214940652,\n",
       "    -36.293007601338914,\n",
       "    -74.12512697387898,\n",
       "    -64.80678797067145,\n",
       "    -38.455960475520435,\n",
       "    -69.78339081376518,\n",
       "    -60.87573338903899,\n",
       "    -67.71913075321653,\n",
       "    -56.04098475494362,\n",
       "    -62.060804520303655,\n",
       "    -66.00196953364029,\n",
       "    -51.372405086575164,\n",
       "    -69.47494807010705,\n",
       "    -65.86503809733478,\n",
       "    -58.61815111189107,\n",
       "    -67.74900346915402,\n",
       "    -84.81765137771558],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2062401649227027,\n",
       "   'mean_inference_ms': 0.6150993113946672,\n",
       "   'mean_action_processing_ms': 0.06404279966207253,\n",
       "   'mean_env_wait_ms': 1.0035493126657584,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 4500,\n",
       "  'agent_timesteps_total': 4500,\n",
       "  'timers': {'learn_time_ms': 1.397, 'learn_throughput': 71583.705},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -3.542685,\n",
       "     'max_q': -3.0334277,\n",
       "     'min_q': -3.9177246,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 4500,\n",
       "   'num_agent_steps_sampled': 4500,\n",
       "   'num_steps_trained': 300100,\n",
       "   'num_agent_steps_trained': 300100,\n",
       "   'last_target_update_ts': 4500,\n",
       "   'num_target_updates': 3001},\n",
       "  'done': False,\n",
       "  'episodes_total': 44,\n",
       "  'training_iteration': 3,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-51-39',\n",
       "  'timestamp': 1625500299,\n",
       "  'time_this_iter_s': 19.571082592010498,\n",
       "  'time_total_s': 42.176366567611694,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 42.176366567611694,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 3,\n",
       "  'perf': {'cpu_util_percent': 12.744444444444444,\n",
       "   'ram_util_percent': 49.30370370370369,\n",
       "   'gpu_util_percent0': 0.15407407407407409,\n",
       "   'vram_util_percent0': 0.5327708173527658}},\n",
       " {'episode_reward_max': -36.293007601338914,\n",
       "  'episode_reward_min': -121.16195954708573,\n",
       "  'episode_reward_mean': -69.01784228820527,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-44.29764357780588,\n",
       "    -58.457792527484294,\n",
       "    -64.90832248467753,\n",
       "    -104.15944801994365,\n",
       "    -59.161750649202176,\n",
       "    -100.51041809315956,\n",
       "    -76.96754332001106,\n",
       "    -87.01396424635172,\n",
       "    -83.32981292295246,\n",
       "    -62.34427033478381,\n",
       "    -73.87525935698109,\n",
       "    -76.58711531018298,\n",
       "    -74.63565538675907,\n",
       "    -72.03901721756382,\n",
       "    -56.87568713492629,\n",
       "    -65.43011531405466,\n",
       "    -44.57187720657699,\n",
       "    -99.26483493278697,\n",
       "    -42.024465280581154,\n",
       "    -88.993475107619,\n",
       "    -78.66486073801096,\n",
       "    -121.16195954708573,\n",
       "    -65.80555425566234,\n",
       "    -61.67969776945103,\n",
       "    -69.30172306403155,\n",
       "    -73.20777233509364,\n",
       "    -73.41541500975862,\n",
       "    -68.88764214940652,\n",
       "    -36.293007601338914,\n",
       "    -74.12512697387898,\n",
       "    -64.80678797067145,\n",
       "    -38.455960475520435,\n",
       "    -69.78339081376518,\n",
       "    -60.87573338903899,\n",
       "    -67.71913075321653,\n",
       "    -56.04098475494362,\n",
       "    -62.060804520303655,\n",
       "    -66.00196953364029,\n",
       "    -51.372405086575164,\n",
       "    -69.47494807010705,\n",
       "    -65.86503809733478,\n",
       "    -58.61815111189107,\n",
       "    -67.74900346915402,\n",
       "    -84.81765137771558,\n",
       "    -60.67331423719679,\n",
       "    -62.92092160691889,\n",
       "    -60.79696094331715,\n",
       "    -45.513389412176025,\n",
       "    -63.73940525979645,\n",
       "    -73.51188125439663,\n",
       "    -66.19938528968896,\n",
       "    -71.82528747308922,\n",
       "    -72.41427571751167,\n",
       "    -67.0926276246614,\n",
       "    -87.73465519194303,\n",
       "    -66.99358359103041,\n",
       "    -59.71774229342409,\n",
       "    -66.71006562864387,\n",
       "    -104.57601218831614],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.20852178660315934,\n",
       "   'mean_inference_ms': 0.6050274623264523,\n",
       "   'mean_action_processing_ms': 0.06574346669733908,\n",
       "   'mean_env_wait_ms': 1.0397408120859997,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 6000,\n",
       "  'agent_timesteps_total': 6000,\n",
       "  'timers': {'learn_time_ms': 1.412, 'learn_throughput': 70821.019},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -5.2142506,\n",
       "     'max_q': -3.9135168,\n",
       "     'min_q': -5.8881545,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 6000,\n",
       "   'num_agent_steps_sampled': 6000,\n",
       "   'num_steps_trained': 450100,\n",
       "   'num_agent_steps_trained': 450100,\n",
       "   'last_target_update_ts': 6000,\n",
       "   'num_target_updates': 4501},\n",
       "  'done': False,\n",
       "  'episodes_total': 59,\n",
       "  'training_iteration': 4,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-51-57',\n",
       "  'timestamp': 1625500317,\n",
       "  'time_this_iter_s': 18.63281512260437,\n",
       "  'time_total_s': 60.809181690216064,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 60.809181690216064,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 4,\n",
       "  'perf': {'cpu_util_percent': 12.532,\n",
       "   'ram_util_percent': 49.30799999999999,\n",
       "   'gpu_util_percent0': 0.124,\n",
       "   'vram_util_percent0': 0.53349015597034}},\n",
       " {'episode_reward_max': -36.293007601338914,\n",
       "  'episode_reward_min': -121.16195954708573,\n",
       "  'episode_reward_mean': -69.00023566118287,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-44.29764357780588,\n",
       "    -58.457792527484294,\n",
       "    -64.90832248467753,\n",
       "    -104.15944801994365,\n",
       "    -59.161750649202176,\n",
       "    -100.51041809315956,\n",
       "    -76.96754332001106,\n",
       "    -87.01396424635172,\n",
       "    -83.32981292295246,\n",
       "    -62.34427033478381,\n",
       "    -73.87525935698109,\n",
       "    -76.58711531018298,\n",
       "    -74.63565538675907,\n",
       "    -72.03901721756382,\n",
       "    -56.87568713492629,\n",
       "    -65.43011531405466,\n",
       "    -44.57187720657699,\n",
       "    -99.26483493278697,\n",
       "    -42.024465280581154,\n",
       "    -88.993475107619,\n",
       "    -78.66486073801096,\n",
       "    -121.16195954708573,\n",
       "    -65.80555425566234,\n",
       "    -61.67969776945103,\n",
       "    -69.30172306403155,\n",
       "    -73.20777233509364,\n",
       "    -73.41541500975862,\n",
       "    -68.88764214940652,\n",
       "    -36.293007601338914,\n",
       "    -74.12512697387898,\n",
       "    -64.80678797067145,\n",
       "    -38.455960475520435,\n",
       "    -69.78339081376518,\n",
       "    -60.87573338903899,\n",
       "    -67.71913075321653,\n",
       "    -56.04098475494362,\n",
       "    -62.060804520303655,\n",
       "    -66.00196953364029,\n",
       "    -51.372405086575164,\n",
       "    -69.47494807010705,\n",
       "    -65.86503809733478,\n",
       "    -58.61815111189107,\n",
       "    -67.74900346915402,\n",
       "    -84.81765137771558,\n",
       "    -60.67331423719679,\n",
       "    -62.92092160691889,\n",
       "    -60.79696094331715,\n",
       "    -45.513389412176025,\n",
       "    -63.73940525979645,\n",
       "    -73.51188125439663,\n",
       "    -66.19938528968896,\n",
       "    -71.82528747308922,\n",
       "    -72.41427571751167,\n",
       "    -67.0926276246614,\n",
       "    -87.73465519194303,\n",
       "    -66.99358359103041,\n",
       "    -59.71774229342409,\n",
       "    -66.71006562864387,\n",
       "    -104.57601218831614,\n",
       "    -52.94505660108639,\n",
       "    -55.895438544234686,\n",
       "    -71.83819945286761,\n",
       "    -73.86988247104861,\n",
       "    -81.54771190644996,\n",
       "    -69.92921391836606,\n",
       "    -64.52696925199842,\n",
       "    -68.94303440667532,\n",
       "    -41.88833433776803,\n",
       "    -78.68333941142663,\n",
       "    -65.66008818463254,\n",
       "    -74.96434284412726,\n",
       "    -101.12023175337838,\n",
       "    -58.81534317312836,\n",
       "    -73.33755766623344],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2099902310153392,\n",
       "   'mean_inference_ms': 0.5975411379328688,\n",
       "   'mean_action_processing_ms': 0.06689449872506358,\n",
       "   'mean_env_wait_ms': 1.054541360035572,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 7500,\n",
       "  'agent_timesteps_total': 7500,\n",
       "  'timers': {'learn_time_ms': 1.381, 'learn_throughput': 72397.97},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -5.9405603,\n",
       "     'max_q': -2.1193497,\n",
       "     'min_q': -7.328626,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 7500,\n",
       "   'num_agent_steps_sampled': 7500,\n",
       "   'num_steps_trained': 600100,\n",
       "   'num_agent_steps_trained': 600100,\n",
       "   'last_target_update_ts': 7500,\n",
       "   'num_target_updates': 6001},\n",
       "  'done': False,\n",
       "  'episodes_total': 74,\n",
       "  'training_iteration': 5,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-52-16',\n",
       "  'timestamp': 1625500336,\n",
       "  'time_this_iter_s': 18.704732656478882,\n",
       "  'time_total_s': 79.51391434669495,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 79.51391434669495,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 5,\n",
       "  'perf': {'cpu_util_percent': 12.407692307692306,\n",
       "   'ram_util_percent': 49.315384615384616,\n",
       "   'gpu_util_percent0': 0.13038461538461538,\n",
       "   'vram_util_percent0': 0.5325610211828571}},\n",
       " {'episode_reward_max': -36.293007601338914,\n",
       "  'episode_reward_min': -121.16195954708573,\n",
       "  'episode_reward_mean': -68.40649928614187,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-44.29764357780588,\n",
       "    -58.457792527484294,\n",
       "    -64.90832248467753,\n",
       "    -104.15944801994365,\n",
       "    -59.161750649202176,\n",
       "    -100.51041809315956,\n",
       "    -76.96754332001106,\n",
       "    -87.01396424635172,\n",
       "    -83.32981292295246,\n",
       "    -62.34427033478381,\n",
       "    -73.87525935698109,\n",
       "    -76.58711531018298,\n",
       "    -74.63565538675907,\n",
       "    -72.03901721756382,\n",
       "    -56.87568713492629,\n",
       "    -65.43011531405466,\n",
       "    -44.57187720657699,\n",
       "    -99.26483493278697,\n",
       "    -42.024465280581154,\n",
       "    -88.993475107619,\n",
       "    -78.66486073801096,\n",
       "    -121.16195954708573,\n",
       "    -65.80555425566234,\n",
       "    -61.67969776945103,\n",
       "    -69.30172306403155,\n",
       "    -73.20777233509364,\n",
       "    -73.41541500975862,\n",
       "    -68.88764214940652,\n",
       "    -36.293007601338914,\n",
       "    -74.12512697387898,\n",
       "    -64.80678797067145,\n",
       "    -38.455960475520435,\n",
       "    -69.78339081376518,\n",
       "    -60.87573338903899,\n",
       "    -67.71913075321653,\n",
       "    -56.04098475494362,\n",
       "    -62.060804520303655,\n",
       "    -66.00196953364029,\n",
       "    -51.372405086575164,\n",
       "    -69.47494807010705,\n",
       "    -65.86503809733478,\n",
       "    -58.61815111189107,\n",
       "    -67.74900346915402,\n",
       "    -84.81765137771558,\n",
       "    -60.67331423719679,\n",
       "    -62.92092160691889,\n",
       "    -60.79696094331715,\n",
       "    -45.513389412176025,\n",
       "    -63.73940525979645,\n",
       "    -73.51188125439663,\n",
       "    -66.19938528968896,\n",
       "    -71.82528747308922,\n",
       "    -72.41427571751167,\n",
       "    -67.0926276246614,\n",
       "    -87.73465519194303,\n",
       "    -66.99358359103041,\n",
       "    -59.71774229342409,\n",
       "    -66.71006562864387,\n",
       "    -104.57601218831614,\n",
       "    -52.94505660108639,\n",
       "    -55.895438544234686,\n",
       "    -71.83819945286761,\n",
       "    -73.86988247104861,\n",
       "    -81.54771190644996,\n",
       "    -69.92921391836606,\n",
       "    -64.52696925199842,\n",
       "    -68.94303440667532,\n",
       "    -41.88833433776803,\n",
       "    -78.68333941142663,\n",
       "    -65.66008818463254,\n",
       "    -74.96434284412726,\n",
       "    -101.12023175337838,\n",
       "    -58.81534317312836,\n",
       "    -73.33755766623344,\n",
       "    -67.95324818706871,\n",
       "    -58.48877653229502,\n",
       "    -41.92880360990791,\n",
       "    -89.08568150002655,\n",
       "    -66.37154932361389,\n",
       "    -73.38257498994925,\n",
       "    -41.037183601250966,\n",
       "    -70.09984511467178,\n",
       "    -70.32267731991796,\n",
       "    -69.39816330366813,\n",
       "    -76.58974589818513,\n",
       "    -65.33917077567583,\n",
       "    -68.80146094896298,\n",
       "    -54.746336597862104,\n",
       "    -68.61577983603662],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.21103965819647952,\n",
       "   'mean_inference_ms': 0.5912180469383691,\n",
       "   'mean_action_processing_ms': 0.0676988383364252,\n",
       "   'mean_env_wait_ms': 1.068902910010547,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 9000,\n",
       "  'agent_timesteps_total': 9000,\n",
       "  'timers': {'learn_time_ms': 1.375, 'learn_throughput': 72705.438},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -6.747919,\n",
       "     'max_q': -2.3105454,\n",
       "     'min_q': -8.717107,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 9000,\n",
       "   'num_agent_steps_sampled': 9000,\n",
       "   'num_steps_trained': 750100,\n",
       "   'num_agent_steps_trained': 750100,\n",
       "   'last_target_update_ts': 9000,\n",
       "   'num_target_updates': 7501},\n",
       "  'done': False,\n",
       "  'episodes_total': 89,\n",
       "  'training_iteration': 6,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-52-35',\n",
       "  'timestamp': 1625500355,\n",
       "  'time_this_iter_s': 19.291314840316772,\n",
       "  'time_total_s': 98.80522918701172,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 98.80522918701172,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 6,\n",
       "  'perf': {'cpu_util_percent': 12.342307692307692,\n",
       "   'ram_util_percent': 49.40384615384615,\n",
       "   'gpu_util_percent0': 0.10923076923076924,\n",
       "   'vram_util_percent0': 0.5327183683102885}},\n",
       " {'episode_reward_max': -33.27495644827692,\n",
       "  'episode_reward_min': -121.16195954708573,\n",
       "  'episode_reward_mean': -68.14296795662415,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 14,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-104.15944801994365,\n",
       "    -59.161750649202176,\n",
       "    -100.51041809315956,\n",
       "    -76.96754332001106,\n",
       "    -87.01396424635172,\n",
       "    -83.32981292295246,\n",
       "    -62.34427033478381,\n",
       "    -73.87525935698109,\n",
       "    -76.58711531018298,\n",
       "    -74.63565538675907,\n",
       "    -72.03901721756382,\n",
       "    -56.87568713492629,\n",
       "    -65.43011531405466,\n",
       "    -44.57187720657699,\n",
       "    -99.26483493278697,\n",
       "    -42.024465280581154,\n",
       "    -88.993475107619,\n",
       "    -78.66486073801096,\n",
       "    -121.16195954708573,\n",
       "    -65.80555425566234,\n",
       "    -61.67969776945103,\n",
       "    -69.30172306403155,\n",
       "    -73.20777233509364,\n",
       "    -73.41541500975862,\n",
       "    -68.88764214940652,\n",
       "    -36.293007601338914,\n",
       "    -74.12512697387898,\n",
       "    -64.80678797067145,\n",
       "    -38.455960475520435,\n",
       "    -69.78339081376518,\n",
       "    -60.87573338903899,\n",
       "    -67.71913075321653,\n",
       "    -56.04098475494362,\n",
       "    -62.060804520303655,\n",
       "    -66.00196953364029,\n",
       "    -51.372405086575164,\n",
       "    -69.47494807010705,\n",
       "    -65.86503809733478,\n",
       "    -58.61815111189107,\n",
       "    -67.74900346915402,\n",
       "    -84.81765137771558,\n",
       "    -60.67331423719679,\n",
       "    -62.92092160691889,\n",
       "    -60.79696094331715,\n",
       "    -45.513389412176025,\n",
       "    -63.73940525979645,\n",
       "    -73.51188125439663,\n",
       "    -66.19938528968896,\n",
       "    -71.82528747308922,\n",
       "    -72.41427571751167,\n",
       "    -67.0926276246614,\n",
       "    -87.73465519194303,\n",
       "    -66.99358359103041,\n",
       "    -59.71774229342409,\n",
       "    -66.71006562864387,\n",
       "    -104.57601218831614,\n",
       "    -52.94505660108639,\n",
       "    -55.895438544234686,\n",
       "    -71.83819945286761,\n",
       "    -73.86988247104861,\n",
       "    -81.54771190644996,\n",
       "    -69.92921391836606,\n",
       "    -64.52696925199842,\n",
       "    -68.94303440667532,\n",
       "    -41.88833433776803,\n",
       "    -78.68333941142663,\n",
       "    -65.66008818463254,\n",
       "    -74.96434284412726,\n",
       "    -101.12023175337838,\n",
       "    -58.81534317312836,\n",
       "    -73.33755766623344,\n",
       "    -67.95324818706871,\n",
       "    -58.48877653229502,\n",
       "    -41.92880360990791,\n",
       "    -89.08568150002655,\n",
       "    -66.37154932361389,\n",
       "    -73.38257498994925,\n",
       "    -41.037183601250966,\n",
       "    -70.09984511467178,\n",
       "    -70.32267731991796,\n",
       "    -69.39816330366813,\n",
       "    -76.58974589818513,\n",
       "    -65.33917077567583,\n",
       "    -68.80146094896298,\n",
       "    -54.746336597862104,\n",
       "    -68.61577983603662,\n",
       "    -70.49056076380334,\n",
       "    -62.53393550348515,\n",
       "    -37.720910119113526,\n",
       "    -67.38422389300706,\n",
       "    -71.04988637166016,\n",
       "    -60.05669966006082,\n",
       "    -81.3521469247887,\n",
       "    -71.94502145152077,\n",
       "    -65.20444602224258,\n",
       "    -33.27495644827692,\n",
       "    -70.4774276768901,\n",
       "    -72.07274614626654,\n",
       "    -67.62265343190343,\n",
       "    -62.59650337273768],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.21225550274938818,\n",
       "   'mean_inference_ms': 0.5843330104646944,\n",
       "   'mean_action_processing_ms': 0.06865442973260463,\n",
       "   'mean_env_wait_ms': 1.0881597066832733,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 10500,\n",
       "  'agent_timesteps_total': 10500,\n",
       "  'timers': {'learn_time_ms': 1.445, 'learn_throughput': 69209.511},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -7.267871,\n",
       "     'max_q': -2.037447,\n",
       "     'min_q': -10.242149,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 10500,\n",
       "   'num_agent_steps_sampled': 10500,\n",
       "   'num_steps_trained': 900100,\n",
       "   'num_agent_steps_trained': 900100,\n",
       "   'last_target_update_ts': 10500,\n",
       "   'num_target_updates': 9001},\n",
       "  'done': False,\n",
       "  'episodes_total': 103,\n",
       "  'training_iteration': 7,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-52-55',\n",
       "  'timestamp': 1625500375,\n",
       "  'time_this_iter_s': 19.246764183044434,\n",
       "  'time_total_s': 118.05199337005615,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 118.05199337005615,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 7,\n",
       "  'perf': {'cpu_util_percent': 12.161538461538461,\n",
       "   'ram_util_percent': 49.407692307692315,\n",
       "   'gpu_util_percent0': 0.10692307692307693,\n",
       "   'vram_util_percent0': 0.5327183683102885}},\n",
       " {'episode_reward_max': -33.27495644827692,\n",
       "  'episode_reward_min': -121.16195954708573,\n",
       "  'episode_reward_mean': -67.06346811174328,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-42.024465280581154,\n",
       "    -88.993475107619,\n",
       "    -78.66486073801096,\n",
       "    -121.16195954708573,\n",
       "    -65.80555425566234,\n",
       "    -61.67969776945103,\n",
       "    -69.30172306403155,\n",
       "    -73.20777233509364,\n",
       "    -73.41541500975862,\n",
       "    -68.88764214940652,\n",
       "    -36.293007601338914,\n",
       "    -74.12512697387898,\n",
       "    -64.80678797067145,\n",
       "    -38.455960475520435,\n",
       "    -69.78339081376518,\n",
       "    -60.87573338903899,\n",
       "    -67.71913075321653,\n",
       "    -56.04098475494362,\n",
       "    -62.060804520303655,\n",
       "    -66.00196953364029,\n",
       "    -51.372405086575164,\n",
       "    -69.47494807010705,\n",
       "    -65.86503809733478,\n",
       "    -58.61815111189107,\n",
       "    -67.74900346915402,\n",
       "    -84.81765137771558,\n",
       "    -60.67331423719679,\n",
       "    -62.92092160691889,\n",
       "    -60.79696094331715,\n",
       "    -45.513389412176025,\n",
       "    -63.73940525979645,\n",
       "    -73.51188125439663,\n",
       "    -66.19938528968896,\n",
       "    -71.82528747308922,\n",
       "    -72.41427571751167,\n",
       "    -67.0926276246614,\n",
       "    -87.73465519194303,\n",
       "    -66.99358359103041,\n",
       "    -59.71774229342409,\n",
       "    -66.71006562864387,\n",
       "    -104.57601218831614,\n",
       "    -52.94505660108639,\n",
       "    -55.895438544234686,\n",
       "    -71.83819945286761,\n",
       "    -73.86988247104861,\n",
       "    -81.54771190644996,\n",
       "    -69.92921391836606,\n",
       "    -64.52696925199842,\n",
       "    -68.94303440667532,\n",
       "    -41.88833433776803,\n",
       "    -78.68333941142663,\n",
       "    -65.66008818463254,\n",
       "    -74.96434284412726,\n",
       "    -101.12023175337838,\n",
       "    -58.81534317312836,\n",
       "    -73.33755766623344,\n",
       "    -67.95324818706871,\n",
       "    -58.48877653229502,\n",
       "    -41.92880360990791,\n",
       "    -89.08568150002655,\n",
       "    -66.37154932361389,\n",
       "    -73.38257498994925,\n",
       "    -41.037183601250966,\n",
       "    -70.09984511467178,\n",
       "    -70.32267731991796,\n",
       "    -69.39816330366813,\n",
       "    -76.58974589818513,\n",
       "    -65.33917077567583,\n",
       "    -68.80146094896298,\n",
       "    -54.746336597862104,\n",
       "    -68.61577983603662,\n",
       "    -70.49056076380334,\n",
       "    -62.53393550348515,\n",
       "    -37.720910119113526,\n",
       "    -67.38422389300706,\n",
       "    -71.04988637166016,\n",
       "    -60.05669966006082,\n",
       "    -81.3521469247887,\n",
       "    -71.94502145152077,\n",
       "    -65.20444602224258,\n",
       "    -33.27495644827692,\n",
       "    -70.4774276768901,\n",
       "    -72.07274614626654,\n",
       "    -67.62265343190343,\n",
       "    -62.59650337273768,\n",
       "    -62.48863835611451,\n",
       "    -63.99369687424335,\n",
       "    -65.53987224809846,\n",
       "    -68.15708624812463,\n",
       "    -106.42380385613262,\n",
       "    -68.15874714774775,\n",
       "    -53.27892199773634,\n",
       "    -63.26498633459871,\n",
       "    -69.77803721634412,\n",
       "    -71.30632818822134,\n",
       "    -68.82478442773139,\n",
       "    -76.03447854909479,\n",
       "    -43.4408893994082,\n",
       "    -69.88101885808334,\n",
       "    -78.24549525646924],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.21505141994704552,\n",
       "   'mean_inference_ms': 0.5717854391871626,\n",
       "   'mean_action_processing_ms': 0.0707968562151315,\n",
       "   'mean_env_wait_ms': 1.1301301290122672,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 12000,\n",
       "  'agent_timesteps_total': 12000,\n",
       "  'timers': {'learn_time_ms': 1.401, 'learn_throughput': 71397.27},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -7.9960103,\n",
       "     'max_q': -3.0167942,\n",
       "     'min_q': -11.116263,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 12000,\n",
       "   'num_agent_steps_sampled': 12000,\n",
       "   'num_steps_trained': 1050100,\n",
       "   'num_agent_steps_trained': 1050100,\n",
       "   'last_target_update_ts': 12000,\n",
       "   'num_target_updates': 10501},\n",
       "  'done': False,\n",
       "  'episodes_total': 118,\n",
       "  'training_iteration': 8,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-53-14',\n",
       "  'timestamp': 1625500394,\n",
       "  'time_this_iter_s': 19.241841077804565,\n",
       "  'time_total_s': 137.29383444786072,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 137.29383444786072,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 8,\n",
       "  'perf': {'cpu_util_percent': 13.084615384615386,\n",
       "   'ram_util_percent': 49.53846153846154,\n",
       "   'gpu_util_percent0': 0.20115384615384618,\n",
       "   'vram_util_percent0': 0.5325905237692504}},\n",
       " {'episode_reward_max': -33.27495644827692,\n",
       "  'episode_reward_min': -106.42380385613262,\n",
       "  'episode_reward_mean': -67.69651563092536,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-60.87573338903899,\n",
       "    -67.71913075321653,\n",
       "    -56.04098475494362,\n",
       "    -62.060804520303655,\n",
       "    -66.00196953364029,\n",
       "    -51.372405086575164,\n",
       "    -69.47494807010705,\n",
       "    -65.86503809733478,\n",
       "    -58.61815111189107,\n",
       "    -67.74900346915402,\n",
       "    -84.81765137771558,\n",
       "    -60.67331423719679,\n",
       "    -62.92092160691889,\n",
       "    -60.79696094331715,\n",
       "    -45.513389412176025,\n",
       "    -63.73940525979645,\n",
       "    -73.51188125439663,\n",
       "    -66.19938528968896,\n",
       "    -71.82528747308922,\n",
       "    -72.41427571751167,\n",
       "    -67.0926276246614,\n",
       "    -87.73465519194303,\n",
       "    -66.99358359103041,\n",
       "    -59.71774229342409,\n",
       "    -66.71006562864387,\n",
       "    -104.57601218831614,\n",
       "    -52.94505660108639,\n",
       "    -55.895438544234686,\n",
       "    -71.83819945286761,\n",
       "    -73.86988247104861,\n",
       "    -81.54771190644996,\n",
       "    -69.92921391836606,\n",
       "    -64.52696925199842,\n",
       "    -68.94303440667532,\n",
       "    -41.88833433776803,\n",
       "    -78.68333941142663,\n",
       "    -65.66008818463254,\n",
       "    -74.96434284412726,\n",
       "    -101.12023175337838,\n",
       "    -58.81534317312836,\n",
       "    -73.33755766623344,\n",
       "    -67.95324818706871,\n",
       "    -58.48877653229502,\n",
       "    -41.92880360990791,\n",
       "    -89.08568150002655,\n",
       "    -66.37154932361389,\n",
       "    -73.38257498994925,\n",
       "    -41.037183601250966,\n",
       "    -70.09984511467178,\n",
       "    -70.32267731991796,\n",
       "    -69.39816330366813,\n",
       "    -76.58974589818513,\n",
       "    -65.33917077567583,\n",
       "    -68.80146094896298,\n",
       "    -54.746336597862104,\n",
       "    -68.61577983603662,\n",
       "    -70.49056076380334,\n",
       "    -62.53393550348515,\n",
       "    -37.720910119113526,\n",
       "    -67.38422389300706,\n",
       "    -71.04988637166016,\n",
       "    -60.05669966006082,\n",
       "    -81.3521469247887,\n",
       "    -71.94502145152077,\n",
       "    -65.20444602224258,\n",
       "    -33.27495644827692,\n",
       "    -70.4774276768901,\n",
       "    -72.07274614626654,\n",
       "    -67.62265343190343,\n",
       "    -62.59650337273768,\n",
       "    -62.48863835611451,\n",
       "    -63.99369687424335,\n",
       "    -65.53987224809846,\n",
       "    -68.15708624812463,\n",
       "    -106.42380385613262,\n",
       "    -68.15874714774775,\n",
       "    -53.27892199773634,\n",
       "    -63.26498633459871,\n",
       "    -69.77803721634412,\n",
       "    -71.30632818822134,\n",
       "    -68.82478442773139,\n",
       "    -76.03447854909479,\n",
       "    -43.4408893994082,\n",
       "    -69.88101885808334,\n",
       "    -78.24549525646924,\n",
       "    -61.02869884434483,\n",
       "    -73.69226495408617,\n",
       "    -70.94476438812457,\n",
       "    -74.15239133953673,\n",
       "    -66.73578144296758,\n",
       "    -75.89568431459817,\n",
       "    -65.69553343872931,\n",
       "    -104.32287194170316,\n",
       "    -70.83758133190183,\n",
       "    -68.15631769830115,\n",
       "    -71.61151847234898,\n",
       "    -70.7796211278556,\n",
       "    -74.77766360569721,\n",
       "    -71.88834127507447,\n",
       "    -69.3925568348154],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.21615280912351165,\n",
       "   'mean_inference_ms': 0.5655498499841641,\n",
       "   'mean_action_processing_ms': 0.07164227741294464,\n",
       "   'mean_env_wait_ms': 1.1480872611725286,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 13500,\n",
       "  'agent_timesteps_total': 13500,\n",
       "  'timers': {'learn_time_ms': 1.4, 'learn_throughput': 71414.289},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -8.962172,\n",
       "     'max_q': -2.0332909,\n",
       "     'min_q': -12.2808275,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 13500,\n",
       "   'num_agent_steps_sampled': 13500,\n",
       "   'num_steps_trained': 1200100,\n",
       "   'num_agent_steps_trained': 1200100,\n",
       "   'last_target_update_ts': 13500,\n",
       "   'num_target_updates': 12001},\n",
       "  'done': False,\n",
       "  'episodes_total': 133,\n",
       "  'training_iteration': 9,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-53-33',\n",
       "  'timestamp': 1625500413,\n",
       "  'time_this_iter_s': 19.498490571975708,\n",
       "  'time_total_s': 156.79232501983643,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 156.79232501983643,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 9,\n",
       "  'perf': {'cpu_util_percent': 12.661538461538461,\n",
       "   'ram_util_percent': 49.56923076923076,\n",
       "   'gpu_util_percent0': 0.20423076923076924,\n",
       "   'vram_util_percent0': 0.5290698817929707}},\n",
       " {'episode_reward_max': -33.27495644827692,\n",
       "  'episode_reward_min': -106.42380385613262,\n",
       "  'episode_reward_mean': -68.29438668069183,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-63.73940525979645,\n",
       "    -73.51188125439663,\n",
       "    -66.19938528968896,\n",
       "    -71.82528747308922,\n",
       "    -72.41427571751167,\n",
       "    -67.0926276246614,\n",
       "    -87.73465519194303,\n",
       "    -66.99358359103041,\n",
       "    -59.71774229342409,\n",
       "    -66.71006562864387,\n",
       "    -104.57601218831614,\n",
       "    -52.94505660108639,\n",
       "    -55.895438544234686,\n",
       "    -71.83819945286761,\n",
       "    -73.86988247104861,\n",
       "    -81.54771190644996,\n",
       "    -69.92921391836606,\n",
       "    -64.52696925199842,\n",
       "    -68.94303440667532,\n",
       "    -41.88833433776803,\n",
       "    -78.68333941142663,\n",
       "    -65.66008818463254,\n",
       "    -74.96434284412726,\n",
       "    -101.12023175337838,\n",
       "    -58.81534317312836,\n",
       "    -73.33755766623344,\n",
       "    -67.95324818706871,\n",
       "    -58.48877653229502,\n",
       "    -41.92880360990791,\n",
       "    -89.08568150002655,\n",
       "    -66.37154932361389,\n",
       "    -73.38257498994925,\n",
       "    -41.037183601250966,\n",
       "    -70.09984511467178,\n",
       "    -70.32267731991796,\n",
       "    -69.39816330366813,\n",
       "    -76.58974589818513,\n",
       "    -65.33917077567583,\n",
       "    -68.80146094896298,\n",
       "    -54.746336597862104,\n",
       "    -68.61577983603662,\n",
       "    -70.49056076380334,\n",
       "    -62.53393550348515,\n",
       "    -37.720910119113526,\n",
       "    -67.38422389300706,\n",
       "    -71.04988637166016,\n",
       "    -60.05669966006082,\n",
       "    -81.3521469247887,\n",
       "    -71.94502145152077,\n",
       "    -65.20444602224258,\n",
       "    -33.27495644827692,\n",
       "    -70.4774276768901,\n",
       "    -72.07274614626654,\n",
       "    -67.62265343190343,\n",
       "    -62.59650337273768,\n",
       "    -62.48863835611451,\n",
       "    -63.99369687424335,\n",
       "    -65.53987224809846,\n",
       "    -68.15708624812463,\n",
       "    -106.42380385613262,\n",
       "    -68.15874714774775,\n",
       "    -53.27892199773634,\n",
       "    -63.26498633459871,\n",
       "    -69.77803721634412,\n",
       "    -71.30632818822134,\n",
       "    -68.82478442773139,\n",
       "    -76.03447854909479,\n",
       "    -43.4408893994082,\n",
       "    -69.88101885808334,\n",
       "    -78.24549525646924,\n",
       "    -61.02869884434483,\n",
       "    -73.69226495408617,\n",
       "    -70.94476438812457,\n",
       "    -74.15239133953673,\n",
       "    -66.73578144296758,\n",
       "    -75.89568431459817,\n",
       "    -65.69553343872931,\n",
       "    -104.32287194170316,\n",
       "    -70.83758133190183,\n",
       "    -68.15631769830115,\n",
       "    -71.61151847234898,\n",
       "    -70.7796211278556,\n",
       "    -74.77766360569721,\n",
       "    -71.88834127507447,\n",
       "    -69.3925568348154,\n",
       "    -66.7618756879469,\n",
       "    -66.43866828598402,\n",
       "    -34.549179634175566,\n",
       "    -68.65198003169708,\n",
       "    -57.77588011512671,\n",
       "    -66.91606501786217,\n",
       "    -65.15738974549537,\n",
       "    -56.01095004662453,\n",
       "    -67.01812250945291,\n",
       "    -96.95021108450162,\n",
       "    -63.88196741930619,\n",
       "    -75.07623285260196,\n",
       "    -70.54036505961729,\n",
       "    -70.91991869244765,\n",
       "    -73.63870515733531],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.21670116787934865,\n",
       "   'mean_inference_ms': 0.5610114721328756,\n",
       "   'mean_action_processing_ms': 0.07213142468900037,\n",
       "   'mean_env_wait_ms': 1.1516423734821544,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 15000,\n",
       "  'agent_timesteps_total': 15000,\n",
       "  'timers': {'learn_time_ms': 1.483, 'learn_throughput': 67435.793},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -9.249465,\n",
       "     'max_q': -1.7399931,\n",
       "     'min_q': -13.630525,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 15000,\n",
       "   'num_agent_steps_sampled': 15000,\n",
       "   'num_steps_trained': 1350100,\n",
       "   'num_agent_steps_trained': 1350100,\n",
       "   'last_target_update_ts': 15000,\n",
       "   'num_target_updates': 13501},\n",
       "  'done': False,\n",
       "  'episodes_total': 148,\n",
       "  'training_iteration': 10,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-53-53',\n",
       "  'timestamp': 1625500433,\n",
       "  'time_this_iter_s': 19.879799842834473,\n",
       "  'time_total_s': 176.6721248626709,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 176.6721248626709,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 10,\n",
       "  'perf': {'cpu_util_percent': 12.54814814814815,\n",
       "   'ram_util_percent': 49.65555555555555,\n",
       "   'gpu_util_percent0': 0.2,\n",
       "   'vram_util_percent0': 0.5290680606456624}},\n",
       " {'episode_reward_max': -33.27495644827692,\n",
       "  'episode_reward_min': -106.42380385613262,\n",
       "  'episode_reward_mean': -67.51251905994411,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-81.54771190644996,\n",
       "    -69.92921391836606,\n",
       "    -64.52696925199842,\n",
       "    -68.94303440667532,\n",
       "    -41.88833433776803,\n",
       "    -78.68333941142663,\n",
       "    -65.66008818463254,\n",
       "    -74.96434284412726,\n",
       "    -101.12023175337838,\n",
       "    -58.81534317312836,\n",
       "    -73.33755766623344,\n",
       "    -67.95324818706871,\n",
       "    -58.48877653229502,\n",
       "    -41.92880360990791,\n",
       "    -89.08568150002655,\n",
       "    -66.37154932361389,\n",
       "    -73.38257498994925,\n",
       "    -41.037183601250966,\n",
       "    -70.09984511467178,\n",
       "    -70.32267731991796,\n",
       "    -69.39816330366813,\n",
       "    -76.58974589818513,\n",
       "    -65.33917077567583,\n",
       "    -68.80146094896298,\n",
       "    -54.746336597862104,\n",
       "    -68.61577983603662,\n",
       "    -70.49056076380334,\n",
       "    -62.53393550348515,\n",
       "    -37.720910119113526,\n",
       "    -67.38422389300706,\n",
       "    -71.04988637166016,\n",
       "    -60.05669966006082,\n",
       "    -81.3521469247887,\n",
       "    -71.94502145152077,\n",
       "    -65.20444602224258,\n",
       "    -33.27495644827692,\n",
       "    -70.4774276768901,\n",
       "    -72.07274614626654,\n",
       "    -67.62265343190343,\n",
       "    -62.59650337273768,\n",
       "    -62.48863835611451,\n",
       "    -63.99369687424335,\n",
       "    -65.53987224809846,\n",
       "    -68.15708624812463,\n",
       "    -106.42380385613262,\n",
       "    -68.15874714774775,\n",
       "    -53.27892199773634,\n",
       "    -63.26498633459871,\n",
       "    -69.77803721634412,\n",
       "    -71.30632818822134,\n",
       "    -68.82478442773139,\n",
       "    -76.03447854909479,\n",
       "    -43.4408893994082,\n",
       "    -69.88101885808334,\n",
       "    -78.24549525646924,\n",
       "    -61.02869884434483,\n",
       "    -73.69226495408617,\n",
       "    -70.94476438812457,\n",
       "    -74.15239133953673,\n",
       "    -66.73578144296758,\n",
       "    -75.89568431459817,\n",
       "    -65.69553343872931,\n",
       "    -104.32287194170316,\n",
       "    -70.83758133190183,\n",
       "    -68.15631769830115,\n",
       "    -71.61151847234898,\n",
       "    -70.7796211278556,\n",
       "    -74.77766360569721,\n",
       "    -71.88834127507447,\n",
       "    -69.3925568348154,\n",
       "    -66.7618756879469,\n",
       "    -66.43866828598402,\n",
       "    -34.549179634175566,\n",
       "    -68.65198003169708,\n",
       "    -57.77588011512671,\n",
       "    -66.91606501786217,\n",
       "    -65.15738974549537,\n",
       "    -56.01095004662453,\n",
       "    -67.01812250945291,\n",
       "    -96.95021108450162,\n",
       "    -63.88196741930619,\n",
       "    -75.07623285260196,\n",
       "    -70.54036505961729,\n",
       "    -70.91991869244765,\n",
       "    -73.63870515733531,\n",
       "    -74.69410324943924,\n",
       "    -56.20110215797976,\n",
       "    -70.94143283550702,\n",
       "    -74.46559865393965,\n",
       "    -37.90696713620425,\n",
       "    -97.11807401482625,\n",
       "    -67.28465395384589,\n",
       "    -58.09257751126385,\n",
       "    -41.417265676140495,\n",
       "    -71.5908118888191,\n",
       "    -58.861463183941325,\n",
       "    -66.08616636973147,\n",
       "    -67.81963689311411,\n",
       "    -63.77983829718602,\n",
       "    -70.6170446850291],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.21713906294285096,\n",
       "   'mean_inference_ms': 0.5583190861573734,\n",
       "   'mean_action_processing_ms': 0.07251398564854852,\n",
       "   'mean_env_wait_ms': 1.1590234363780418,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 16500,\n",
       "  'agent_timesteps_total': 16500,\n",
       "  'timers': {'learn_time_ms': 1.341, 'learn_throughput': 74564.079},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -8.526261,\n",
       "     'max_q': -2.5233767,\n",
       "     'min_q': -13.779133,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 16500,\n",
       "   'num_agent_steps_sampled': 16500,\n",
       "   'num_steps_trained': 1500100,\n",
       "   'num_agent_steps_trained': 1500100,\n",
       "   'last_target_update_ts': 16500,\n",
       "   'num_target_updates': 15001},\n",
       "  'done': False,\n",
       "  'episodes_total': 163,\n",
       "  'training_iteration': 11,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-54-13',\n",
       "  'timestamp': 1625500453,\n",
       "  'time_this_iter_s': 19.49092149734497,\n",
       "  'time_total_s': 196.16304636001587,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 196.16304636001587,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 11,\n",
       "  'perf': {'cpu_util_percent': 12.240740740740742,\n",
       "   'ram_util_percent': 49.677777777777784,\n",
       "   'gpu_util_percent0': 0.1666666666666667,\n",
       "   'vram_util_percent0': 0.5259429718647312}},\n",
       " {'episode_reward_max': -33.27495644827692,\n",
       "  'episode_reward_min': -118.76138410679755,\n",
       "  'episode_reward_mean': -67.75484556157036,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-66.37154932361389,\n",
       "    -73.38257498994925,\n",
       "    -41.037183601250966,\n",
       "    -70.09984511467178,\n",
       "    -70.32267731991796,\n",
       "    -69.39816330366813,\n",
       "    -76.58974589818513,\n",
       "    -65.33917077567583,\n",
       "    -68.80146094896298,\n",
       "    -54.746336597862104,\n",
       "    -68.61577983603662,\n",
       "    -70.49056076380334,\n",
       "    -62.53393550348515,\n",
       "    -37.720910119113526,\n",
       "    -67.38422389300706,\n",
       "    -71.04988637166016,\n",
       "    -60.05669966006082,\n",
       "    -81.3521469247887,\n",
       "    -71.94502145152077,\n",
       "    -65.20444602224258,\n",
       "    -33.27495644827692,\n",
       "    -70.4774276768901,\n",
       "    -72.07274614626654,\n",
       "    -67.62265343190343,\n",
       "    -62.59650337273768,\n",
       "    -62.48863835611451,\n",
       "    -63.99369687424335,\n",
       "    -65.53987224809846,\n",
       "    -68.15708624812463,\n",
       "    -106.42380385613262,\n",
       "    -68.15874714774775,\n",
       "    -53.27892199773634,\n",
       "    -63.26498633459871,\n",
       "    -69.77803721634412,\n",
       "    -71.30632818822134,\n",
       "    -68.82478442773139,\n",
       "    -76.03447854909479,\n",
       "    -43.4408893994082,\n",
       "    -69.88101885808334,\n",
       "    -78.24549525646924,\n",
       "    -61.02869884434483,\n",
       "    -73.69226495408617,\n",
       "    -70.94476438812457,\n",
       "    -74.15239133953673,\n",
       "    -66.73578144296758,\n",
       "    -75.89568431459817,\n",
       "    -65.69553343872931,\n",
       "    -104.32287194170316,\n",
       "    -70.83758133190183,\n",
       "    -68.15631769830115,\n",
       "    -71.61151847234898,\n",
       "    -70.7796211278556,\n",
       "    -74.77766360569721,\n",
       "    -71.88834127507447,\n",
       "    -69.3925568348154,\n",
       "    -66.7618756879469,\n",
       "    -66.43866828598402,\n",
       "    -34.549179634175566,\n",
       "    -68.65198003169708,\n",
       "    -57.77588011512671,\n",
       "    -66.91606501786217,\n",
       "    -65.15738974549537,\n",
       "    -56.01095004662453,\n",
       "    -67.01812250945291,\n",
       "    -96.95021108450162,\n",
       "    -63.88196741930619,\n",
       "    -75.07623285260196,\n",
       "    -70.54036505961729,\n",
       "    -70.91991869244765,\n",
       "    -73.63870515733531,\n",
       "    -74.69410324943924,\n",
       "    -56.20110215797976,\n",
       "    -70.94143283550702,\n",
       "    -74.46559865393965,\n",
       "    -37.90696713620425,\n",
       "    -97.11807401482625,\n",
       "    -67.28465395384589,\n",
       "    -58.09257751126385,\n",
       "    -41.417265676140495,\n",
       "    -71.5908118888191,\n",
       "    -58.861463183941325,\n",
       "    -66.08616636973147,\n",
       "    -67.81963689311411,\n",
       "    -63.77983829718602,\n",
       "    -70.6170446850291,\n",
       "    -74.74217386014384,\n",
       "    -76.15483327909932,\n",
       "    -118.76138410679755,\n",
       "    -76.9759454210475,\n",
       "    -63.65308669186759,\n",
       "    -52.885917579268664,\n",
       "    -38.77679018388243,\n",
       "    -106.44830662987083,\n",
       "    -35.66860863643257,\n",
       "    -72.01686453878696,\n",
       "    -50.36872601748615,\n",
       "    -39.10320229926052,\n",
       "    -106.99665495863121,\n",
       "    -78.21024098881396,\n",
       "    -70.3425916547193],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.21755551790284192,\n",
       "   'mean_inference_ms': 0.5567451160732264,\n",
       "   'mean_action_processing_ms': 0.0728556919446485,\n",
       "   'mean_env_wait_ms': 1.1677602463345444,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 18000,\n",
       "  'agent_timesteps_total': 18000,\n",
       "  'timers': {'learn_time_ms': 1.602, 'learn_throughput': 62414.309},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -8.89155,\n",
       "     'max_q': -1.4178468,\n",
       "     'min_q': -14.683425,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 18000,\n",
       "   'num_agent_steps_sampled': 18000,\n",
       "   'num_steps_trained': 1650100,\n",
       "   'num_agent_steps_trained': 1650100,\n",
       "   'last_target_update_ts': 18000,\n",
       "   'num_target_updates': 16501},\n",
       "  'done': False,\n",
       "  'episodes_total': 178,\n",
       "  'training_iteration': 12,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-54-32',\n",
       "  'timestamp': 1625500472,\n",
       "  'time_this_iter_s': 19.20927906036377,\n",
       "  'time_total_s': 215.37232542037964,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 215.37232542037964,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 12,\n",
       "  'perf': {'cpu_util_percent': 13.200000000000001,\n",
       "   'ram_util_percent': 49.71153846153847,\n",
       "   'gpu_util_percent0': 0.21576923076923074,\n",
       "   'vram_util_percent0': 0.5307220266310013}},\n",
       " {'episode_reward_max': -33.27495644827692,\n",
       "  'episode_reward_min': -118.76138410679755,\n",
       "  'episode_reward_mean': -68.4256972561449,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-71.04988637166016,\n",
       "    -60.05669966006082,\n",
       "    -81.3521469247887,\n",
       "    -71.94502145152077,\n",
       "    -65.20444602224258,\n",
       "    -33.27495644827692,\n",
       "    -70.4774276768901,\n",
       "    -72.07274614626654,\n",
       "    -67.62265343190343,\n",
       "    -62.59650337273768,\n",
       "    -62.48863835611451,\n",
       "    -63.99369687424335,\n",
       "    -65.53987224809846,\n",
       "    -68.15708624812463,\n",
       "    -106.42380385613262,\n",
       "    -68.15874714774775,\n",
       "    -53.27892199773634,\n",
       "    -63.26498633459871,\n",
       "    -69.77803721634412,\n",
       "    -71.30632818822134,\n",
       "    -68.82478442773139,\n",
       "    -76.03447854909479,\n",
       "    -43.4408893994082,\n",
       "    -69.88101885808334,\n",
       "    -78.24549525646924,\n",
       "    -61.02869884434483,\n",
       "    -73.69226495408617,\n",
       "    -70.94476438812457,\n",
       "    -74.15239133953673,\n",
       "    -66.73578144296758,\n",
       "    -75.89568431459817,\n",
       "    -65.69553343872931,\n",
       "    -104.32287194170316,\n",
       "    -70.83758133190183,\n",
       "    -68.15631769830115,\n",
       "    -71.61151847234898,\n",
       "    -70.7796211278556,\n",
       "    -74.77766360569721,\n",
       "    -71.88834127507447,\n",
       "    -69.3925568348154,\n",
       "    -66.7618756879469,\n",
       "    -66.43866828598402,\n",
       "    -34.549179634175566,\n",
       "    -68.65198003169708,\n",
       "    -57.77588011512671,\n",
       "    -66.91606501786217,\n",
       "    -65.15738974549537,\n",
       "    -56.01095004662453,\n",
       "    -67.01812250945291,\n",
       "    -96.95021108450162,\n",
       "    -63.88196741930619,\n",
       "    -75.07623285260196,\n",
       "    -70.54036505961729,\n",
       "    -70.91991869244765,\n",
       "    -73.63870515733531,\n",
       "    -74.69410324943924,\n",
       "    -56.20110215797976,\n",
       "    -70.94143283550702,\n",
       "    -74.46559865393965,\n",
       "    -37.90696713620425,\n",
       "    -97.11807401482625,\n",
       "    -67.28465395384589,\n",
       "    -58.09257751126385,\n",
       "    -41.417265676140495,\n",
       "    -71.5908118888191,\n",
       "    -58.861463183941325,\n",
       "    -66.08616636973147,\n",
       "    -67.81963689311411,\n",
       "    -63.77983829718602,\n",
       "    -70.6170446850291,\n",
       "    -74.74217386014384,\n",
       "    -76.15483327909932,\n",
       "    -118.76138410679755,\n",
       "    -76.9759454210475,\n",
       "    -63.65308669186759,\n",
       "    -52.885917579268664,\n",
       "    -38.77679018388243,\n",
       "    -106.44830662987083,\n",
       "    -35.66860863643257,\n",
       "    -72.01686453878696,\n",
       "    -50.36872601748615,\n",
       "    -39.10320229926052,\n",
       "    -106.99665495863121,\n",
       "    -78.21024098881396,\n",
       "    -70.3425916547193,\n",
       "    -64.69962330113911,\n",
       "    -59.1825686718565,\n",
       "    -65.48189473194178,\n",
       "    -59.09276024403545,\n",
       "    -64.22737147540353,\n",
       "    -73.25183929806072,\n",
       "    -61.34879014719493,\n",
       "    -72.04217892894854,\n",
       "    -82.54314969700306,\n",
       "    -87.29737287639229,\n",
       "    -67.7184725972568,\n",
       "    -63.106422041409914,\n",
       "    -88.59465729368308,\n",
       "    -59.09839952404819,\n",
       "    -62.233786618282494],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.21794887103819513,\n",
       "   'mean_inference_ms': 0.5565604520925649,\n",
       "   'mean_action_processing_ms': 0.07320732930104265,\n",
       "   'mean_env_wait_ms': 1.17461069599295,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 19500,\n",
       "  'agent_timesteps_total': 19500,\n",
       "  'timers': {'learn_time_ms': 1.594, 'learn_throughput': 62745.774},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -8.778004,\n",
       "     'max_q': -2.0894012,\n",
       "     'min_q': -15.401364,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 19500,\n",
       "   'num_agent_steps_sampled': 19500,\n",
       "   'num_steps_trained': 1800100,\n",
       "   'num_agent_steps_trained': 1800100,\n",
       "   'last_target_update_ts': 19500,\n",
       "   'num_target_updates': 18001},\n",
       "  'done': False,\n",
       "  'episodes_total': 193,\n",
       "  'training_iteration': 13,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-54-52',\n",
       "  'timestamp': 1625500492,\n",
       "  'time_this_iter_s': 19.994198322296143,\n",
       "  'time_total_s': 235.36652374267578,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 235.36652374267578,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 13,\n",
       "  'perf': {'cpu_util_percent': 12.725925925925926,\n",
       "   'ram_util_percent': 49.766666666666666,\n",
       "   'gpu_util_percent0': 0.20407407407407407,\n",
       "   'vram_util_percent0': 0.5266532193149426}},\n",
       " {'episode_reward_max': -34.549179634175566,\n",
       "  'episode_reward_min': -118.76138410679755,\n",
       "  'episode_reward_mean': -69.39779398027741,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 14,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-106.42380385613262,\n",
       "    -68.15874714774775,\n",
       "    -53.27892199773634,\n",
       "    -63.26498633459871,\n",
       "    -69.77803721634412,\n",
       "    -71.30632818822134,\n",
       "    -68.82478442773139,\n",
       "    -76.03447854909479,\n",
       "    -43.4408893994082,\n",
       "    -69.88101885808334,\n",
       "    -78.24549525646924,\n",
       "    -61.02869884434483,\n",
       "    -73.69226495408617,\n",
       "    -70.94476438812457,\n",
       "    -74.15239133953673,\n",
       "    -66.73578144296758,\n",
       "    -75.89568431459817,\n",
       "    -65.69553343872931,\n",
       "    -104.32287194170316,\n",
       "    -70.83758133190183,\n",
       "    -68.15631769830115,\n",
       "    -71.61151847234898,\n",
       "    -70.7796211278556,\n",
       "    -74.77766360569721,\n",
       "    -71.88834127507447,\n",
       "    -69.3925568348154,\n",
       "    -66.7618756879469,\n",
       "    -66.43866828598402,\n",
       "    -34.549179634175566,\n",
       "    -68.65198003169708,\n",
       "    -57.77588011512671,\n",
       "    -66.91606501786217,\n",
       "    -65.15738974549537,\n",
       "    -56.01095004662453,\n",
       "    -67.01812250945291,\n",
       "    -96.95021108450162,\n",
       "    -63.88196741930619,\n",
       "    -75.07623285260196,\n",
       "    -70.54036505961729,\n",
       "    -70.91991869244765,\n",
       "    -73.63870515733531,\n",
       "    -74.69410324943924,\n",
       "    -56.20110215797976,\n",
       "    -70.94143283550702,\n",
       "    -74.46559865393965,\n",
       "    -37.90696713620425,\n",
       "    -97.11807401482625,\n",
       "    -67.28465395384589,\n",
       "    -58.09257751126385,\n",
       "    -41.417265676140495,\n",
       "    -71.5908118888191,\n",
       "    -58.861463183941325,\n",
       "    -66.08616636973147,\n",
       "    -67.81963689311411,\n",
       "    -63.77983829718602,\n",
       "    -70.6170446850291,\n",
       "    -74.74217386014384,\n",
       "    -76.15483327909932,\n",
       "    -118.76138410679755,\n",
       "    -76.9759454210475,\n",
       "    -63.65308669186759,\n",
       "    -52.885917579268664,\n",
       "    -38.77679018388243,\n",
       "    -106.44830662987083,\n",
       "    -35.66860863643257,\n",
       "    -72.01686453878696,\n",
       "    -50.36872601748615,\n",
       "    -39.10320229926052,\n",
       "    -106.99665495863121,\n",
       "    -78.21024098881396,\n",
       "    -70.3425916547193,\n",
       "    -64.69962330113911,\n",
       "    -59.1825686718565,\n",
       "    -65.48189473194178,\n",
       "    -59.09276024403545,\n",
       "    -64.22737147540353,\n",
       "    -73.25183929806072,\n",
       "    -61.34879014719493,\n",
       "    -72.04217892894854,\n",
       "    -82.54314969700306,\n",
       "    -87.29737287639229,\n",
       "    -67.7184725972568,\n",
       "    -63.106422041409914,\n",
       "    -88.59465729368308,\n",
       "    -59.09839952404819,\n",
       "    -62.233786618282494,\n",
       "    -110.02770530547065,\n",
       "    -52.22777344629228,\n",
       "    -69.45316734016465,\n",
       "    -99.6696367400076,\n",
       "    -70.76344497273081,\n",
       "    -70.14459023323086,\n",
       "    -75.42466421279204,\n",
       "    -67.00461710379545,\n",
       "    -55.44578996826647,\n",
       "    -50.45708876041607,\n",
       "    -67.01252784670129,\n",
       "    -75.63738732598644,\n",
       "    -64.42745969663187,\n",
       "    -85.34560069369586],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.21833272636218964,\n",
       "   'mean_inference_ms': 0.5569238120563861,\n",
       "   'mean_action_processing_ms': 0.0735344499251691,\n",
       "   'mean_env_wait_ms': 1.1798254021046861,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 21000,\n",
       "  'agent_timesteps_total': 21000,\n",
       "  'timers': {'learn_time_ms': 1.684, 'learn_throughput': 59389.216},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -10.456233,\n",
       "     'max_q': -1.0276921,\n",
       "     'min_q': -16.34292,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 21000,\n",
       "   'num_agent_steps_sampled': 21000,\n",
       "   'num_steps_trained': 1950100,\n",
       "   'num_agent_steps_trained': 1950100,\n",
       "   'last_target_update_ts': 21000,\n",
       "   'num_target_updates': 19501},\n",
       "  'done': False,\n",
       "  'episodes_total': 207,\n",
       "  'training_iteration': 14,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-55-12',\n",
       "  'timestamp': 1625500512,\n",
       "  'time_this_iter_s': 19.938971281051636,\n",
       "  'time_total_s': 255.30549502372742,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 255.30549502372742,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 14,\n",
       "  'perf': {'cpu_util_percent': 12.38888888888889,\n",
       "   'ram_util_percent': 49.79999999999999,\n",
       "   'gpu_util_percent0': 0.22185185185185186,\n",
       "   'vram_util_percent0': 0.5286040323115239}},\n",
       " {'episode_reward_max': -34.549179634175566,\n",
       "  'episode_reward_min': -118.76138410679755,\n",
       "  'episode_reward_mean': -68.11766933623122,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-66.73578144296758,\n",
       "    -75.89568431459817,\n",
       "    -65.69553343872931,\n",
       "    -104.32287194170316,\n",
       "    -70.83758133190183,\n",
       "    -68.15631769830115,\n",
       "    -71.61151847234898,\n",
       "    -70.7796211278556,\n",
       "    -74.77766360569721,\n",
       "    -71.88834127507447,\n",
       "    -69.3925568348154,\n",
       "    -66.7618756879469,\n",
       "    -66.43866828598402,\n",
       "    -34.549179634175566,\n",
       "    -68.65198003169708,\n",
       "    -57.77588011512671,\n",
       "    -66.91606501786217,\n",
       "    -65.15738974549537,\n",
       "    -56.01095004662453,\n",
       "    -67.01812250945291,\n",
       "    -96.95021108450162,\n",
       "    -63.88196741930619,\n",
       "    -75.07623285260196,\n",
       "    -70.54036505961729,\n",
       "    -70.91991869244765,\n",
       "    -73.63870515733531,\n",
       "    -74.69410324943924,\n",
       "    -56.20110215797976,\n",
       "    -70.94143283550702,\n",
       "    -74.46559865393965,\n",
       "    -37.90696713620425,\n",
       "    -97.11807401482625,\n",
       "    -67.28465395384589,\n",
       "    -58.09257751126385,\n",
       "    -41.417265676140495,\n",
       "    -71.5908118888191,\n",
       "    -58.861463183941325,\n",
       "    -66.08616636973147,\n",
       "    -67.81963689311411,\n",
       "    -63.77983829718602,\n",
       "    -70.6170446850291,\n",
       "    -74.74217386014384,\n",
       "    -76.15483327909932,\n",
       "    -118.76138410679755,\n",
       "    -76.9759454210475,\n",
       "    -63.65308669186759,\n",
       "    -52.885917579268664,\n",
       "    -38.77679018388243,\n",
       "    -106.44830662987083,\n",
       "    -35.66860863643257,\n",
       "    -72.01686453878696,\n",
       "    -50.36872601748615,\n",
       "    -39.10320229926052,\n",
       "    -106.99665495863121,\n",
       "    -78.21024098881396,\n",
       "    -70.3425916547193,\n",
       "    -64.69962330113911,\n",
       "    -59.1825686718565,\n",
       "    -65.48189473194178,\n",
       "    -59.09276024403545,\n",
       "    -64.22737147540353,\n",
       "    -73.25183929806072,\n",
       "    -61.34879014719493,\n",
       "    -72.04217892894854,\n",
       "    -82.54314969700306,\n",
       "    -87.29737287639229,\n",
       "    -67.7184725972568,\n",
       "    -63.106422041409914,\n",
       "    -88.59465729368308,\n",
       "    -59.09839952404819,\n",
       "    -62.233786618282494,\n",
       "    -110.02770530547065,\n",
       "    -52.22777344629228,\n",
       "    -69.45316734016465,\n",
       "    -99.6696367400076,\n",
       "    -70.76344497273081,\n",
       "    -70.14459023323086,\n",
       "    -75.42466421279204,\n",
       "    -67.00461710379545,\n",
       "    -55.44578996826647,\n",
       "    -50.45708876041607,\n",
       "    -67.01252784670129,\n",
       "    -75.63738732598644,\n",
       "    -64.42745969663187,\n",
       "    -85.34560069369586,\n",
       "    -78.15016492610768,\n",
       "    -52.8194653288415,\n",
       "    -55.387306966725184,\n",
       "    -38.383051770238865,\n",
       "    -52.2799619097662,\n",
       "    -62.28664652419363,\n",
       "    -70.24124027324179,\n",
       "    -72.35418803132035,\n",
       "    -39.62223706366056,\n",
       "    -68.89721872878235,\n",
       "    -63.884626384864006,\n",
       "    -70.7578872413635,\n",
       "    -70.10087893748005,\n",
       "    -66.54871339329364,\n",
       "    -58.72955887316037],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.21864418904549787,\n",
       "   'mean_inference_ms': 0.5570845377988111,\n",
       "   'mean_action_processing_ms': 0.07382752153484211,\n",
       "   'mean_env_wait_ms': 1.1855912546443976,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 22500,\n",
       "  'agent_timesteps_total': 22500,\n",
       "  'timers': {'learn_time_ms': 1.46, 'learn_throughput': 68482.905},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -9.326554,\n",
       "     'max_q': -1.4463403,\n",
       "     'min_q': -17.036655,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 22500,\n",
       "   'num_agent_steps_sampled': 22500,\n",
       "   'num_steps_trained': 2100100,\n",
       "   'num_agent_steps_trained': 2100100,\n",
       "   'last_target_update_ts': 22500,\n",
       "   'num_target_updates': 21001},\n",
       "  'done': False,\n",
       "  'episodes_total': 222,\n",
       "  'training_iteration': 15,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-55-32',\n",
       "  'timestamp': 1625500532,\n",
       "  'time_this_iter_s': 19.88166379928589,\n",
       "  'time_total_s': 275.1871588230133,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 275.1871588230133,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 15,\n",
       "  'perf': {'cpu_util_percent': 12.642307692307694,\n",
       "   'ram_util_percent': 49.892307692307696,\n",
       "   'gpu_util_percent0': 0.19153846153846155,\n",
       "   'vram_util_percent0': 0.5324528450327479}},\n",
       " {'episode_reward_max': -35.66860863643257,\n",
       "  'episode_reward_min': -118.76138410679755,\n",
       "  'episode_reward_mean': -67.72816474275787,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-57.77588011512671,\n",
       "    -66.91606501786217,\n",
       "    -65.15738974549537,\n",
       "    -56.01095004662453,\n",
       "    -67.01812250945291,\n",
       "    -96.95021108450162,\n",
       "    -63.88196741930619,\n",
       "    -75.07623285260196,\n",
       "    -70.54036505961729,\n",
       "    -70.91991869244765,\n",
       "    -73.63870515733531,\n",
       "    -74.69410324943924,\n",
       "    -56.20110215797976,\n",
       "    -70.94143283550702,\n",
       "    -74.46559865393965,\n",
       "    -37.90696713620425,\n",
       "    -97.11807401482625,\n",
       "    -67.28465395384589,\n",
       "    -58.09257751126385,\n",
       "    -41.417265676140495,\n",
       "    -71.5908118888191,\n",
       "    -58.861463183941325,\n",
       "    -66.08616636973147,\n",
       "    -67.81963689311411,\n",
       "    -63.77983829718602,\n",
       "    -70.6170446850291,\n",
       "    -74.74217386014384,\n",
       "    -76.15483327909932,\n",
       "    -118.76138410679755,\n",
       "    -76.9759454210475,\n",
       "    -63.65308669186759,\n",
       "    -52.885917579268664,\n",
       "    -38.77679018388243,\n",
       "    -106.44830662987083,\n",
       "    -35.66860863643257,\n",
       "    -72.01686453878696,\n",
       "    -50.36872601748615,\n",
       "    -39.10320229926052,\n",
       "    -106.99665495863121,\n",
       "    -78.21024098881396,\n",
       "    -70.3425916547193,\n",
       "    -64.69962330113911,\n",
       "    -59.1825686718565,\n",
       "    -65.48189473194178,\n",
       "    -59.09276024403545,\n",
       "    -64.22737147540353,\n",
       "    -73.25183929806072,\n",
       "    -61.34879014719493,\n",
       "    -72.04217892894854,\n",
       "    -82.54314969700306,\n",
       "    -87.29737287639229,\n",
       "    -67.7184725972568,\n",
       "    -63.106422041409914,\n",
       "    -88.59465729368308,\n",
       "    -59.09839952404819,\n",
       "    -62.233786618282494,\n",
       "    -110.02770530547065,\n",
       "    -52.22777344629228,\n",
       "    -69.45316734016465,\n",
       "    -99.6696367400076,\n",
       "    -70.76344497273081,\n",
       "    -70.14459023323086,\n",
       "    -75.42466421279204,\n",
       "    -67.00461710379545,\n",
       "    -55.44578996826647,\n",
       "    -50.45708876041607,\n",
       "    -67.01252784670129,\n",
       "    -75.63738732598644,\n",
       "    -64.42745969663187,\n",
       "    -85.34560069369586,\n",
       "    -78.15016492610768,\n",
       "    -52.8194653288415,\n",
       "    -55.387306966725184,\n",
       "    -38.383051770238865,\n",
       "    -52.2799619097662,\n",
       "    -62.28664652419363,\n",
       "    -70.24124027324179,\n",
       "    -72.35418803132035,\n",
       "    -39.62223706366056,\n",
       "    -68.89721872878235,\n",
       "    -63.884626384864006,\n",
       "    -70.7578872413635,\n",
       "    -70.10087893748005,\n",
       "    -66.54871339329364,\n",
       "    -58.72955887316037,\n",
       "    -67.1307938854297,\n",
       "    -71.58306691795929,\n",
       "    -70.34208429770815,\n",
       "    -89.93152028415778,\n",
       "    -62.07151600752413,\n",
       "    -56.59348476604737,\n",
       "    -70.67982774366462,\n",
       "    -51.0426002602183,\n",
       "    -86.0226617149838,\n",
       "    -64.97036080677353,\n",
       "    -57.33620793618172,\n",
       "    -45.62032405180535,\n",
       "    -85.52772675173995,\n",
       "    -71.3340372510032,\n",
       "    -57.35850310126454],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2189295842129571,\n",
       "   'mean_inference_ms': 0.5572722577396223,\n",
       "   'mean_action_processing_ms': 0.07409056668393706,\n",
       "   'mean_env_wait_ms': 1.1892768768092732,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 24000,\n",
       "  'agent_timesteps_total': 24000,\n",
       "  'timers': {'learn_time_ms': 1.568, 'learn_throughput': 63770.358},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -10.202113,\n",
       "     'max_q': -2.055935,\n",
       "     'min_q': -17.631538,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 24000,\n",
       "   'num_agent_steps_sampled': 24000,\n",
       "   'num_steps_trained': 2250100,\n",
       "   'num_agent_steps_trained': 2250100,\n",
       "   'last_target_update_ts': 24000,\n",
       "   'num_target_updates': 22501},\n",
       "  'done': False,\n",
       "  'episodes_total': 237,\n",
       "  'training_iteration': 16,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-55-51',\n",
       "  'timestamp': 1625500551,\n",
       "  'time_this_iter_s': 19.58697533607483,\n",
       "  'time_total_s': 294.77413415908813,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 294.77413415908813,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 16,\n",
       "  'perf': {'cpu_util_percent': 12.970370370370372,\n",
       "   'ram_util_percent': 49.99629629629629,\n",
       "   'gpu_util_percent0': 0.21333333333333335,\n",
       "   'vram_util_percent0': 0.526151311116793}},\n",
       " {'episode_reward_max': -35.66860863643257,\n",
       "  'episode_reward_min': -118.76138410679755,\n",
       "  'episode_reward_mean': -67.78768614164807,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-37.90696713620425,\n",
       "    -97.11807401482625,\n",
       "    -67.28465395384589,\n",
       "    -58.09257751126385,\n",
       "    -41.417265676140495,\n",
       "    -71.5908118888191,\n",
       "    -58.861463183941325,\n",
       "    -66.08616636973147,\n",
       "    -67.81963689311411,\n",
       "    -63.77983829718602,\n",
       "    -70.6170446850291,\n",
       "    -74.74217386014384,\n",
       "    -76.15483327909932,\n",
       "    -118.76138410679755,\n",
       "    -76.9759454210475,\n",
       "    -63.65308669186759,\n",
       "    -52.885917579268664,\n",
       "    -38.77679018388243,\n",
       "    -106.44830662987083,\n",
       "    -35.66860863643257,\n",
       "    -72.01686453878696,\n",
       "    -50.36872601748615,\n",
       "    -39.10320229926052,\n",
       "    -106.99665495863121,\n",
       "    -78.21024098881396,\n",
       "    -70.3425916547193,\n",
       "    -64.69962330113911,\n",
       "    -59.1825686718565,\n",
       "    -65.48189473194178,\n",
       "    -59.09276024403545,\n",
       "    -64.22737147540353,\n",
       "    -73.25183929806072,\n",
       "    -61.34879014719493,\n",
       "    -72.04217892894854,\n",
       "    -82.54314969700306,\n",
       "    -87.29737287639229,\n",
       "    -67.7184725972568,\n",
       "    -63.106422041409914,\n",
       "    -88.59465729368308,\n",
       "    -59.09839952404819,\n",
       "    -62.233786618282494,\n",
       "    -110.02770530547065,\n",
       "    -52.22777344629228,\n",
       "    -69.45316734016465,\n",
       "    -99.6696367400076,\n",
       "    -70.76344497273081,\n",
       "    -70.14459023323086,\n",
       "    -75.42466421279204,\n",
       "    -67.00461710379545,\n",
       "    -55.44578996826647,\n",
       "    -50.45708876041607,\n",
       "    -67.01252784670129,\n",
       "    -75.63738732598644,\n",
       "    -64.42745969663187,\n",
       "    -85.34560069369586,\n",
       "    -78.15016492610768,\n",
       "    -52.8194653288415,\n",
       "    -55.387306966725184,\n",
       "    -38.383051770238865,\n",
       "    -52.2799619097662,\n",
       "    -62.28664652419363,\n",
       "    -70.24124027324179,\n",
       "    -72.35418803132035,\n",
       "    -39.62223706366056,\n",
       "    -68.89721872878235,\n",
       "    -63.884626384864006,\n",
       "    -70.7578872413635,\n",
       "    -70.10087893748005,\n",
       "    -66.54871339329364,\n",
       "    -58.72955887316037,\n",
       "    -67.1307938854297,\n",
       "    -71.58306691795929,\n",
       "    -70.34208429770815,\n",
       "    -89.93152028415778,\n",
       "    -62.07151600752413,\n",
       "    -56.59348476604737,\n",
       "    -70.67982774366462,\n",
       "    -51.0426002602183,\n",
       "    -86.0226617149838,\n",
       "    -64.97036080677353,\n",
       "    -57.33620793618172,\n",
       "    -45.62032405180535,\n",
       "    -85.52772675173995,\n",
       "    -71.3340372510032,\n",
       "    -57.35850310126454,\n",
       "    -60.887367528519945,\n",
       "    -69.65582495468149,\n",
       "    -55.01680599733014,\n",
       "    -40.77399293741399,\n",
       "    -69.96145373674135,\n",
       "    -80.37118507050344,\n",
       "    -62.14108824852597,\n",
       "    -78.75182035563101,\n",
       "    -73.58699058578294,\n",
       "    -41.548956004610815,\n",
       "    -63.626540003119125,\n",
       "    -103.40874234968585,\n",
       "    -103.46218685693741,\n",
       "    -60.745432682730474,\n",
       "    -82.20179717404287],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2192410979595738,\n",
       "   'mean_inference_ms': 0.5578179474659102,\n",
       "   'mean_action_processing_ms': 0.07435799725277734,\n",
       "   'mean_env_wait_ms': 1.1901106046399645,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 25500,\n",
       "  'agent_timesteps_total': 25500,\n",
       "  'timers': {'learn_time_ms': 1.468, 'learn_throughput': 68138.021},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -9.761016,\n",
       "     'max_q': -1.3253467,\n",
       "     'min_q': -16.869648,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 25500,\n",
       "   'num_agent_steps_sampled': 25500,\n",
       "   'num_steps_trained': 2400100,\n",
       "   'num_agent_steps_trained': 2400100,\n",
       "   'last_target_update_ts': 25500,\n",
       "   'num_target_updates': 24001},\n",
       "  'done': False,\n",
       "  'episodes_total': 252,\n",
       "  'training_iteration': 17,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-56-12',\n",
       "  'timestamp': 1625500572,\n",
       "  'time_this_iter_s': 20.275004148483276,\n",
       "  'time_total_s': 315.0491383075714,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 315.0491383075714,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 17,\n",
       "  'perf': {'cpu_util_percent': 17.73333333333333,\n",
       "   'ram_util_percent': 50.22592592592592,\n",
       "   'gpu_util_percent0': 0.2396296296296296,\n",
       "   'vram_util_percent0': 0.5143138536132654}},\n",
       " {'episode_reward_max': -35.66860863643257,\n",
       "  'episode_reward_min': -116.19519670871938,\n",
       "  'episode_reward_mean': -67.93204786969395,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-63.65308669186759,\n",
       "    -52.885917579268664,\n",
       "    -38.77679018388243,\n",
       "    -106.44830662987083,\n",
       "    -35.66860863643257,\n",
       "    -72.01686453878696,\n",
       "    -50.36872601748615,\n",
       "    -39.10320229926052,\n",
       "    -106.99665495863121,\n",
       "    -78.21024098881396,\n",
       "    -70.3425916547193,\n",
       "    -64.69962330113911,\n",
       "    -59.1825686718565,\n",
       "    -65.48189473194178,\n",
       "    -59.09276024403545,\n",
       "    -64.22737147540353,\n",
       "    -73.25183929806072,\n",
       "    -61.34879014719493,\n",
       "    -72.04217892894854,\n",
       "    -82.54314969700306,\n",
       "    -87.29737287639229,\n",
       "    -67.7184725972568,\n",
       "    -63.106422041409914,\n",
       "    -88.59465729368308,\n",
       "    -59.09839952404819,\n",
       "    -62.233786618282494,\n",
       "    -110.02770530547065,\n",
       "    -52.22777344629228,\n",
       "    -69.45316734016465,\n",
       "    -99.6696367400076,\n",
       "    -70.76344497273081,\n",
       "    -70.14459023323086,\n",
       "    -75.42466421279204,\n",
       "    -67.00461710379545,\n",
       "    -55.44578996826647,\n",
       "    -50.45708876041607,\n",
       "    -67.01252784670129,\n",
       "    -75.63738732598644,\n",
       "    -64.42745969663187,\n",
       "    -85.34560069369586,\n",
       "    -78.15016492610768,\n",
       "    -52.8194653288415,\n",
       "    -55.387306966725184,\n",
       "    -38.383051770238865,\n",
       "    -52.2799619097662,\n",
       "    -62.28664652419363,\n",
       "    -70.24124027324179,\n",
       "    -72.35418803132035,\n",
       "    -39.62223706366056,\n",
       "    -68.89721872878235,\n",
       "    -63.884626384864006,\n",
       "    -70.7578872413635,\n",
       "    -70.10087893748005,\n",
       "    -66.54871339329364,\n",
       "    -58.72955887316037,\n",
       "    -67.1307938854297,\n",
       "    -71.58306691795929,\n",
       "    -70.34208429770815,\n",
       "    -89.93152028415778,\n",
       "    -62.07151600752413,\n",
       "    -56.59348476604737,\n",
       "    -70.67982774366462,\n",
       "    -51.0426002602183,\n",
       "    -86.0226617149838,\n",
       "    -64.97036080677353,\n",
       "    -57.33620793618172,\n",
       "    -45.62032405180535,\n",
       "    -85.52772675173995,\n",
       "    -71.3340372510032,\n",
       "    -57.35850310126454,\n",
       "    -60.887367528519945,\n",
       "    -69.65582495468149,\n",
       "    -55.01680599733014,\n",
       "    -40.77399293741399,\n",
       "    -69.96145373674135,\n",
       "    -80.37118507050344,\n",
       "    -62.14108824852597,\n",
       "    -78.75182035563101,\n",
       "    -73.58699058578294,\n",
       "    -41.548956004610815,\n",
       "    -63.626540003119125,\n",
       "    -103.40874234968585,\n",
       "    -103.46218685693741,\n",
       "    -60.745432682730474,\n",
       "    -82.20179717404287,\n",
       "    -89.49729001048385,\n",
       "    -68.00122385342013,\n",
       "    -48.137334934477956,\n",
       "    -81.95107471263228,\n",
       "    -37.91465152547477,\n",
       "    -56.93712265764696,\n",
       "    -62.614266976976936,\n",
       "    -72.6351249062669,\n",
       "    -116.19519670871938,\n",
       "    -87.31497450536578,\n",
       "    -84.96431194593714,\n",
       "    -48.66613155259949,\n",
       "    -68.39712790570374,\n",
       "    -64.90978125546798,\n",
       "    -73.50939563060376],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.21951989608895872,\n",
       "   'mean_inference_ms': 0.5584042776457914,\n",
       "   'mean_action_processing_ms': 0.0746105328477028,\n",
       "   'mean_env_wait_ms': 1.188503159800999,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 27000,\n",
       "  'agent_timesteps_total': 27000,\n",
       "  'timers': {'learn_time_ms': 1.509, 'learn_throughput': 66254.447},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -9.75196,\n",
       "     'max_q': -1.2566022,\n",
       "     'min_q': -17.46826,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 27000,\n",
       "   'num_agent_steps_sampled': 27000,\n",
       "   'num_steps_trained': 2550100,\n",
       "   'num_agent_steps_trained': 2550100,\n",
       "   'last_target_update_ts': 27000,\n",
       "   'num_target_updates': 25501},\n",
       "  'done': False,\n",
       "  'episodes_total': 267,\n",
       "  'training_iteration': 18,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-56-31',\n",
       "  'timestamp': 1625500591,\n",
       "  'time_this_iter_s': 19.39920997619629,\n",
       "  'time_total_s': 334.4483482837677,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 334.4483482837677,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 18,\n",
       "  'perf': {'cpu_util_percent': 12.946153846153845,\n",
       "   'ram_util_percent': 50.32692307692308,\n",
       "   'gpu_util_percent0': 0.1503846153846154,\n",
       "   'vram_util_percent0': 0.5173475207993234}},\n",
       " {'episode_reward_max': -37.91465152547477,\n",
       "  'episode_reward_min': -116.19519670871938,\n",
       "  'episode_reward_mean': -68.5220582361839,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-64.22737147540353,\n",
       "    -73.25183929806072,\n",
       "    -61.34879014719493,\n",
       "    -72.04217892894854,\n",
       "    -82.54314969700306,\n",
       "    -87.29737287639229,\n",
       "    -67.7184725972568,\n",
       "    -63.106422041409914,\n",
       "    -88.59465729368308,\n",
       "    -59.09839952404819,\n",
       "    -62.233786618282494,\n",
       "    -110.02770530547065,\n",
       "    -52.22777344629228,\n",
       "    -69.45316734016465,\n",
       "    -99.6696367400076,\n",
       "    -70.76344497273081,\n",
       "    -70.14459023323086,\n",
       "    -75.42466421279204,\n",
       "    -67.00461710379545,\n",
       "    -55.44578996826647,\n",
       "    -50.45708876041607,\n",
       "    -67.01252784670129,\n",
       "    -75.63738732598644,\n",
       "    -64.42745969663187,\n",
       "    -85.34560069369586,\n",
       "    -78.15016492610768,\n",
       "    -52.8194653288415,\n",
       "    -55.387306966725184,\n",
       "    -38.383051770238865,\n",
       "    -52.2799619097662,\n",
       "    -62.28664652419363,\n",
       "    -70.24124027324179,\n",
       "    -72.35418803132035,\n",
       "    -39.62223706366056,\n",
       "    -68.89721872878235,\n",
       "    -63.884626384864006,\n",
       "    -70.7578872413635,\n",
       "    -70.10087893748005,\n",
       "    -66.54871339329364,\n",
       "    -58.72955887316037,\n",
       "    -67.1307938854297,\n",
       "    -71.58306691795929,\n",
       "    -70.34208429770815,\n",
       "    -89.93152028415778,\n",
       "    -62.07151600752413,\n",
       "    -56.59348476604737,\n",
       "    -70.67982774366462,\n",
       "    -51.0426002602183,\n",
       "    -86.0226617149838,\n",
       "    -64.97036080677353,\n",
       "    -57.33620793618172,\n",
       "    -45.62032405180535,\n",
       "    -85.52772675173995,\n",
       "    -71.3340372510032,\n",
       "    -57.35850310126454,\n",
       "    -60.887367528519945,\n",
       "    -69.65582495468149,\n",
       "    -55.01680599733014,\n",
       "    -40.77399293741399,\n",
       "    -69.96145373674135,\n",
       "    -80.37118507050344,\n",
       "    -62.14108824852597,\n",
       "    -78.75182035563101,\n",
       "    -73.58699058578294,\n",
       "    -41.548956004610815,\n",
       "    -63.626540003119125,\n",
       "    -103.40874234968585,\n",
       "    -103.46218685693741,\n",
       "    -60.745432682730474,\n",
       "    -82.20179717404287,\n",
       "    -89.49729001048385,\n",
       "    -68.00122385342013,\n",
       "    -48.137334934477956,\n",
       "    -81.95107471263228,\n",
       "    -37.91465152547477,\n",
       "    -56.93712265764696,\n",
       "    -62.614266976976936,\n",
       "    -72.6351249062669,\n",
       "    -116.19519670871938,\n",
       "    -87.31497450536578,\n",
       "    -84.96431194593714,\n",
       "    -48.66613155259949,\n",
       "    -68.39712790570374,\n",
       "    -64.90978125546798,\n",
       "    -73.50939563060376,\n",
       "    -41.26425221487933,\n",
       "    -70.80641019714537,\n",
       "    -71.75321312246369,\n",
       "    -55.29155321040551,\n",
       "    -78.33525284226918,\n",
       "    -69.80004997109631,\n",
       "    -70.12387094693567,\n",
       "    -60.67384494295952,\n",
       "    -63.21331021155285,\n",
       "    -87.56204611011103,\n",
       "    -68.54527202320666,\n",
       "    -79.5162692430633,\n",
       "    -100.50280370023142,\n",
       "    -50.32069427873289,\n",
       "    -54.22003076193643],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.21977224800064182,\n",
       "   'mean_inference_ms': 0.5590968735548074,\n",
       "   'mean_action_processing_ms': 0.07483929641469234,\n",
       "   'mean_env_wait_ms': 1.1859202696737166,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 28500,\n",
       "  'agent_timesteps_total': 28500,\n",
       "  'timers': {'learn_time_ms': 1.456, 'learn_throughput': 68685.892},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -10.508972,\n",
       "     'max_q': -2.1511288,\n",
       "     'min_q': -17.494814,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 28500,\n",
       "   'num_agent_steps_sampled': 28500,\n",
       "   'num_steps_trained': 2700100,\n",
       "   'num_agent_steps_trained': 2700100,\n",
       "   'last_target_update_ts': 28500,\n",
       "   'num_target_updates': 27001},\n",
       "  'done': False,\n",
       "  'episodes_total': 282,\n",
       "  'training_iteration': 19,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-56-51',\n",
       "  'timestamp': 1625500611,\n",
       "  'time_this_iter_s': 19.512092113494873,\n",
       "  'time_total_s': 353.9604403972626,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 353.9604403972626,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 19,\n",
       "  'perf': {'cpu_util_percent': 13.076923076923078,\n",
       "   'ram_util_percent': 50.392307692307696,\n",
       "   'gpu_util_percent0': 0.1896153846153846,\n",
       "   'vram_util_percent0': 0.524467478315599}},\n",
       " {'episode_reward_max': -37.91465152547477,\n",
       "  'episode_reward_min': -116.19519670871938,\n",
       "  'episode_reward_mean': -67.78607873276506,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-70.76344497273081,\n",
       "    -70.14459023323086,\n",
       "    -75.42466421279204,\n",
       "    -67.00461710379545,\n",
       "    -55.44578996826647,\n",
       "    -50.45708876041607,\n",
       "    -67.01252784670129,\n",
       "    -75.63738732598644,\n",
       "    -64.42745969663187,\n",
       "    -85.34560069369586,\n",
       "    -78.15016492610768,\n",
       "    -52.8194653288415,\n",
       "    -55.387306966725184,\n",
       "    -38.383051770238865,\n",
       "    -52.2799619097662,\n",
       "    -62.28664652419363,\n",
       "    -70.24124027324179,\n",
       "    -72.35418803132035,\n",
       "    -39.62223706366056,\n",
       "    -68.89721872878235,\n",
       "    -63.884626384864006,\n",
       "    -70.7578872413635,\n",
       "    -70.10087893748005,\n",
       "    -66.54871339329364,\n",
       "    -58.72955887316037,\n",
       "    -67.1307938854297,\n",
       "    -71.58306691795929,\n",
       "    -70.34208429770815,\n",
       "    -89.93152028415778,\n",
       "    -62.07151600752413,\n",
       "    -56.59348476604737,\n",
       "    -70.67982774366462,\n",
       "    -51.0426002602183,\n",
       "    -86.0226617149838,\n",
       "    -64.97036080677353,\n",
       "    -57.33620793618172,\n",
       "    -45.62032405180535,\n",
       "    -85.52772675173995,\n",
       "    -71.3340372510032,\n",
       "    -57.35850310126454,\n",
       "    -60.887367528519945,\n",
       "    -69.65582495468149,\n",
       "    -55.01680599733014,\n",
       "    -40.77399293741399,\n",
       "    -69.96145373674135,\n",
       "    -80.37118507050344,\n",
       "    -62.14108824852597,\n",
       "    -78.75182035563101,\n",
       "    -73.58699058578294,\n",
       "    -41.548956004610815,\n",
       "    -63.626540003119125,\n",
       "    -103.40874234968585,\n",
       "    -103.46218685693741,\n",
       "    -60.745432682730474,\n",
       "    -82.20179717404287,\n",
       "    -89.49729001048385,\n",
       "    -68.00122385342013,\n",
       "    -48.137334934477956,\n",
       "    -81.95107471263228,\n",
       "    -37.91465152547477,\n",
       "    -56.93712265764696,\n",
       "    -62.614266976976936,\n",
       "    -72.6351249062669,\n",
       "    -116.19519670871938,\n",
       "    -87.31497450536578,\n",
       "    -84.96431194593714,\n",
       "    -48.66613155259949,\n",
       "    -68.39712790570374,\n",
       "    -64.90978125546798,\n",
       "    -73.50939563060376,\n",
       "    -41.26425221487933,\n",
       "    -70.80641019714537,\n",
       "    -71.75321312246369,\n",
       "    -55.29155321040551,\n",
       "    -78.33525284226918,\n",
       "    -69.80004997109631,\n",
       "    -70.12387094693567,\n",
       "    -60.67384494295952,\n",
       "    -63.21331021155285,\n",
       "    -87.56204611011103,\n",
       "    -68.54527202320666,\n",
       "    -79.5162692430633,\n",
       "    -100.50280370023142,\n",
       "    -50.32069427873289,\n",
       "    -54.22003076193643,\n",
       "    -72.24383771784132,\n",
       "    -38.97990702940442,\n",
       "    -69.48422834787807,\n",
       "    -72.38356854246933,\n",
       "    -81.32813813794795,\n",
       "    -67.25557767750608,\n",
       "    -64.6007553052858,\n",
       "    -62.741261211389634,\n",
       "    -55.10919899121017,\n",
       "    -91.77539362677413,\n",
       "    -68.80075108096042,\n",
       "    -90.69397568012229,\n",
       "    -74.31127214422732,\n",
       "    -64.59162354219791,\n",
       "    -64.94328395251974],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.21998528333968637,\n",
       "   'mean_inference_ms': 0.5596421446698787,\n",
       "   'mean_action_processing_ms': 0.07502840550142814,\n",
       "   'mean_env_wait_ms': 1.1810861229335257,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 30000,\n",
       "  'agent_timesteps_total': 30000,\n",
       "  'timers': {'learn_time_ms': 1.373, 'learn_throughput': 72822.835},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -11.011707,\n",
       "     'max_q': -0.7072208,\n",
       "     'min_q': -18.354786,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 30000,\n",
       "   'num_agent_steps_sampled': 30000,\n",
       "   'num_steps_trained': 2850100,\n",
       "   'num_agent_steps_trained': 2850100,\n",
       "   'last_target_update_ts': 30000,\n",
       "   'num_target_updates': 28501},\n",
       "  'done': False,\n",
       "  'episodes_total': 297,\n",
       "  'training_iteration': 20,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-57-10',\n",
       "  'timestamp': 1625500630,\n",
       "  'time_this_iter_s': 19.356003522872925,\n",
       "  'time_total_s': 373.3164439201355,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 373.3164439201355,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 20,\n",
       "  'perf': {'cpu_util_percent': 12.50769230769231,\n",
       "   'ram_util_percent': 50.43076923076923,\n",
       "   'gpu_util_percent0': 0.16038461538461538,\n",
       "   'vram_util_percent0': 0.5262376334992034}},\n",
       " {'episode_reward_max': -37.91465152547477,\n",
       "  'episode_reward_min': -116.19519670871938,\n",
       "  'episode_reward_mean': -68.30671152544224,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 14,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-52.2799619097662,\n",
       "    -62.28664652419363,\n",
       "    -70.24124027324179,\n",
       "    -72.35418803132035,\n",
       "    -39.62223706366056,\n",
       "    -68.89721872878235,\n",
       "    -63.884626384864006,\n",
       "    -70.7578872413635,\n",
       "    -70.10087893748005,\n",
       "    -66.54871339329364,\n",
       "    -58.72955887316037,\n",
       "    -67.1307938854297,\n",
       "    -71.58306691795929,\n",
       "    -70.34208429770815,\n",
       "    -89.93152028415778,\n",
       "    -62.07151600752413,\n",
       "    -56.59348476604737,\n",
       "    -70.67982774366462,\n",
       "    -51.0426002602183,\n",
       "    -86.0226617149838,\n",
       "    -64.97036080677353,\n",
       "    -57.33620793618172,\n",
       "    -45.62032405180535,\n",
       "    -85.52772675173995,\n",
       "    -71.3340372510032,\n",
       "    -57.35850310126454,\n",
       "    -60.887367528519945,\n",
       "    -69.65582495468149,\n",
       "    -55.01680599733014,\n",
       "    -40.77399293741399,\n",
       "    -69.96145373674135,\n",
       "    -80.37118507050344,\n",
       "    -62.14108824852597,\n",
       "    -78.75182035563101,\n",
       "    -73.58699058578294,\n",
       "    -41.548956004610815,\n",
       "    -63.626540003119125,\n",
       "    -103.40874234968585,\n",
       "    -103.46218685693741,\n",
       "    -60.745432682730474,\n",
       "    -82.20179717404287,\n",
       "    -89.49729001048385,\n",
       "    -68.00122385342013,\n",
       "    -48.137334934477956,\n",
       "    -81.95107471263228,\n",
       "    -37.91465152547477,\n",
       "    -56.93712265764696,\n",
       "    -62.614266976976936,\n",
       "    -72.6351249062669,\n",
       "    -116.19519670871938,\n",
       "    -87.31497450536578,\n",
       "    -84.96431194593714,\n",
       "    -48.66613155259949,\n",
       "    -68.39712790570374,\n",
       "    -64.90978125546798,\n",
       "    -73.50939563060376,\n",
       "    -41.26425221487933,\n",
       "    -70.80641019714537,\n",
       "    -71.75321312246369,\n",
       "    -55.29155321040551,\n",
       "    -78.33525284226918,\n",
       "    -69.80004997109631,\n",
       "    -70.12387094693567,\n",
       "    -60.67384494295952,\n",
       "    -63.21331021155285,\n",
       "    -87.56204611011103,\n",
       "    -68.54527202320666,\n",
       "    -79.5162692430633,\n",
       "    -100.50280370023142,\n",
       "    -50.32069427873289,\n",
       "    -54.22003076193643,\n",
       "    -72.24383771784132,\n",
       "    -38.97990702940442,\n",
       "    -69.48422834787807,\n",
       "    -72.38356854246933,\n",
       "    -81.32813813794795,\n",
       "    -67.25557767750608,\n",
       "    -64.6007553052858,\n",
       "    -62.741261211389634,\n",
       "    -55.10919899121017,\n",
       "    -91.77539362677413,\n",
       "    -68.80075108096042,\n",
       "    -90.69397568012229,\n",
       "    -74.31127214422732,\n",
       "    -64.59162354219791,\n",
       "    -64.94328395251974,\n",
       "    -63.51772359584422,\n",
       "    -50.09000778506741,\n",
       "    -65.22900711503976,\n",
       "    -69.47731320498292,\n",
       "    -65.64854741257892,\n",
       "    -65.2133223836005,\n",
       "    -67.55985797059661,\n",
       "    -69.92768957665172,\n",
       "    -89.67228025118274,\n",
       "    -69.56413403459243,\n",
       "    -67.58931972670496,\n",
       "    -69.3586384307536,\n",
       "    -70.66838860574623,\n",
       "    -74.95020898053548],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2201443039889407,\n",
       "   'mean_inference_ms': 0.5601048044620929,\n",
       "   'mean_action_processing_ms': 0.07517472833990432,\n",
       "   'mean_env_wait_ms': 1.175540093143303,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 31500,\n",
       "  'agent_timesteps_total': 31500,\n",
       "  'timers': {'learn_time_ms': 1.504, 'learn_throughput': 66476.012},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -10.6693,\n",
       "     'max_q': -1.8540452,\n",
       "     'min_q': -19.132662,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 31500,\n",
       "   'num_agent_steps_sampled': 31500,\n",
       "   'num_steps_trained': 3000100,\n",
       "   'num_agent_steps_trained': 3000100,\n",
       "   'last_target_update_ts': 31500,\n",
       "   'num_target_updates': 30001},\n",
       "  'done': False,\n",
       "  'episodes_total': 311,\n",
       "  'training_iteration': 21,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-57-30',\n",
       "  'timestamp': 1625500650,\n",
       "  'time_this_iter_s': 19.96198320388794,\n",
       "  'time_total_s': 393.27842712402344,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 393.27842712402344,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 21,\n",
       "  'perf': {'cpu_util_percent': 13.040740740740741,\n",
       "   'ram_util_percent': 50.65185185185185,\n",
       "   'gpu_util_percent0': 0.1737037037037037,\n",
       "   'vram_util_percent0': 0.5180166103203688}},\n",
       " {'episode_reward_max': -37.91465152547477,\n",
       "  'episode_reward_min': -116.19519670871938,\n",
       "  'episode_reward_mean': -68.61772951369343,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-62.07151600752413,\n",
       "    -56.59348476604737,\n",
       "    -70.67982774366462,\n",
       "    -51.0426002602183,\n",
       "    -86.0226617149838,\n",
       "    -64.97036080677353,\n",
       "    -57.33620793618172,\n",
       "    -45.62032405180535,\n",
       "    -85.52772675173995,\n",
       "    -71.3340372510032,\n",
       "    -57.35850310126454,\n",
       "    -60.887367528519945,\n",
       "    -69.65582495468149,\n",
       "    -55.01680599733014,\n",
       "    -40.77399293741399,\n",
       "    -69.96145373674135,\n",
       "    -80.37118507050344,\n",
       "    -62.14108824852597,\n",
       "    -78.75182035563101,\n",
       "    -73.58699058578294,\n",
       "    -41.548956004610815,\n",
       "    -63.626540003119125,\n",
       "    -103.40874234968585,\n",
       "    -103.46218685693741,\n",
       "    -60.745432682730474,\n",
       "    -82.20179717404287,\n",
       "    -89.49729001048385,\n",
       "    -68.00122385342013,\n",
       "    -48.137334934477956,\n",
       "    -81.95107471263228,\n",
       "    -37.91465152547477,\n",
       "    -56.93712265764696,\n",
       "    -62.614266976976936,\n",
       "    -72.6351249062669,\n",
       "    -116.19519670871938,\n",
       "    -87.31497450536578,\n",
       "    -84.96431194593714,\n",
       "    -48.66613155259949,\n",
       "    -68.39712790570374,\n",
       "    -64.90978125546798,\n",
       "    -73.50939563060376,\n",
       "    -41.26425221487933,\n",
       "    -70.80641019714537,\n",
       "    -71.75321312246369,\n",
       "    -55.29155321040551,\n",
       "    -78.33525284226918,\n",
       "    -69.80004997109631,\n",
       "    -70.12387094693567,\n",
       "    -60.67384494295952,\n",
       "    -63.21331021155285,\n",
       "    -87.56204611011103,\n",
       "    -68.54527202320666,\n",
       "    -79.5162692430633,\n",
       "    -100.50280370023142,\n",
       "    -50.32069427873289,\n",
       "    -54.22003076193643,\n",
       "    -72.24383771784132,\n",
       "    -38.97990702940442,\n",
       "    -69.48422834787807,\n",
       "    -72.38356854246933,\n",
       "    -81.32813813794795,\n",
       "    -67.25557767750608,\n",
       "    -64.6007553052858,\n",
       "    -62.741261211389634,\n",
       "    -55.10919899121017,\n",
       "    -91.77539362677413,\n",
       "    -68.80075108096042,\n",
       "    -90.69397568012229,\n",
       "    -74.31127214422732,\n",
       "    -64.59162354219791,\n",
       "    -64.94328395251974,\n",
       "    -63.51772359584422,\n",
       "    -50.09000778506741,\n",
       "    -65.22900711503976,\n",
       "    -69.47731320498292,\n",
       "    -65.64854741257892,\n",
       "    -65.2133223836005,\n",
       "    -67.55985797059661,\n",
       "    -69.92768957665172,\n",
       "    -89.67228025118274,\n",
       "    -69.56413403459243,\n",
       "    -67.58931972670496,\n",
       "    -69.3586384307536,\n",
       "    -70.66838860574623,\n",
       "    -74.95020898053548,\n",
       "    -88.34033585464056,\n",
       "    -63.04945393020515,\n",
       "    -67.574061190445,\n",
       "    -58.85477036323803,\n",
       "    -63.76097690405362,\n",
       "    -62.54609004022629,\n",
       "    -63.55935832452537,\n",
       "    -60.91127700607122,\n",
       "    -85.4982347568673,\n",
       "    -63.93225777111339,\n",
       "    -64.13113231909614,\n",
       "    -81.01255003003625,\n",
       "    -72.93816885240457,\n",
       "    -67.33673661374485,\n",
       "    -62.34701761483378],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2202950907975202,\n",
       "   'mean_inference_ms': 0.5605458201414727,\n",
       "   'mean_action_processing_ms': 0.07530124273254554,\n",
       "   'mean_env_wait_ms': 1.1686343384087123,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 33000,\n",
       "  'agent_timesteps_total': 33000,\n",
       "  'timers': {'learn_time_ms': 1.609, 'learn_throughput': 62166.388},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -10.539846,\n",
       "     'max_q': -2.4499004,\n",
       "     'min_q': -19.159216,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 33000,\n",
       "   'num_agent_steps_sampled': 33000,\n",
       "   'num_steps_trained': 3150100,\n",
       "   'num_agent_steps_trained': 3150100,\n",
       "   'last_target_update_ts': 33000,\n",
       "   'num_target_updates': 31501},\n",
       "  'done': False,\n",
       "  'episodes_total': 326,\n",
       "  'training_iteration': 22,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-57-50',\n",
       "  'timestamp': 1625500670,\n",
       "  'time_this_iter_s': 19.677824020385742,\n",
       "  'time_total_s': 412.9562511444092,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 412.9562511444092,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 22,\n",
       "  'perf': {'cpu_util_percent': 12.52222222222222,\n",
       "   'ram_util_percent': 50.67407407407407,\n",
       "   'gpu_util_percent0': 0.14222222222222222,\n",
       "   'vram_util_percent0': 0.5171074935840981}},\n",
       " {'episode_reward_max': -37.91465152547477,\n",
       "  'episode_reward_min': -116.19519670871938,\n",
       "  'episode_reward_mean': -69.22126478682567,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-69.96145373674135,\n",
       "    -80.37118507050344,\n",
       "    -62.14108824852597,\n",
       "    -78.75182035563101,\n",
       "    -73.58699058578294,\n",
       "    -41.548956004610815,\n",
       "    -63.626540003119125,\n",
       "    -103.40874234968585,\n",
       "    -103.46218685693741,\n",
       "    -60.745432682730474,\n",
       "    -82.20179717404287,\n",
       "    -89.49729001048385,\n",
       "    -68.00122385342013,\n",
       "    -48.137334934477956,\n",
       "    -81.95107471263228,\n",
       "    -37.91465152547477,\n",
       "    -56.93712265764696,\n",
       "    -62.614266976976936,\n",
       "    -72.6351249062669,\n",
       "    -116.19519670871938,\n",
       "    -87.31497450536578,\n",
       "    -84.96431194593714,\n",
       "    -48.66613155259949,\n",
       "    -68.39712790570374,\n",
       "    -64.90978125546798,\n",
       "    -73.50939563060376,\n",
       "    -41.26425221487933,\n",
       "    -70.80641019714537,\n",
       "    -71.75321312246369,\n",
       "    -55.29155321040551,\n",
       "    -78.33525284226918,\n",
       "    -69.80004997109631,\n",
       "    -70.12387094693567,\n",
       "    -60.67384494295952,\n",
       "    -63.21331021155285,\n",
       "    -87.56204611011103,\n",
       "    -68.54527202320666,\n",
       "    -79.5162692430633,\n",
       "    -100.50280370023142,\n",
       "    -50.32069427873289,\n",
       "    -54.22003076193643,\n",
       "    -72.24383771784132,\n",
       "    -38.97990702940442,\n",
       "    -69.48422834787807,\n",
       "    -72.38356854246933,\n",
       "    -81.32813813794795,\n",
       "    -67.25557767750608,\n",
       "    -64.6007553052858,\n",
       "    -62.741261211389634,\n",
       "    -55.10919899121017,\n",
       "    -91.77539362677413,\n",
       "    -68.80075108096042,\n",
       "    -90.69397568012229,\n",
       "    -74.31127214422732,\n",
       "    -64.59162354219791,\n",
       "    -64.94328395251974,\n",
       "    -63.51772359584422,\n",
       "    -50.09000778506741,\n",
       "    -65.22900711503976,\n",
       "    -69.47731320498292,\n",
       "    -65.64854741257892,\n",
       "    -65.2133223836005,\n",
       "    -67.55985797059661,\n",
       "    -69.92768957665172,\n",
       "    -89.67228025118274,\n",
       "    -69.56413403459243,\n",
       "    -67.58931972670496,\n",
       "    -69.3586384307536,\n",
       "    -70.66838860574623,\n",
       "    -74.95020898053548,\n",
       "    -88.34033585464056,\n",
       "    -63.04945393020515,\n",
       "    -67.574061190445,\n",
       "    -58.85477036323803,\n",
       "    -63.76097690405362,\n",
       "    -62.54609004022629,\n",
       "    -63.55935832452537,\n",
       "    -60.91127700607122,\n",
       "    -85.4982347568673,\n",
       "    -63.93225777111339,\n",
       "    -64.13113231909614,\n",
       "    -81.01255003003625,\n",
       "    -72.93816885240457,\n",
       "    -67.33673661374485,\n",
       "    -62.34701761483378,\n",
       "    -62.84535459890984,\n",
       "    -62.76123928186395,\n",
       "    -43.93859503950119,\n",
       "    -58.91835539092152,\n",
       "    -62.88219681964668,\n",
       "    -60.85170341020684,\n",
       "    -69.95711330401893,\n",
       "    -65.58809898254881,\n",
       "    -57.50777501023412,\n",
       "    -66.12200912418291,\n",
       "    -83.31906047652842,\n",
       "    -61.64301702755775,\n",
       "    -110.56071007622492,\n",
       "    -68.24220140493918,\n",
       "    -60.107339175091916],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22045667619606715,\n",
       "   'mean_inference_ms': 0.5610152268150234,\n",
       "   'mean_action_processing_ms': 0.07543333719887789,\n",
       "   'mean_env_wait_ms': 1.1622281079302843,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 34500,\n",
       "  'agent_timesteps_total': 34500,\n",
       "  'timers': {'learn_time_ms': 2.942, 'learn_throughput': 33990.324},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -11.677202,\n",
       "     'max_q': -1.9541545,\n",
       "     'min_q': -19.11046,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 34500,\n",
       "   'num_agent_steps_sampled': 34500,\n",
       "   'num_steps_trained': 3300100,\n",
       "   'num_agent_steps_trained': 3300100,\n",
       "   'last_target_update_ts': 34500,\n",
       "   'num_target_updates': 33001},\n",
       "  'done': False,\n",
       "  'episodes_total': 341,\n",
       "  'training_iteration': 23,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-58-10',\n",
       "  'timestamp': 1625500690,\n",
       "  'time_this_iter_s': 20.174495458602905,\n",
       "  'time_total_s': 433.1307466030121,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 433.1307466030121,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 23,\n",
       "  'perf': {'cpu_util_percent': 16.274074074074072,\n",
       "   'ram_util_percent': 47.66296296296296,\n",
       "   'gpu_util_percent0': 0.22925925925925927,\n",
       "   'vram_util_percent0': 0.5175431120202278}},\n",
       " {'episode_reward_max': -37.91465152547477,\n",
       "  'episode_reward_min': -116.19519670871938,\n",
       "  'episode_reward_mean': -68.76919486010914,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-37.91465152547477,\n",
       "    -56.93712265764696,\n",
       "    -62.614266976976936,\n",
       "    -72.6351249062669,\n",
       "    -116.19519670871938,\n",
       "    -87.31497450536578,\n",
       "    -84.96431194593714,\n",
       "    -48.66613155259949,\n",
       "    -68.39712790570374,\n",
       "    -64.90978125546798,\n",
       "    -73.50939563060376,\n",
       "    -41.26425221487933,\n",
       "    -70.80641019714537,\n",
       "    -71.75321312246369,\n",
       "    -55.29155321040551,\n",
       "    -78.33525284226918,\n",
       "    -69.80004997109631,\n",
       "    -70.12387094693567,\n",
       "    -60.67384494295952,\n",
       "    -63.21331021155285,\n",
       "    -87.56204611011103,\n",
       "    -68.54527202320666,\n",
       "    -79.5162692430633,\n",
       "    -100.50280370023142,\n",
       "    -50.32069427873289,\n",
       "    -54.22003076193643,\n",
       "    -72.24383771784132,\n",
       "    -38.97990702940442,\n",
       "    -69.48422834787807,\n",
       "    -72.38356854246933,\n",
       "    -81.32813813794795,\n",
       "    -67.25557767750608,\n",
       "    -64.6007553052858,\n",
       "    -62.741261211389634,\n",
       "    -55.10919899121017,\n",
       "    -91.77539362677413,\n",
       "    -68.80075108096042,\n",
       "    -90.69397568012229,\n",
       "    -74.31127214422732,\n",
       "    -64.59162354219791,\n",
       "    -64.94328395251974,\n",
       "    -63.51772359584422,\n",
       "    -50.09000778506741,\n",
       "    -65.22900711503976,\n",
       "    -69.47731320498292,\n",
       "    -65.64854741257892,\n",
       "    -65.2133223836005,\n",
       "    -67.55985797059661,\n",
       "    -69.92768957665172,\n",
       "    -89.67228025118274,\n",
       "    -69.56413403459243,\n",
       "    -67.58931972670496,\n",
       "    -69.3586384307536,\n",
       "    -70.66838860574623,\n",
       "    -74.95020898053548,\n",
       "    -88.34033585464056,\n",
       "    -63.04945393020515,\n",
       "    -67.574061190445,\n",
       "    -58.85477036323803,\n",
       "    -63.76097690405362,\n",
       "    -62.54609004022629,\n",
       "    -63.55935832452537,\n",
       "    -60.91127700607122,\n",
       "    -85.4982347568673,\n",
       "    -63.93225777111339,\n",
       "    -64.13113231909614,\n",
       "    -81.01255003003625,\n",
       "    -72.93816885240457,\n",
       "    -67.33673661374485,\n",
       "    -62.34701761483378,\n",
       "    -62.84535459890984,\n",
       "    -62.76123928186395,\n",
       "    -43.93859503950119,\n",
       "    -58.91835539092152,\n",
       "    -62.88219681964668,\n",
       "    -60.85170341020684,\n",
       "    -69.95711330401893,\n",
       "    -65.58809898254881,\n",
       "    -57.50777501023412,\n",
       "    -66.12200912418291,\n",
       "    -83.31906047652842,\n",
       "    -61.64301702755775,\n",
       "    -110.56071007622492,\n",
       "    -68.24220140493918,\n",
       "    -60.107339175091916,\n",
       "    -68.74368995539558,\n",
       "    -85.54737349056592,\n",
       "    -73.98076954076714,\n",
       "    -67.01066648118348,\n",
       "    -67.2571342450343,\n",
       "    -106.85804646044886,\n",
       "    -72.94431853460198,\n",
       "    -66.51549078160905,\n",
       "    -66.7512346123599,\n",
       "    -69.81445462151719,\n",
       "    -67.99732259674794,\n",
       "    -77.60340956825377,\n",
       "    -38.483153025240355,\n",
       "    -67.68672452706627,\n",
       "    -64.9923354668812],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22061219106104046,\n",
       "   'mean_inference_ms': 0.5615252288593067,\n",
       "   'mean_action_processing_ms': 0.07555802724097153,\n",
       "   'mean_env_wait_ms': 1.1569174413094694,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 36000,\n",
       "  'agent_timesteps_total': 36000,\n",
       "  'timers': {'learn_time_ms': 1.336, 'learn_throughput': 74876.892},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -10.931772,\n",
       "     'max_q': -2.6054878,\n",
       "     'min_q': -21.223835,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 36000,\n",
       "   'num_agent_steps_sampled': 36000,\n",
       "   'num_steps_trained': 3450100,\n",
       "   'num_agent_steps_trained': 3450100,\n",
       "   'last_target_update_ts': 36000,\n",
       "   'num_target_updates': 34501},\n",
       "  'done': False,\n",
       "  'episodes_total': 356,\n",
       "  'training_iteration': 24,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-58-30',\n",
       "  'timestamp': 1625500710,\n",
       "  'time_this_iter_s': 19.928709268569946,\n",
       "  'time_total_s': 453.05945587158203,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 453.05945587158203,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 24,\n",
       "  'perf': {'cpu_util_percent': 13.988461538461538,\n",
       "   'ram_util_percent': 45.30384615384614,\n",
       "   'gpu_util_percent0': 0.2107692307692308,\n",
       "   'vram_util_percent0': 0.5247231673976752}},\n",
       " {'episode_reward_max': -38.483153025240355,\n",
       "  'episode_reward_min': -110.56071007622492,\n",
       "  'episode_reward_mean': -69.08409990590623,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-78.33525284226918,\n",
       "    -69.80004997109631,\n",
       "    -70.12387094693567,\n",
       "    -60.67384494295952,\n",
       "    -63.21331021155285,\n",
       "    -87.56204611011103,\n",
       "    -68.54527202320666,\n",
       "    -79.5162692430633,\n",
       "    -100.50280370023142,\n",
       "    -50.32069427873289,\n",
       "    -54.22003076193643,\n",
       "    -72.24383771784132,\n",
       "    -38.97990702940442,\n",
       "    -69.48422834787807,\n",
       "    -72.38356854246933,\n",
       "    -81.32813813794795,\n",
       "    -67.25557767750608,\n",
       "    -64.6007553052858,\n",
       "    -62.741261211389634,\n",
       "    -55.10919899121017,\n",
       "    -91.77539362677413,\n",
       "    -68.80075108096042,\n",
       "    -90.69397568012229,\n",
       "    -74.31127214422732,\n",
       "    -64.59162354219791,\n",
       "    -64.94328395251974,\n",
       "    -63.51772359584422,\n",
       "    -50.09000778506741,\n",
       "    -65.22900711503976,\n",
       "    -69.47731320498292,\n",
       "    -65.64854741257892,\n",
       "    -65.2133223836005,\n",
       "    -67.55985797059661,\n",
       "    -69.92768957665172,\n",
       "    -89.67228025118274,\n",
       "    -69.56413403459243,\n",
       "    -67.58931972670496,\n",
       "    -69.3586384307536,\n",
       "    -70.66838860574623,\n",
       "    -74.95020898053548,\n",
       "    -88.34033585464056,\n",
       "    -63.04945393020515,\n",
       "    -67.574061190445,\n",
       "    -58.85477036323803,\n",
       "    -63.76097690405362,\n",
       "    -62.54609004022629,\n",
       "    -63.55935832452537,\n",
       "    -60.91127700607122,\n",
       "    -85.4982347568673,\n",
       "    -63.93225777111339,\n",
       "    -64.13113231909614,\n",
       "    -81.01255003003625,\n",
       "    -72.93816885240457,\n",
       "    -67.33673661374485,\n",
       "    -62.34701761483378,\n",
       "    -62.84535459890984,\n",
       "    -62.76123928186395,\n",
       "    -43.93859503950119,\n",
       "    -58.91835539092152,\n",
       "    -62.88219681964668,\n",
       "    -60.85170341020684,\n",
       "    -69.95711330401893,\n",
       "    -65.58809898254881,\n",
       "    -57.50777501023412,\n",
       "    -66.12200912418291,\n",
       "    -83.31906047652842,\n",
       "    -61.64301702755775,\n",
       "    -110.56071007622492,\n",
       "    -68.24220140493918,\n",
       "    -60.107339175091916,\n",
       "    -68.74368995539558,\n",
       "    -85.54737349056592,\n",
       "    -73.98076954076714,\n",
       "    -67.01066648118348,\n",
       "    -67.2571342450343,\n",
       "    -106.85804646044886,\n",
       "    -72.94431853460198,\n",
       "    -66.51549078160905,\n",
       "    -66.7512346123599,\n",
       "    -69.81445462151719,\n",
       "    -67.99732259674794,\n",
       "    -77.60340956825377,\n",
       "    -38.483153025240355,\n",
       "    -67.68672452706627,\n",
       "    -64.9923354668812,\n",
       "    -66.14170193567028,\n",
       "    -66.82097071970777,\n",
       "    -76.99143971919253,\n",
       "    -77.79119884046207,\n",
       "    -70.51528957462632,\n",
       "    -63.54469629798036,\n",
       "    -101.77125580945939,\n",
       "    -57.441416725722505,\n",
       "    -78.07055103812739,\n",
       "    -53.06749677684894,\n",
       "    -62.949120718434536,\n",
       "    -73.18073380938984,\n",
       "    -81.2650790399682,\n",
       "    -43.691070064211765,\n",
       "    -71.42199782556159],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22078132070870843,\n",
       "   'mean_inference_ms': 0.5620486304136789,\n",
       "   'mean_action_processing_ms': 0.0756859664119749,\n",
       "   'mean_env_wait_ms': 1.1528299110054854,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 37500,\n",
       "  'agent_timesteps_total': 37500,\n",
       "  'timers': {'learn_time_ms': 1.411, 'learn_throughput': 70874.871},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.025302,\n",
       "     'max_q': -2.7327626,\n",
       "     'min_q': -20.6042,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 37500,\n",
       "   'num_agent_steps_sampled': 37500,\n",
       "   'num_steps_trained': 3600100,\n",
       "   'num_agent_steps_trained': 3600100,\n",
       "   'last_target_update_ts': 37500,\n",
       "   'num_target_updates': 36001},\n",
       "  'done': False,\n",
       "  'episodes_total': 371,\n",
       "  'training_iteration': 25,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-58-50',\n",
       "  'timestamp': 1625500730,\n",
       "  'time_this_iter_s': 20.008182764053345,\n",
       "  'time_total_s': 473.0676386356354,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 473.0676386356354,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 25,\n",
       "  'perf': {'cpu_util_percent': 12.866666666666665,\n",
       "   'ram_util_percent': 45.344444444444434,\n",
       "   'gpu_util_percent0': 0.22851851851851854,\n",
       "   'vram_util_percent0': 0.5115296836084359}},\n",
       " {'episode_reward_max': -37.6925120278722,\n",
       "  'episode_reward_min': -110.56071007622492,\n",
       "  'episode_reward_mean': -68.47154028525219,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-81.32813813794795,\n",
       "    -67.25557767750608,\n",
       "    -64.6007553052858,\n",
       "    -62.741261211389634,\n",
       "    -55.10919899121017,\n",
       "    -91.77539362677413,\n",
       "    -68.80075108096042,\n",
       "    -90.69397568012229,\n",
       "    -74.31127214422732,\n",
       "    -64.59162354219791,\n",
       "    -64.94328395251974,\n",
       "    -63.51772359584422,\n",
       "    -50.09000778506741,\n",
       "    -65.22900711503976,\n",
       "    -69.47731320498292,\n",
       "    -65.64854741257892,\n",
       "    -65.2133223836005,\n",
       "    -67.55985797059661,\n",
       "    -69.92768957665172,\n",
       "    -89.67228025118274,\n",
       "    -69.56413403459243,\n",
       "    -67.58931972670496,\n",
       "    -69.3586384307536,\n",
       "    -70.66838860574623,\n",
       "    -74.95020898053548,\n",
       "    -88.34033585464056,\n",
       "    -63.04945393020515,\n",
       "    -67.574061190445,\n",
       "    -58.85477036323803,\n",
       "    -63.76097690405362,\n",
       "    -62.54609004022629,\n",
       "    -63.55935832452537,\n",
       "    -60.91127700607122,\n",
       "    -85.4982347568673,\n",
       "    -63.93225777111339,\n",
       "    -64.13113231909614,\n",
       "    -81.01255003003625,\n",
       "    -72.93816885240457,\n",
       "    -67.33673661374485,\n",
       "    -62.34701761483378,\n",
       "    -62.84535459890984,\n",
       "    -62.76123928186395,\n",
       "    -43.93859503950119,\n",
       "    -58.91835539092152,\n",
       "    -62.88219681964668,\n",
       "    -60.85170341020684,\n",
       "    -69.95711330401893,\n",
       "    -65.58809898254881,\n",
       "    -57.50777501023412,\n",
       "    -66.12200912418291,\n",
       "    -83.31906047652842,\n",
       "    -61.64301702755775,\n",
       "    -110.56071007622492,\n",
       "    -68.24220140493918,\n",
       "    -60.107339175091916,\n",
       "    -68.74368995539558,\n",
       "    -85.54737349056592,\n",
       "    -73.98076954076714,\n",
       "    -67.01066648118348,\n",
       "    -67.2571342450343,\n",
       "    -106.85804646044886,\n",
       "    -72.94431853460198,\n",
       "    -66.51549078160905,\n",
       "    -66.7512346123599,\n",
       "    -69.81445462151719,\n",
       "    -67.99732259674794,\n",
       "    -77.60340956825377,\n",
       "    -38.483153025240355,\n",
       "    -67.68672452706627,\n",
       "    -64.9923354668812,\n",
       "    -66.14170193567028,\n",
       "    -66.82097071970777,\n",
       "    -76.99143971919253,\n",
       "    -77.79119884046207,\n",
       "    -70.51528957462632,\n",
       "    -63.54469629798036,\n",
       "    -101.77125580945939,\n",
       "    -57.441416725722505,\n",
       "    -78.07055103812739,\n",
       "    -53.06749677684894,\n",
       "    -62.949120718434536,\n",
       "    -73.18073380938984,\n",
       "    -81.2650790399682,\n",
       "    -43.691070064211765,\n",
       "    -71.42199782556159,\n",
       "    -66.47713268456077,\n",
       "    -68.18449216448919,\n",
       "    -79.84544299503867,\n",
       "    -60.8652995956477,\n",
       "    -72.72501273952722,\n",
       "    -39.16322044849828,\n",
       "    -62.33497984969161,\n",
       "    -101.10260308936229,\n",
       "    -56.18313234944594,\n",
       "    -60.234580129968556,\n",
       "    -85.29380227215621,\n",
       "    -37.94895351216115,\n",
       "    -37.6925120278722,\n",
       "    -63.55394475497248,\n",
       "    -83.04391599089251],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2209384502060649,\n",
       "   'mean_inference_ms': 0.5623030231383233,\n",
       "   'mean_action_processing_ms': 0.07579668733422784,\n",
       "   'mean_env_wait_ms': 1.149635778113316,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 39000,\n",
       "  'agent_timesteps_total': 39000,\n",
       "  'timers': {'learn_time_ms': 1.513, 'learn_throughput': 66112.418},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.673753,\n",
       "     'max_q': -2.855202,\n",
       "     'min_q': -21.136524,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 39000,\n",
       "   'num_agent_steps_sampled': 39000,\n",
       "   'num_steps_trained': 3750100,\n",
       "   'num_agent_steps_trained': 3750100,\n",
       "   'last_target_update_ts': 39000,\n",
       "   'num_target_updates': 37501},\n",
       "  'done': False,\n",
       "  'episodes_total': 386,\n",
       "  'training_iteration': 26,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-59-09',\n",
       "  'timestamp': 1625500749,\n",
       "  'time_this_iter_s': 19.61254644393921,\n",
       "  'time_total_s': 492.6801850795746,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 492.6801850795746,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 26,\n",
       "  'perf': {'cpu_util_percent': 12.503846153846155,\n",
       "   'ram_util_percent': 45.45,\n",
       "   'gpu_util_percent0': 0.22692307692307695,\n",
       "   'vram_util_percent0': 0.5116731900163248}},\n",
       " {'episode_reward_max': -36.672992186962155,\n",
       "  'episode_reward_min': -110.56071007622492,\n",
       "  'episode_reward_mean': -68.40457850452079,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 14,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-69.47731320498292,\n",
       "    -65.64854741257892,\n",
       "    -65.2133223836005,\n",
       "    -67.55985797059661,\n",
       "    -69.92768957665172,\n",
       "    -89.67228025118274,\n",
       "    -69.56413403459243,\n",
       "    -67.58931972670496,\n",
       "    -69.3586384307536,\n",
       "    -70.66838860574623,\n",
       "    -74.95020898053548,\n",
       "    -88.34033585464056,\n",
       "    -63.04945393020515,\n",
       "    -67.574061190445,\n",
       "    -58.85477036323803,\n",
       "    -63.76097690405362,\n",
       "    -62.54609004022629,\n",
       "    -63.55935832452537,\n",
       "    -60.91127700607122,\n",
       "    -85.4982347568673,\n",
       "    -63.93225777111339,\n",
       "    -64.13113231909614,\n",
       "    -81.01255003003625,\n",
       "    -72.93816885240457,\n",
       "    -67.33673661374485,\n",
       "    -62.34701761483378,\n",
       "    -62.84535459890984,\n",
       "    -62.76123928186395,\n",
       "    -43.93859503950119,\n",
       "    -58.91835539092152,\n",
       "    -62.88219681964668,\n",
       "    -60.85170341020684,\n",
       "    -69.95711330401893,\n",
       "    -65.58809898254881,\n",
       "    -57.50777501023412,\n",
       "    -66.12200912418291,\n",
       "    -83.31906047652842,\n",
       "    -61.64301702755775,\n",
       "    -110.56071007622492,\n",
       "    -68.24220140493918,\n",
       "    -60.107339175091916,\n",
       "    -68.74368995539558,\n",
       "    -85.54737349056592,\n",
       "    -73.98076954076714,\n",
       "    -67.01066648118348,\n",
       "    -67.2571342450343,\n",
       "    -106.85804646044886,\n",
       "    -72.94431853460198,\n",
       "    -66.51549078160905,\n",
       "    -66.7512346123599,\n",
       "    -69.81445462151719,\n",
       "    -67.99732259674794,\n",
       "    -77.60340956825377,\n",
       "    -38.483153025240355,\n",
       "    -67.68672452706627,\n",
       "    -64.9923354668812,\n",
       "    -66.14170193567028,\n",
       "    -66.82097071970777,\n",
       "    -76.99143971919253,\n",
       "    -77.79119884046207,\n",
       "    -70.51528957462632,\n",
       "    -63.54469629798036,\n",
       "    -101.77125580945939,\n",
       "    -57.441416725722505,\n",
       "    -78.07055103812739,\n",
       "    -53.06749677684894,\n",
       "    -62.949120718434536,\n",
       "    -73.18073380938984,\n",
       "    -81.2650790399682,\n",
       "    -43.691070064211765,\n",
       "    -71.42199782556159,\n",
       "    -66.47713268456077,\n",
       "    -68.18449216448919,\n",
       "    -79.84544299503867,\n",
       "    -60.8652995956477,\n",
       "    -72.72501273952722,\n",
       "    -39.16322044849828,\n",
       "    -62.33497984969161,\n",
       "    -101.10260308936229,\n",
       "    -56.18313234944594,\n",
       "    -60.234580129968556,\n",
       "    -85.29380227215621,\n",
       "    -37.94895351216115,\n",
       "    -37.6925120278722,\n",
       "    -63.55394475497248,\n",
       "    -83.04391599089251,\n",
       "    -59.63341798405079,\n",
       "    -72.4526204497884,\n",
       "    -107.99519027940168,\n",
       "    -67.32517907975856,\n",
       "    -67.64036646677334,\n",
       "    -65.43567027773189,\n",
       "    -98.81495291876409,\n",
       "    -64.42090842727355,\n",
       "    -69.74783062990667,\n",
       "    -68.08692885896367,\n",
       "    -36.672992186962155,\n",
       "    -62.20381485974605,\n",
       "    -68.23679314346403,\n",
       "    -49.62512621036832],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22110050671561646,\n",
       "   'mean_inference_ms': 0.56248063674338,\n",
       "   'mean_action_processing_ms': 0.07590260826071578,\n",
       "   'mean_env_wait_ms': 1.1484420989624988,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 40500,\n",
       "  'agent_timesteps_total': 40500,\n",
       "  'timers': {'learn_time_ms': 1.567, 'learn_throughput': 63829.557},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -11.544419,\n",
       "     'max_q': -2.0913615,\n",
       "     'min_q': -22.936504,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 40500,\n",
       "   'num_agent_steps_sampled': 40500,\n",
       "   'num_steps_trained': 3900100,\n",
       "   'num_agent_steps_trained': 3900100,\n",
       "   'last_target_update_ts': 40500,\n",
       "   'num_target_updates': 39001},\n",
       "  'done': False,\n",
       "  'episodes_total': 400,\n",
       "  'training_iteration': 27,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-59-30',\n",
       "  'timestamp': 1625500770,\n",
       "  'time_this_iter_s': 20.272340059280396,\n",
       "  'time_total_s': 512.952525138855,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 512.952525138855,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 27,\n",
       "  'perf': {'cpu_util_percent': 12.799999999999997,\n",
       "   'ram_util_percent': 45.52592592592592,\n",
       "   'gpu_util_percent0': 0.20259259259259263,\n",
       "   'vram_util_percent0': 0.519181416138716}},\n",
       " {'episode_reward_max': -36.672992186962155,\n",
       "  'episode_reward_min': -110.56071007622492,\n",
       "  'episode_reward_mean': -67.67033351748711,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-63.76097690405362,\n",
       "    -62.54609004022629,\n",
       "    -63.55935832452537,\n",
       "    -60.91127700607122,\n",
       "    -85.4982347568673,\n",
       "    -63.93225777111339,\n",
       "    -64.13113231909614,\n",
       "    -81.01255003003625,\n",
       "    -72.93816885240457,\n",
       "    -67.33673661374485,\n",
       "    -62.34701761483378,\n",
       "    -62.84535459890984,\n",
       "    -62.76123928186395,\n",
       "    -43.93859503950119,\n",
       "    -58.91835539092152,\n",
       "    -62.88219681964668,\n",
       "    -60.85170341020684,\n",
       "    -69.95711330401893,\n",
       "    -65.58809898254881,\n",
       "    -57.50777501023412,\n",
       "    -66.12200912418291,\n",
       "    -83.31906047652842,\n",
       "    -61.64301702755775,\n",
       "    -110.56071007622492,\n",
       "    -68.24220140493918,\n",
       "    -60.107339175091916,\n",
       "    -68.74368995539558,\n",
       "    -85.54737349056592,\n",
       "    -73.98076954076714,\n",
       "    -67.01066648118348,\n",
       "    -67.2571342450343,\n",
       "    -106.85804646044886,\n",
       "    -72.94431853460198,\n",
       "    -66.51549078160905,\n",
       "    -66.7512346123599,\n",
       "    -69.81445462151719,\n",
       "    -67.99732259674794,\n",
       "    -77.60340956825377,\n",
       "    -38.483153025240355,\n",
       "    -67.68672452706627,\n",
       "    -64.9923354668812,\n",
       "    -66.14170193567028,\n",
       "    -66.82097071970777,\n",
       "    -76.99143971919253,\n",
       "    -77.79119884046207,\n",
       "    -70.51528957462632,\n",
       "    -63.54469629798036,\n",
       "    -101.77125580945939,\n",
       "    -57.441416725722505,\n",
       "    -78.07055103812739,\n",
       "    -53.06749677684894,\n",
       "    -62.949120718434536,\n",
       "    -73.18073380938984,\n",
       "    -81.2650790399682,\n",
       "    -43.691070064211765,\n",
       "    -71.42199782556159,\n",
       "    -66.47713268456077,\n",
       "    -68.18449216448919,\n",
       "    -79.84544299503867,\n",
       "    -60.8652995956477,\n",
       "    -72.72501273952722,\n",
       "    -39.16322044849828,\n",
       "    -62.33497984969161,\n",
       "    -101.10260308936229,\n",
       "    -56.18313234944594,\n",
       "    -60.234580129968556,\n",
       "    -85.29380227215621,\n",
       "    -37.94895351216115,\n",
       "    -37.6925120278722,\n",
       "    -63.55394475497248,\n",
       "    -83.04391599089251,\n",
       "    -59.63341798405079,\n",
       "    -72.4526204497884,\n",
       "    -107.99519027940168,\n",
       "    -67.32517907975856,\n",
       "    -67.64036646677334,\n",
       "    -65.43567027773189,\n",
       "    -98.81495291876409,\n",
       "    -64.42090842727355,\n",
       "    -69.74783062990667,\n",
       "    -68.08692885896367,\n",
       "    -36.672992186962155,\n",
       "    -62.20381485974605,\n",
       "    -68.23679314346403,\n",
       "    -49.62512621036832,\n",
       "    -76.61636131602413,\n",
       "    -46.47280248493626,\n",
       "    -56.91174351963955,\n",
       "    -63.36258024951144,\n",
       "    -67.4309628167993,\n",
       "    -71.74480903318945,\n",
       "    -68.30349069005496,\n",
       "    -73.99535581230452,\n",
       "    -73.90622332445457,\n",
       "    -64.02121424894332,\n",
       "    -65.11124685610075,\n",
       "    -67.4783035357724,\n",
       "    -68.38009767918614,\n",
       "    -68.5904256471162,\n",
       "    -51.69820599905487],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22127844405774838,\n",
       "   'mean_inference_ms': 0.5626781486807615,\n",
       "   'mean_action_processing_ms': 0.07601176113060845,\n",
       "   'mean_env_wait_ms': 1.1491182159950406,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 42000,\n",
       "  'agent_timesteps_total': 42000,\n",
       "  'timers': {'learn_time_ms': 1.597, 'learn_throughput': 62629.595},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -11.246787,\n",
       "     'max_q': -3.2371497,\n",
       "     'min_q': -19.026423,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 42000,\n",
       "   'num_agent_steps_sampled': 42000,\n",
       "   'num_steps_trained': 4050100,\n",
       "   'num_agent_steps_trained': 4050100,\n",
       "   'last_target_update_ts': 42000,\n",
       "   'num_target_updates': 40501},\n",
       "  'done': False,\n",
       "  'episodes_total': 415,\n",
       "  'training_iteration': 28,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_17-59-50',\n",
       "  'timestamp': 1625500790,\n",
       "  'time_this_iter_s': 20.27103018760681,\n",
       "  'time_total_s': 533.2235553264618,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 533.2235553264618,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 28,\n",
       "  'perf': {'cpu_util_percent': 12.864285714285714,\n",
       "   'ram_util_percent': 45.521428571428565,\n",
       "   'gpu_util_percent0': 0.21571428571428578,\n",
       "   'vram_util_percent0': 0.5243269898089638}},\n",
       " {'episode_reward_max': -36.672992186962155,\n",
       "  'episode_reward_min': -110.56071007622492,\n",
       "  'episode_reward_mean': -68.04295288474168,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-62.88219681964668,\n",
       "    -60.85170341020684,\n",
       "    -69.95711330401893,\n",
       "    -65.58809898254881,\n",
       "    -57.50777501023412,\n",
       "    -66.12200912418291,\n",
       "    -83.31906047652842,\n",
       "    -61.64301702755775,\n",
       "    -110.56071007622492,\n",
       "    -68.24220140493918,\n",
       "    -60.107339175091916,\n",
       "    -68.74368995539558,\n",
       "    -85.54737349056592,\n",
       "    -73.98076954076714,\n",
       "    -67.01066648118348,\n",
       "    -67.2571342450343,\n",
       "    -106.85804646044886,\n",
       "    -72.94431853460198,\n",
       "    -66.51549078160905,\n",
       "    -66.7512346123599,\n",
       "    -69.81445462151719,\n",
       "    -67.99732259674794,\n",
       "    -77.60340956825377,\n",
       "    -38.483153025240355,\n",
       "    -67.68672452706627,\n",
       "    -64.9923354668812,\n",
       "    -66.14170193567028,\n",
       "    -66.82097071970777,\n",
       "    -76.99143971919253,\n",
       "    -77.79119884046207,\n",
       "    -70.51528957462632,\n",
       "    -63.54469629798036,\n",
       "    -101.77125580945939,\n",
       "    -57.441416725722505,\n",
       "    -78.07055103812739,\n",
       "    -53.06749677684894,\n",
       "    -62.949120718434536,\n",
       "    -73.18073380938984,\n",
       "    -81.2650790399682,\n",
       "    -43.691070064211765,\n",
       "    -71.42199782556159,\n",
       "    -66.47713268456077,\n",
       "    -68.18449216448919,\n",
       "    -79.84544299503867,\n",
       "    -60.8652995956477,\n",
       "    -72.72501273952722,\n",
       "    -39.16322044849828,\n",
       "    -62.33497984969161,\n",
       "    -101.10260308936229,\n",
       "    -56.18313234944594,\n",
       "    -60.234580129968556,\n",
       "    -85.29380227215621,\n",
       "    -37.94895351216115,\n",
       "    -37.6925120278722,\n",
       "    -63.55394475497248,\n",
       "    -83.04391599089251,\n",
       "    -59.63341798405079,\n",
       "    -72.4526204497884,\n",
       "    -107.99519027940168,\n",
       "    -67.32517907975856,\n",
       "    -67.64036646677334,\n",
       "    -65.43567027773189,\n",
       "    -98.81495291876409,\n",
       "    -64.42090842727355,\n",
       "    -69.74783062990667,\n",
       "    -68.08692885896367,\n",
       "    -36.672992186962155,\n",
       "    -62.20381485974605,\n",
       "    -68.23679314346403,\n",
       "    -49.62512621036832,\n",
       "    -76.61636131602413,\n",
       "    -46.47280248493626,\n",
       "    -56.91174351963955,\n",
       "    -63.36258024951144,\n",
       "    -67.4309628167993,\n",
       "    -71.74480903318945,\n",
       "    -68.30349069005496,\n",
       "    -73.99535581230452,\n",
       "    -73.90622332445457,\n",
       "    -64.02121424894332,\n",
       "    -65.11124685610075,\n",
       "    -67.4783035357724,\n",
       "    -68.38009767918614,\n",
       "    -68.5904256471162,\n",
       "    -51.69820599905487,\n",
       "    -69.31320528117162,\n",
       "    -78.88105860005544,\n",
       "    -65.08941363371484,\n",
       "    -46.22442230139685,\n",
       "    -75.3369691604119,\n",
       "    -60.190322877670894,\n",
       "    -95.4189380923035,\n",
       "    -66.06410963776264,\n",
       "    -68.65819880459654,\n",
       "    -61.9420355290903,\n",
       "    -73.25579235416559,\n",
       "    -64.38849388302701,\n",
       "    -58.14446099787146,\n",
       "    -62.70536447021344,\n",
       "    -68.08649564617373],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22142130994346196,\n",
       "   'mean_inference_ms': 0.5628786408924022,\n",
       "   'mean_action_processing_ms': 0.07610329050341719,\n",
       "   'mean_env_wait_ms': 1.150791221918886,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 43500,\n",
       "  'agent_timesteps_total': 43500,\n",
       "  'timers': {'learn_time_ms': 1.378, 'learn_throughput': 72580.882},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -10.394093,\n",
       "     'max_q': -3.1169925,\n",
       "     'min_q': -20.683819,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 43500,\n",
       "   'num_agent_steps_sampled': 43500,\n",
       "   'num_steps_trained': 4200100,\n",
       "   'num_agent_steps_trained': 4200100,\n",
       "   'last_target_update_ts': 43500,\n",
       "   'num_target_updates': 42001},\n",
       "  'done': False,\n",
       "  'episodes_total': 430,\n",
       "  'training_iteration': 29,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-00-10',\n",
       "  'timestamp': 1625500810,\n",
       "  'time_this_iter_s': 19.97298264503479,\n",
       "  'time_total_s': 553.1965379714966,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 553.1965379714966,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 29,\n",
       "  'perf': {'cpu_util_percent': 11.803846153846155,\n",
       "   'ram_util_percent': 45.51153846153846,\n",
       "   'gpu_util_percent0': 0.23461538461538467,\n",
       "   'vram_util_percent0': 0.5296107625435162}},\n",
       " {'episode_reward_max': -36.672992186962155,\n",
       "  'episode_reward_min': -107.99519027940168,\n",
       "  'episode_reward_mean': -67.1523240195088,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-67.2571342450343,\n",
       "    -106.85804646044886,\n",
       "    -72.94431853460198,\n",
       "    -66.51549078160905,\n",
       "    -66.7512346123599,\n",
       "    -69.81445462151719,\n",
       "    -67.99732259674794,\n",
       "    -77.60340956825377,\n",
       "    -38.483153025240355,\n",
       "    -67.68672452706627,\n",
       "    -64.9923354668812,\n",
       "    -66.14170193567028,\n",
       "    -66.82097071970777,\n",
       "    -76.99143971919253,\n",
       "    -77.79119884046207,\n",
       "    -70.51528957462632,\n",
       "    -63.54469629798036,\n",
       "    -101.77125580945939,\n",
       "    -57.441416725722505,\n",
       "    -78.07055103812739,\n",
       "    -53.06749677684894,\n",
       "    -62.949120718434536,\n",
       "    -73.18073380938984,\n",
       "    -81.2650790399682,\n",
       "    -43.691070064211765,\n",
       "    -71.42199782556159,\n",
       "    -66.47713268456077,\n",
       "    -68.18449216448919,\n",
       "    -79.84544299503867,\n",
       "    -60.8652995956477,\n",
       "    -72.72501273952722,\n",
       "    -39.16322044849828,\n",
       "    -62.33497984969161,\n",
       "    -101.10260308936229,\n",
       "    -56.18313234944594,\n",
       "    -60.234580129968556,\n",
       "    -85.29380227215621,\n",
       "    -37.94895351216115,\n",
       "    -37.6925120278722,\n",
       "    -63.55394475497248,\n",
       "    -83.04391599089251,\n",
       "    -59.63341798405079,\n",
       "    -72.4526204497884,\n",
       "    -107.99519027940168,\n",
       "    -67.32517907975856,\n",
       "    -67.64036646677334,\n",
       "    -65.43567027773189,\n",
       "    -98.81495291876409,\n",
       "    -64.42090842727355,\n",
       "    -69.74783062990667,\n",
       "    -68.08692885896367,\n",
       "    -36.672992186962155,\n",
       "    -62.20381485974605,\n",
       "    -68.23679314346403,\n",
       "    -49.62512621036832,\n",
       "    -76.61636131602413,\n",
       "    -46.47280248493626,\n",
       "    -56.91174351963955,\n",
       "    -63.36258024951144,\n",
       "    -67.4309628167993,\n",
       "    -71.74480903318945,\n",
       "    -68.30349069005496,\n",
       "    -73.99535581230452,\n",
       "    -73.90622332445457,\n",
       "    -64.02121424894332,\n",
       "    -65.11124685610075,\n",
       "    -67.4783035357724,\n",
       "    -68.38009767918614,\n",
       "    -68.5904256471162,\n",
       "    -51.69820599905487,\n",
       "    -69.31320528117162,\n",
       "    -78.88105860005544,\n",
       "    -65.08941363371484,\n",
       "    -46.22442230139685,\n",
       "    -75.3369691604119,\n",
       "    -60.190322877670894,\n",
       "    -95.4189380923035,\n",
       "    -66.06410963776264,\n",
       "    -68.65819880459654,\n",
       "    -61.9420355290903,\n",
       "    -73.25579235416559,\n",
       "    -64.38849388302701,\n",
       "    -58.14446099787146,\n",
       "    -62.70536447021344,\n",
       "    -68.08649564617373,\n",
       "    -60.00894589638843,\n",
       "    -65.58446805554506,\n",
       "    -42.73587766135384,\n",
       "    -65.18136540645614,\n",
       "    -73.03726454173975,\n",
       "    -54.567082972680275,\n",
       "    -63.40339983340749,\n",
       "    -70.96629790410245,\n",
       "    -84.0220848543054,\n",
       "    -69.42750474222397,\n",
       "    -66.63977166927549,\n",
       "    -63.981844744234444,\n",
       "    -71.89171464905674,\n",
       "    -59.00245971561436,\n",
       "    -62.55075510942008],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22149054366481963,\n",
       "   'mean_inference_ms': 0.5629945741136604,\n",
       "   'mean_action_processing_ms': 0.07614775576081655,\n",
       "   'mean_env_wait_ms': 1.1528662033709518,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 45000,\n",
       "  'agent_timesteps_total': 45000,\n",
       "  'timers': {'learn_time_ms': 1.434, 'learn_throughput': 69719.149},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -10.145481,\n",
       "     'max_q': -4.6990113,\n",
       "     'min_q': -18.599152,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 45000,\n",
       "   'num_agent_steps_sampled': 45000,\n",
       "   'num_steps_trained': 4350100,\n",
       "   'num_agent_steps_trained': 4350100,\n",
       "   'last_target_update_ts': 45000,\n",
       "   'num_target_updates': 43501},\n",
       "  'done': False,\n",
       "  'episodes_total': 445,\n",
       "  'training_iteration': 30,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-00-30',\n",
       "  'timestamp': 1625500830,\n",
       "  'time_this_iter_s': 19.94455862045288,\n",
       "  'time_total_s': 573.1410965919495,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 573.1410965919495,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 30,\n",
       "  'perf': {'cpu_util_percent': 11.718518518518518,\n",
       "   'ram_util_percent': 45.581481481481475,\n",
       "   'gpu_util_percent0': 0.2414814814814815,\n",
       "   'vram_util_percent0': 0.5289638910196311}},\n",
       " {'episode_reward_max': -33.39665900047392,\n",
       "  'episode_reward_min': -107.99519027940168,\n",
       "  'episode_reward_mean': -68.01986239773129,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-70.51528957462632,\n",
       "    -63.54469629798036,\n",
       "    -101.77125580945939,\n",
       "    -57.441416725722505,\n",
       "    -78.07055103812739,\n",
       "    -53.06749677684894,\n",
       "    -62.949120718434536,\n",
       "    -73.18073380938984,\n",
       "    -81.2650790399682,\n",
       "    -43.691070064211765,\n",
       "    -71.42199782556159,\n",
       "    -66.47713268456077,\n",
       "    -68.18449216448919,\n",
       "    -79.84544299503867,\n",
       "    -60.8652995956477,\n",
       "    -72.72501273952722,\n",
       "    -39.16322044849828,\n",
       "    -62.33497984969161,\n",
       "    -101.10260308936229,\n",
       "    -56.18313234944594,\n",
       "    -60.234580129968556,\n",
       "    -85.29380227215621,\n",
       "    -37.94895351216115,\n",
       "    -37.6925120278722,\n",
       "    -63.55394475497248,\n",
       "    -83.04391599089251,\n",
       "    -59.63341798405079,\n",
       "    -72.4526204497884,\n",
       "    -107.99519027940168,\n",
       "    -67.32517907975856,\n",
       "    -67.64036646677334,\n",
       "    -65.43567027773189,\n",
       "    -98.81495291876409,\n",
       "    -64.42090842727355,\n",
       "    -69.74783062990667,\n",
       "    -68.08692885896367,\n",
       "    -36.672992186962155,\n",
       "    -62.20381485974605,\n",
       "    -68.23679314346403,\n",
       "    -49.62512621036832,\n",
       "    -76.61636131602413,\n",
       "    -46.47280248493626,\n",
       "    -56.91174351963955,\n",
       "    -63.36258024951144,\n",
       "    -67.4309628167993,\n",
       "    -71.74480903318945,\n",
       "    -68.30349069005496,\n",
       "    -73.99535581230452,\n",
       "    -73.90622332445457,\n",
       "    -64.02121424894332,\n",
       "    -65.11124685610075,\n",
       "    -67.4783035357724,\n",
       "    -68.38009767918614,\n",
       "    -68.5904256471162,\n",
       "    -51.69820599905487,\n",
       "    -69.31320528117162,\n",
       "    -78.88105860005544,\n",
       "    -65.08941363371484,\n",
       "    -46.22442230139685,\n",
       "    -75.3369691604119,\n",
       "    -60.190322877670894,\n",
       "    -95.4189380923035,\n",
       "    -66.06410963776264,\n",
       "    -68.65819880459654,\n",
       "    -61.9420355290903,\n",
       "    -73.25579235416559,\n",
       "    -64.38849388302701,\n",
       "    -58.14446099787146,\n",
       "    -62.70536447021344,\n",
       "    -68.08649564617373,\n",
       "    -60.00894589638843,\n",
       "    -65.58446805554506,\n",
       "    -42.73587766135384,\n",
       "    -65.18136540645614,\n",
       "    -73.03726454173975,\n",
       "    -54.567082972680275,\n",
       "    -63.40339983340749,\n",
       "    -70.96629790410245,\n",
       "    -84.0220848543054,\n",
       "    -69.42750474222397,\n",
       "    -66.63977166927549,\n",
       "    -63.981844744234444,\n",
       "    -71.89171464905674,\n",
       "    -59.00245971561436,\n",
       "    -62.55075510942008,\n",
       "    -95.35143459066408,\n",
       "    -85.66650357077103,\n",
       "    -61.77051883580818,\n",
       "    -87.16183922602937,\n",
       "    -84.07743084260535,\n",
       "    -89.86541651840892,\n",
       "    -66.45320069012459,\n",
       "    -33.39665900047392,\n",
       "    -83.99925792084004,\n",
       "    -69.2720210605373,\n",
       "    -71.57323676719163,\n",
       "    -70.9295441538282,\n",
       "    -60.688071533601395,\n",
       "    -106.2743953763872,\n",
       "    -74.92324338977126],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22154824904019418,\n",
       "   'mean_inference_ms': 0.5630858510068363,\n",
       "   'mean_action_processing_ms': 0.07615619906492835,\n",
       "   'mean_env_wait_ms': 1.1550487155959217,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 46500,\n",
       "  'agent_timesteps_total': 46500,\n",
       "  'timers': {'learn_time_ms': 1.416, 'learn_throughput': 70599.293},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -11.184557,\n",
       "     'max_q': -4.046387,\n",
       "     'min_q': -18.302994,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 46500,\n",
       "   'num_agent_steps_sampled': 46500,\n",
       "   'num_steps_trained': 4500100,\n",
       "   'num_agent_steps_trained': 4500100,\n",
       "   'last_target_update_ts': 46500,\n",
       "   'num_target_updates': 45001},\n",
       "  'done': False,\n",
       "  'episodes_total': 460,\n",
       "  'training_iteration': 31,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-00-50',\n",
       "  'timestamp': 1625500850,\n",
       "  'time_this_iter_s': 19.80938196182251,\n",
       "  'time_total_s': 592.950478553772,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 592.950478553772,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 31,\n",
       "  'perf': {'cpu_util_percent': 11.846153846153843,\n",
       "   'ram_util_percent': 45.607692307692304,\n",
       "   'gpu_util_percent0': 0.2530769230769231,\n",
       "   'vram_util_percent0': 0.5299647935802372}},\n",
       " {'episode_reward_max': -33.39665900047392,\n",
       "  'episode_reward_min': -107.99519027940168,\n",
       "  'episode_reward_mean': -68.11381844059099,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-72.72501273952722,\n",
       "    -39.16322044849828,\n",
       "    -62.33497984969161,\n",
       "    -101.10260308936229,\n",
       "    -56.18313234944594,\n",
       "    -60.234580129968556,\n",
       "    -85.29380227215621,\n",
       "    -37.94895351216115,\n",
       "    -37.6925120278722,\n",
       "    -63.55394475497248,\n",
       "    -83.04391599089251,\n",
       "    -59.63341798405079,\n",
       "    -72.4526204497884,\n",
       "    -107.99519027940168,\n",
       "    -67.32517907975856,\n",
       "    -67.64036646677334,\n",
       "    -65.43567027773189,\n",
       "    -98.81495291876409,\n",
       "    -64.42090842727355,\n",
       "    -69.74783062990667,\n",
       "    -68.08692885896367,\n",
       "    -36.672992186962155,\n",
       "    -62.20381485974605,\n",
       "    -68.23679314346403,\n",
       "    -49.62512621036832,\n",
       "    -76.61636131602413,\n",
       "    -46.47280248493626,\n",
       "    -56.91174351963955,\n",
       "    -63.36258024951144,\n",
       "    -67.4309628167993,\n",
       "    -71.74480903318945,\n",
       "    -68.30349069005496,\n",
       "    -73.99535581230452,\n",
       "    -73.90622332445457,\n",
       "    -64.02121424894332,\n",
       "    -65.11124685610075,\n",
       "    -67.4783035357724,\n",
       "    -68.38009767918614,\n",
       "    -68.5904256471162,\n",
       "    -51.69820599905487,\n",
       "    -69.31320528117162,\n",
       "    -78.88105860005544,\n",
       "    -65.08941363371484,\n",
       "    -46.22442230139685,\n",
       "    -75.3369691604119,\n",
       "    -60.190322877670894,\n",
       "    -95.4189380923035,\n",
       "    -66.06410963776264,\n",
       "    -68.65819880459654,\n",
       "    -61.9420355290903,\n",
       "    -73.25579235416559,\n",
       "    -64.38849388302701,\n",
       "    -58.14446099787146,\n",
       "    -62.70536447021344,\n",
       "    -68.08649564617373,\n",
       "    -60.00894589638843,\n",
       "    -65.58446805554506,\n",
       "    -42.73587766135384,\n",
       "    -65.18136540645614,\n",
       "    -73.03726454173975,\n",
       "    -54.567082972680275,\n",
       "    -63.40339983340749,\n",
       "    -70.96629790410245,\n",
       "    -84.0220848543054,\n",
       "    -69.42750474222397,\n",
       "    -66.63977166927549,\n",
       "    -63.981844744234444,\n",
       "    -71.89171464905674,\n",
       "    -59.00245971561436,\n",
       "    -62.55075510942008,\n",
       "    -95.35143459066408,\n",
       "    -85.66650357077103,\n",
       "    -61.77051883580818,\n",
       "    -87.16183922602937,\n",
       "    -84.07743084260535,\n",
       "    -89.86541651840892,\n",
       "    -66.45320069012459,\n",
       "    -33.39665900047392,\n",
       "    -83.99925792084004,\n",
       "    -69.2720210605373,\n",
       "    -71.57323676719163,\n",
       "    -70.9295441538282,\n",
       "    -60.688071533601395,\n",
       "    -106.2743953763872,\n",
       "    -74.92324338977126,\n",
       "    -70.7101118310571,\n",
       "    -91.56864070784735,\n",
       "    -60.33049961064375,\n",
       "    -70.93230767358898,\n",
       "    -46.37330380990934,\n",
       "    -84.51010759830429,\n",
       "    -59.315665208299656,\n",
       "    -35.18365072171996,\n",
       "    -97.13563454212671,\n",
       "    -69.69396869526545,\n",
       "    -36.70842877383607,\n",
       "    -95.75273665409185,\n",
       "    -70.62162481137426,\n",
       "    -95.86793469285365,\n",
       "    -56.98206407511846],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22158184219323712,\n",
       "   'mean_inference_ms': 0.563068306238953,\n",
       "   'mean_action_processing_ms': 0.07614714812290738,\n",
       "   'mean_env_wait_ms': 1.1575004980972183,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 48000,\n",
       "  'agent_timesteps_total': 48000,\n",
       "  'timers': {'learn_time_ms': 1.447, 'learn_throughput': 69087.531},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -11.20892,\n",
       "     'max_q': -3.0573874,\n",
       "     'min_q': -19.09231,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 48000,\n",
       "   'num_agent_steps_sampled': 48000,\n",
       "   'num_steps_trained': 4650100,\n",
       "   'num_agent_steps_trained': 4650100,\n",
       "   'last_target_update_ts': 48000,\n",
       "   'num_target_updates': 46501},\n",
       "  'done': False,\n",
       "  'episodes_total': 475,\n",
       "  'training_iteration': 32,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-01-10',\n",
       "  'timestamp': 1625500870,\n",
       "  'time_this_iter_s': 19.90609908103943,\n",
       "  'time_total_s': 612.8565776348114,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 612.8565776348114,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 32,\n",
       "  'perf': {'cpu_util_percent': 12.24074074074074,\n",
       "   'ram_util_percent': 45.69629629629631,\n",
       "   'gpu_util_percent0': 0.24259259259259258,\n",
       "   'vram_util_percent0': 0.5302423364300122}},\n",
       " {'episode_reward_max': -33.39665900047392,\n",
       "  'episode_reward_min': -106.2743953763872,\n",
       "  'episode_reward_mean': -67.35976136028644,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-67.64036646677334,\n",
       "    -65.43567027773189,\n",
       "    -98.81495291876409,\n",
       "    -64.42090842727355,\n",
       "    -69.74783062990667,\n",
       "    -68.08692885896367,\n",
       "    -36.672992186962155,\n",
       "    -62.20381485974605,\n",
       "    -68.23679314346403,\n",
       "    -49.62512621036832,\n",
       "    -76.61636131602413,\n",
       "    -46.47280248493626,\n",
       "    -56.91174351963955,\n",
       "    -63.36258024951144,\n",
       "    -67.4309628167993,\n",
       "    -71.74480903318945,\n",
       "    -68.30349069005496,\n",
       "    -73.99535581230452,\n",
       "    -73.90622332445457,\n",
       "    -64.02121424894332,\n",
       "    -65.11124685610075,\n",
       "    -67.4783035357724,\n",
       "    -68.38009767918614,\n",
       "    -68.5904256471162,\n",
       "    -51.69820599905487,\n",
       "    -69.31320528117162,\n",
       "    -78.88105860005544,\n",
       "    -65.08941363371484,\n",
       "    -46.22442230139685,\n",
       "    -75.3369691604119,\n",
       "    -60.190322877670894,\n",
       "    -95.4189380923035,\n",
       "    -66.06410963776264,\n",
       "    -68.65819880459654,\n",
       "    -61.9420355290903,\n",
       "    -73.25579235416559,\n",
       "    -64.38849388302701,\n",
       "    -58.14446099787146,\n",
       "    -62.70536447021344,\n",
       "    -68.08649564617373,\n",
       "    -60.00894589638843,\n",
       "    -65.58446805554506,\n",
       "    -42.73587766135384,\n",
       "    -65.18136540645614,\n",
       "    -73.03726454173975,\n",
       "    -54.567082972680275,\n",
       "    -63.40339983340749,\n",
       "    -70.96629790410245,\n",
       "    -84.0220848543054,\n",
       "    -69.42750474222397,\n",
       "    -66.63977166927549,\n",
       "    -63.981844744234444,\n",
       "    -71.89171464905674,\n",
       "    -59.00245971561436,\n",
       "    -62.55075510942008,\n",
       "    -95.35143459066408,\n",
       "    -85.66650357077103,\n",
       "    -61.77051883580818,\n",
       "    -87.16183922602937,\n",
       "    -84.07743084260535,\n",
       "    -89.86541651840892,\n",
       "    -66.45320069012459,\n",
       "    -33.39665900047392,\n",
       "    -83.99925792084004,\n",
       "    -69.2720210605373,\n",
       "    -71.57323676719163,\n",
       "    -70.9295441538282,\n",
       "    -60.688071533601395,\n",
       "    -106.2743953763872,\n",
       "    -74.92324338977126,\n",
       "    -70.7101118310571,\n",
       "    -91.56864070784735,\n",
       "    -60.33049961064375,\n",
       "    -70.93230767358898,\n",
       "    -46.37330380990934,\n",
       "    -84.51010759830429,\n",
       "    -59.315665208299656,\n",
       "    -35.18365072171996,\n",
       "    -97.13563454212671,\n",
       "    -69.69396869526545,\n",
       "    -36.70842877383607,\n",
       "    -95.75273665409185,\n",
       "    -70.62162481137426,\n",
       "    -95.86793469285365,\n",
       "    -56.98206407511846,\n",
       "    -61.24022136665297,\n",
       "    -64.8297135436058,\n",
       "    -62.950107400913225,\n",
       "    -67.65951541396628,\n",
       "    -42.502694733262786,\n",
       "    -57.71953999273898,\n",
       "    -77.39341731256027,\n",
       "    -63.72068275285816,\n",
       "    -66.90717562698903,\n",
       "    -62.48422792175958,\n",
       "    -59.32900010978818,\n",
       "    -68.98336597151214,\n",
       "    -63.54075376641473,\n",
       "    -44.190877260170666,\n",
       "    -67.82606375390073],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22159198852631604,\n",
       "   'mean_inference_ms': 0.5630737833425402,\n",
       "   'mean_action_processing_ms': 0.07612963403995078,\n",
       "   'mean_env_wait_ms': 1.1597080743785428,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 49500,\n",
       "  'agent_timesteps_total': 49500,\n",
       "  'timers': {'learn_time_ms': 1.451, 'learn_throughput': 68894.612},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -10.836779,\n",
       "     'max_q': -3.4001746,\n",
       "     'min_q': -19.962421,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 49500,\n",
       "   'num_agent_steps_sampled': 49500,\n",
       "   'num_steps_trained': 4800100,\n",
       "   'num_agent_steps_trained': 4800100,\n",
       "   'last_target_update_ts': 49500,\n",
       "   'num_target_updates': 48001},\n",
       "  'done': False,\n",
       "  'episodes_total': 490,\n",
       "  'training_iteration': 33,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-01-30',\n",
       "  'timestamp': 1625500890,\n",
       "  'time_this_iter_s': 20.186203956604004,\n",
       "  'time_total_s': 633.0427815914154,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 633.0427815914154,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 33,\n",
       "  'perf': {'cpu_util_percent': 11.9,\n",
       "   'ram_util_percent': 45.70370370370371,\n",
       "   'gpu_util_percent0': 0.22370370370370377,\n",
       "   'vram_util_percent0': 0.5300055872799417}},\n",
       " {'episode_reward_max': -33.39665900047392,\n",
       "  'episode_reward_min': -106.2743953763872,\n",
       "  'episode_reward_mean': -67.65793280698644,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 14,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-67.4309628167993,\n",
       "    -71.74480903318945,\n",
       "    -68.30349069005496,\n",
       "    -73.99535581230452,\n",
       "    -73.90622332445457,\n",
       "    -64.02121424894332,\n",
       "    -65.11124685610075,\n",
       "    -67.4783035357724,\n",
       "    -68.38009767918614,\n",
       "    -68.5904256471162,\n",
       "    -51.69820599905487,\n",
       "    -69.31320528117162,\n",
       "    -78.88105860005544,\n",
       "    -65.08941363371484,\n",
       "    -46.22442230139685,\n",
       "    -75.3369691604119,\n",
       "    -60.190322877670894,\n",
       "    -95.4189380923035,\n",
       "    -66.06410963776264,\n",
       "    -68.65819880459654,\n",
       "    -61.9420355290903,\n",
       "    -73.25579235416559,\n",
       "    -64.38849388302701,\n",
       "    -58.14446099787146,\n",
       "    -62.70536447021344,\n",
       "    -68.08649564617373,\n",
       "    -60.00894589638843,\n",
       "    -65.58446805554506,\n",
       "    -42.73587766135384,\n",
       "    -65.18136540645614,\n",
       "    -73.03726454173975,\n",
       "    -54.567082972680275,\n",
       "    -63.40339983340749,\n",
       "    -70.96629790410245,\n",
       "    -84.0220848543054,\n",
       "    -69.42750474222397,\n",
       "    -66.63977166927549,\n",
       "    -63.981844744234444,\n",
       "    -71.89171464905674,\n",
       "    -59.00245971561436,\n",
       "    -62.55075510942008,\n",
       "    -95.35143459066408,\n",
       "    -85.66650357077103,\n",
       "    -61.77051883580818,\n",
       "    -87.16183922602937,\n",
       "    -84.07743084260535,\n",
       "    -89.86541651840892,\n",
       "    -66.45320069012459,\n",
       "    -33.39665900047392,\n",
       "    -83.99925792084004,\n",
       "    -69.2720210605373,\n",
       "    -71.57323676719163,\n",
       "    -70.9295441538282,\n",
       "    -60.688071533601395,\n",
       "    -106.2743953763872,\n",
       "    -74.92324338977126,\n",
       "    -70.7101118310571,\n",
       "    -91.56864070784735,\n",
       "    -60.33049961064375,\n",
       "    -70.93230767358898,\n",
       "    -46.37330380990934,\n",
       "    -84.51010759830429,\n",
       "    -59.315665208299656,\n",
       "    -35.18365072171996,\n",
       "    -97.13563454212671,\n",
       "    -69.69396869526545,\n",
       "    -36.70842877383607,\n",
       "    -95.75273665409185,\n",
       "    -70.62162481137426,\n",
       "    -95.86793469285365,\n",
       "    -56.98206407511846,\n",
       "    -61.24022136665297,\n",
       "    -64.8297135436058,\n",
       "    -62.950107400913225,\n",
       "    -67.65951541396628,\n",
       "    -42.502694733262786,\n",
       "    -57.71953999273898,\n",
       "    -77.39341731256027,\n",
       "    -63.72068275285816,\n",
       "    -66.90717562698903,\n",
       "    -62.48422792175958,\n",
       "    -59.32900010978818,\n",
       "    -68.98336597151214,\n",
       "    -63.54075376641473,\n",
       "    -44.190877260170666,\n",
       "    -67.82606375390073,\n",
       "    -67.9851565945453,\n",
       "    -65.2977318763192,\n",
       "    -65.75603497242565,\n",
       "    -63.59310525115048,\n",
       "    -66.49468090535332,\n",
       "    -54.15274898666783,\n",
       "    -59.51502392512422,\n",
       "    -66.68603624175454,\n",
       "    -76.90956487988947,\n",
       "    -66.15916674017785,\n",
       "    -69.52381248641709,\n",
       "    -65.01865884083442,\n",
       "    -70.20372550169134,\n",
       "    -66.77056901771432],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22156797804508258,\n",
       "   'mean_inference_ms': 0.5631076593474265,\n",
       "   'mean_action_processing_ms': 0.07609925641149547,\n",
       "   'mean_env_wait_ms': 1.1598541385169363,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 51000,\n",
       "  'agent_timesteps_total': 51000,\n",
       "  'timers': {'learn_time_ms': 1.451, 'learn_throughput': 68919.518},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -10.939871,\n",
       "     'max_q': -3.9706168,\n",
       "     'min_q': -20.23995,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 51000,\n",
       "   'num_agent_steps_sampled': 51000,\n",
       "   'num_steps_trained': 4950100,\n",
       "   'num_agent_steps_trained': 4950100,\n",
       "   'last_target_update_ts': 51000,\n",
       "   'num_target_updates': 49501},\n",
       "  'done': False,\n",
       "  'episodes_total': 504,\n",
       "  'training_iteration': 34,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-01-50',\n",
       "  'timestamp': 1625500910,\n",
       "  'time_this_iter_s': 19.9309401512146,\n",
       "  'time_total_s': 652.97372174263,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 652.97372174263,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 34,\n",
       "  'perf': {'cpu_util_percent': 11.98076923076923,\n",
       "   'ram_util_percent': 45.780769230769224,\n",
       "   'gpu_util_percent0': 0.24423076923076922,\n",
       "   'vram_util_percent0': 0.5298271148437347}},\n",
       " {'episode_reward_max': -33.39665900047392,\n",
       "  'episode_reward_min': -106.2743953763872,\n",
       "  'episode_reward_mean': -67.72633779518912,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-75.3369691604119,\n",
       "    -60.190322877670894,\n",
       "    -95.4189380923035,\n",
       "    -66.06410963776264,\n",
       "    -68.65819880459654,\n",
       "    -61.9420355290903,\n",
       "    -73.25579235416559,\n",
       "    -64.38849388302701,\n",
       "    -58.14446099787146,\n",
       "    -62.70536447021344,\n",
       "    -68.08649564617373,\n",
       "    -60.00894589638843,\n",
       "    -65.58446805554506,\n",
       "    -42.73587766135384,\n",
       "    -65.18136540645614,\n",
       "    -73.03726454173975,\n",
       "    -54.567082972680275,\n",
       "    -63.40339983340749,\n",
       "    -70.96629790410245,\n",
       "    -84.0220848543054,\n",
       "    -69.42750474222397,\n",
       "    -66.63977166927549,\n",
       "    -63.981844744234444,\n",
       "    -71.89171464905674,\n",
       "    -59.00245971561436,\n",
       "    -62.55075510942008,\n",
       "    -95.35143459066408,\n",
       "    -85.66650357077103,\n",
       "    -61.77051883580818,\n",
       "    -87.16183922602937,\n",
       "    -84.07743084260535,\n",
       "    -89.86541651840892,\n",
       "    -66.45320069012459,\n",
       "    -33.39665900047392,\n",
       "    -83.99925792084004,\n",
       "    -69.2720210605373,\n",
       "    -71.57323676719163,\n",
       "    -70.9295441538282,\n",
       "    -60.688071533601395,\n",
       "    -106.2743953763872,\n",
       "    -74.92324338977126,\n",
       "    -70.7101118310571,\n",
       "    -91.56864070784735,\n",
       "    -60.33049961064375,\n",
       "    -70.93230767358898,\n",
       "    -46.37330380990934,\n",
       "    -84.51010759830429,\n",
       "    -59.315665208299656,\n",
       "    -35.18365072171996,\n",
       "    -97.13563454212671,\n",
       "    -69.69396869526545,\n",
       "    -36.70842877383607,\n",
       "    -95.75273665409185,\n",
       "    -70.62162481137426,\n",
       "    -95.86793469285365,\n",
       "    -56.98206407511846,\n",
       "    -61.24022136665297,\n",
       "    -64.8297135436058,\n",
       "    -62.950107400913225,\n",
       "    -67.65951541396628,\n",
       "    -42.502694733262786,\n",
       "    -57.71953999273898,\n",
       "    -77.39341731256027,\n",
       "    -63.72068275285816,\n",
       "    -66.90717562698903,\n",
       "    -62.48422792175958,\n",
       "    -59.32900010978818,\n",
       "    -68.98336597151214,\n",
       "    -63.54075376641473,\n",
       "    -44.190877260170666,\n",
       "    -67.82606375390073,\n",
       "    -67.9851565945453,\n",
       "    -65.2977318763192,\n",
       "    -65.75603497242565,\n",
       "    -63.59310525115048,\n",
       "    -66.49468090535332,\n",
       "    -54.15274898666783,\n",
       "    -59.51502392512422,\n",
       "    -66.68603624175454,\n",
       "    -76.90956487988947,\n",
       "    -66.15916674017785,\n",
       "    -69.52381248641709,\n",
       "    -65.01865884083442,\n",
       "    -70.20372550169134,\n",
       "    -66.77056901771432,\n",
       "    -71.56687028499628,\n",
       "    -73.06573454258019,\n",
       "    -70.52039054583024,\n",
       "    -70.72167689242387,\n",
       "    -66.19107191299508,\n",
       "    -62.8775250598776,\n",
       "    -56.48969131940902,\n",
       "    -72.5733925426211,\n",
       "    -68.70800545098692,\n",
       "    -71.9543881027349,\n",
       "    -72.54158186741661,\n",
       "    -64.22717838632367,\n",
       "    -59.04237029526044,\n",
       "    -60.22780890467796,\n",
       "    -66.3012481714492],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22151805226543733,\n",
       "   'mean_inference_ms': 0.5632862147398218,\n",
       "   'mean_action_processing_ms': 0.07605908695820444,\n",
       "   'mean_env_wait_ms': 1.1581270900969325,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 52500,\n",
       "  'agent_timesteps_total': 52500,\n",
       "  'timers': {'learn_time_ms': 1.825, 'learn_throughput': 54806.727},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -11.757573,\n",
       "     'max_q': -3.5514872,\n",
       "     'min_q': -19.471317,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 52500,\n",
       "   'num_agent_steps_sampled': 52500,\n",
       "   'num_steps_trained': 5100100,\n",
       "   'num_agent_steps_trained': 5100100,\n",
       "   'last_target_update_ts': 52500,\n",
       "   'num_target_updates': 51001},\n",
       "  'done': False,\n",
       "  'episodes_total': 519,\n",
       "  'training_iteration': 35,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-02-10',\n",
       "  'timestamp': 1625500930,\n",
       "  'time_this_iter_s': 19.755934238433838,\n",
       "  'time_total_s': 672.7296559810638,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 672.7296559810638,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 35,\n",
       "  'perf': {'cpu_util_percent': 11.818518518518518,\n",
       "   'ram_util_percent': 45.79999999999999,\n",
       "   'gpu_util_percent0': 0.26851851851851855,\n",
       "   'vram_util_percent0': 0.5301665767019896}},\n",
       " {'episode_reward_max': -33.39665900047392,\n",
       "  'episode_reward_min': -106.2743953763872,\n",
       "  'episode_reward_mean': -67.33452964782171,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-73.03726454173975,\n",
       "    -54.567082972680275,\n",
       "    -63.40339983340749,\n",
       "    -70.96629790410245,\n",
       "    -84.0220848543054,\n",
       "    -69.42750474222397,\n",
       "    -66.63977166927549,\n",
       "    -63.981844744234444,\n",
       "    -71.89171464905674,\n",
       "    -59.00245971561436,\n",
       "    -62.55075510942008,\n",
       "    -95.35143459066408,\n",
       "    -85.66650357077103,\n",
       "    -61.77051883580818,\n",
       "    -87.16183922602937,\n",
       "    -84.07743084260535,\n",
       "    -89.86541651840892,\n",
       "    -66.45320069012459,\n",
       "    -33.39665900047392,\n",
       "    -83.99925792084004,\n",
       "    -69.2720210605373,\n",
       "    -71.57323676719163,\n",
       "    -70.9295441538282,\n",
       "    -60.688071533601395,\n",
       "    -106.2743953763872,\n",
       "    -74.92324338977126,\n",
       "    -70.7101118310571,\n",
       "    -91.56864070784735,\n",
       "    -60.33049961064375,\n",
       "    -70.93230767358898,\n",
       "    -46.37330380990934,\n",
       "    -84.51010759830429,\n",
       "    -59.315665208299656,\n",
       "    -35.18365072171996,\n",
       "    -97.13563454212671,\n",
       "    -69.69396869526545,\n",
       "    -36.70842877383607,\n",
       "    -95.75273665409185,\n",
       "    -70.62162481137426,\n",
       "    -95.86793469285365,\n",
       "    -56.98206407511846,\n",
       "    -61.24022136665297,\n",
       "    -64.8297135436058,\n",
       "    -62.950107400913225,\n",
       "    -67.65951541396628,\n",
       "    -42.502694733262786,\n",
       "    -57.71953999273898,\n",
       "    -77.39341731256027,\n",
       "    -63.72068275285816,\n",
       "    -66.90717562698903,\n",
       "    -62.48422792175958,\n",
       "    -59.32900010978818,\n",
       "    -68.98336597151214,\n",
       "    -63.54075376641473,\n",
       "    -44.190877260170666,\n",
       "    -67.82606375390073,\n",
       "    -67.9851565945453,\n",
       "    -65.2977318763192,\n",
       "    -65.75603497242565,\n",
       "    -63.59310525115048,\n",
       "    -66.49468090535332,\n",
       "    -54.15274898666783,\n",
       "    -59.51502392512422,\n",
       "    -66.68603624175454,\n",
       "    -76.90956487988947,\n",
       "    -66.15916674017785,\n",
       "    -69.52381248641709,\n",
       "    -65.01865884083442,\n",
       "    -70.20372550169134,\n",
       "    -66.77056901771432,\n",
       "    -71.56687028499628,\n",
       "    -73.06573454258019,\n",
       "    -70.52039054583024,\n",
       "    -70.72167689242387,\n",
       "    -66.19107191299508,\n",
       "    -62.8775250598776,\n",
       "    -56.48969131940902,\n",
       "    -72.5733925426211,\n",
       "    -68.70800545098692,\n",
       "    -71.9543881027349,\n",
       "    -72.54158186741661,\n",
       "    -64.22717838632367,\n",
       "    -59.04237029526044,\n",
       "    -60.22780890467796,\n",
       "    -66.3012481714492,\n",
       "    -75.3592120390615,\n",
       "    -62.49582764537123,\n",
       "    -60.31278610482156,\n",
       "    -37.747639697115204,\n",
       "    -67.31463863581604,\n",
       "    -76.67877169024516,\n",
       "    -67.34120677104647,\n",
       "    -45.27211281435348,\n",
       "    -64.92274948533978,\n",
       "    -60.01084780186193,\n",
       "    -70.35551454314103,\n",
       "    -67.04269846245339,\n",
       "    -67.67423653502495,\n",
       "    -75.45020372077695,\n",
       "    -50.54257778986077],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22146603069912552,\n",
       "   'mean_inference_ms': 0.5635554824560259,\n",
       "   'mean_action_processing_ms': 0.07601972152327757,\n",
       "   'mean_env_wait_ms': 1.1555433228517353,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 54000,\n",
       "  'agent_timesteps_total': 54000,\n",
       "  'timers': {'learn_time_ms': 1.528, 'learn_throughput': 65448.054},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.07343,\n",
       "     'max_q': -2.8467445,\n",
       "     'min_q': -19.235218,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 54000,\n",
       "   'num_agent_steps_sampled': 54000,\n",
       "   'num_steps_trained': 5250100,\n",
       "   'num_agent_steps_trained': 5250100,\n",
       "   'last_target_update_ts': 54000,\n",
       "   'num_target_updates': 52501},\n",
       "  'done': False,\n",
       "  'episodes_total': 534,\n",
       "  'training_iteration': 36,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-02-29',\n",
       "  'timestamp': 1625500949,\n",
       "  'time_this_iter_s': 19.58139204978943,\n",
       "  'time_total_s': 692.3110480308533,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 692.3110480308533,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 36,\n",
       "  'perf': {'cpu_util_percent': 12.0,\n",
       "   'ram_util_percent': 45.89615384615385,\n",
       "   'gpu_util_percent0': 0.2742307692307693,\n",
       "   'vram_util_percent0': 0.5284994984560313}},\n",
       " {'episode_reward_max': -33.39665900047392,\n",
       "  'episode_reward_min': -106.2743953763872,\n",
       "  'episode_reward_mean': -66.89319806605202,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-84.07743084260535,\n",
       "    -89.86541651840892,\n",
       "    -66.45320069012459,\n",
       "    -33.39665900047392,\n",
       "    -83.99925792084004,\n",
       "    -69.2720210605373,\n",
       "    -71.57323676719163,\n",
       "    -70.9295441538282,\n",
       "    -60.688071533601395,\n",
       "    -106.2743953763872,\n",
       "    -74.92324338977126,\n",
       "    -70.7101118310571,\n",
       "    -91.56864070784735,\n",
       "    -60.33049961064375,\n",
       "    -70.93230767358898,\n",
       "    -46.37330380990934,\n",
       "    -84.51010759830429,\n",
       "    -59.315665208299656,\n",
       "    -35.18365072171996,\n",
       "    -97.13563454212671,\n",
       "    -69.69396869526545,\n",
       "    -36.70842877383607,\n",
       "    -95.75273665409185,\n",
       "    -70.62162481137426,\n",
       "    -95.86793469285365,\n",
       "    -56.98206407511846,\n",
       "    -61.24022136665297,\n",
       "    -64.8297135436058,\n",
       "    -62.950107400913225,\n",
       "    -67.65951541396628,\n",
       "    -42.502694733262786,\n",
       "    -57.71953999273898,\n",
       "    -77.39341731256027,\n",
       "    -63.72068275285816,\n",
       "    -66.90717562698903,\n",
       "    -62.48422792175958,\n",
       "    -59.32900010978818,\n",
       "    -68.98336597151214,\n",
       "    -63.54075376641473,\n",
       "    -44.190877260170666,\n",
       "    -67.82606375390073,\n",
       "    -67.9851565945453,\n",
       "    -65.2977318763192,\n",
       "    -65.75603497242565,\n",
       "    -63.59310525115048,\n",
       "    -66.49468090535332,\n",
       "    -54.15274898666783,\n",
       "    -59.51502392512422,\n",
       "    -66.68603624175454,\n",
       "    -76.90956487988947,\n",
       "    -66.15916674017785,\n",
       "    -69.52381248641709,\n",
       "    -65.01865884083442,\n",
       "    -70.20372550169134,\n",
       "    -66.77056901771432,\n",
       "    -71.56687028499628,\n",
       "    -73.06573454258019,\n",
       "    -70.52039054583024,\n",
       "    -70.72167689242387,\n",
       "    -66.19107191299508,\n",
       "    -62.8775250598776,\n",
       "    -56.48969131940902,\n",
       "    -72.5733925426211,\n",
       "    -68.70800545098692,\n",
       "    -71.9543881027349,\n",
       "    -72.54158186741661,\n",
       "    -64.22717838632367,\n",
       "    -59.04237029526044,\n",
       "    -60.22780890467796,\n",
       "    -66.3012481714492,\n",
       "    -75.3592120390615,\n",
       "    -62.49582764537123,\n",
       "    -60.31278610482156,\n",
       "    -37.747639697115204,\n",
       "    -67.31463863581604,\n",
       "    -76.67877169024516,\n",
       "    -67.34120677104647,\n",
       "    -45.27211281435348,\n",
       "    -64.92274948533978,\n",
       "    -60.01084780186193,\n",
       "    -70.35551454314103,\n",
       "    -67.04269846245339,\n",
       "    -67.67423653502495,\n",
       "    -75.45020372077695,\n",
       "    -50.54257778986077,\n",
       "    -54.16110622248656,\n",
       "    -79.88430569824963,\n",
       "    -65.34586292581203,\n",
       "    -70.20312990270217,\n",
       "    -73.78166229011286,\n",
       "    -67.59548377611142,\n",
       "    -61.75224441422762,\n",
       "    -65.20215038466537,\n",
       "    -76.00759868898776,\n",
       "    -72.9247807096126,\n",
       "    -68.89239951417063,\n",
       "    -75.21905351908418,\n",
       "    -61.994068151915805,\n",
       "    -65.36823463056436,\n",
       "    -66.97523795366176],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22140437277213493,\n",
       "   'mean_inference_ms': 0.5638436563039742,\n",
       "   'mean_action_processing_ms': 0.07598663041318371,\n",
       "   'mean_env_wait_ms': 1.1524141210962668,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 55500,\n",
       "  'agent_timesteps_total': 55500,\n",
       "  'timers': {'learn_time_ms': 1.378, 'learn_throughput': 72578.37},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.166252,\n",
       "     'max_q': -3.2624776,\n",
       "     'min_q': -18.892307,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 55500,\n",
       "   'num_agent_steps_sampled': 55500,\n",
       "   'num_steps_trained': 5400100,\n",
       "   'num_agent_steps_trained': 5400100,\n",
       "   'last_target_update_ts': 55500,\n",
       "   'num_target_updates': 54001},\n",
       "  'done': False,\n",
       "  'episodes_total': 549,\n",
       "  'training_iteration': 37,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-02-49',\n",
       "  'timestamp': 1625500969,\n",
       "  'time_this_iter_s': 19.99690008163452,\n",
       "  'time_total_s': 712.3079481124878,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 712.3079481124878,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 37,\n",
       "  'perf': {'cpu_util_percent': 12.057692307692308,\n",
       "   'ram_util_percent': 45.900000000000006,\n",
       "   'gpu_util_percent0': 0.2715384615384615,\n",
       "   'vram_util_percent0': 0.5275259131050489}},\n",
       " {'episode_reward_max': -35.18365072171996,\n",
       "  'episode_reward_min': -97.13563454212671,\n",
       "  'episode_reward_mean': -65.93536056065074,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-46.37330380990934,\n",
       "    -84.51010759830429,\n",
       "    -59.315665208299656,\n",
       "    -35.18365072171996,\n",
       "    -97.13563454212671,\n",
       "    -69.69396869526545,\n",
       "    -36.70842877383607,\n",
       "    -95.75273665409185,\n",
       "    -70.62162481137426,\n",
       "    -95.86793469285365,\n",
       "    -56.98206407511846,\n",
       "    -61.24022136665297,\n",
       "    -64.8297135436058,\n",
       "    -62.950107400913225,\n",
       "    -67.65951541396628,\n",
       "    -42.502694733262786,\n",
       "    -57.71953999273898,\n",
       "    -77.39341731256027,\n",
       "    -63.72068275285816,\n",
       "    -66.90717562698903,\n",
       "    -62.48422792175958,\n",
       "    -59.32900010978818,\n",
       "    -68.98336597151214,\n",
       "    -63.54075376641473,\n",
       "    -44.190877260170666,\n",
       "    -67.82606375390073,\n",
       "    -67.9851565945453,\n",
       "    -65.2977318763192,\n",
       "    -65.75603497242565,\n",
       "    -63.59310525115048,\n",
       "    -66.49468090535332,\n",
       "    -54.15274898666783,\n",
       "    -59.51502392512422,\n",
       "    -66.68603624175454,\n",
       "    -76.90956487988947,\n",
       "    -66.15916674017785,\n",
       "    -69.52381248641709,\n",
       "    -65.01865884083442,\n",
       "    -70.20372550169134,\n",
       "    -66.77056901771432,\n",
       "    -71.56687028499628,\n",
       "    -73.06573454258019,\n",
       "    -70.52039054583024,\n",
       "    -70.72167689242387,\n",
       "    -66.19107191299508,\n",
       "    -62.8775250598776,\n",
       "    -56.48969131940902,\n",
       "    -72.5733925426211,\n",
       "    -68.70800545098692,\n",
       "    -71.9543881027349,\n",
       "    -72.54158186741661,\n",
       "    -64.22717838632367,\n",
       "    -59.04237029526044,\n",
       "    -60.22780890467796,\n",
       "    -66.3012481714492,\n",
       "    -75.3592120390615,\n",
       "    -62.49582764537123,\n",
       "    -60.31278610482156,\n",
       "    -37.747639697115204,\n",
       "    -67.31463863581604,\n",
       "    -76.67877169024516,\n",
       "    -67.34120677104647,\n",
       "    -45.27211281435348,\n",
       "    -64.92274948533978,\n",
       "    -60.01084780186193,\n",
       "    -70.35551454314103,\n",
       "    -67.04269846245339,\n",
       "    -67.67423653502495,\n",
       "    -75.45020372077695,\n",
       "    -50.54257778986077,\n",
       "    -54.16110622248656,\n",
       "    -79.88430569824963,\n",
       "    -65.34586292581203,\n",
       "    -70.20312990270217,\n",
       "    -73.78166229011286,\n",
       "    -67.59548377611142,\n",
       "    -61.75224441422762,\n",
       "    -65.20215038466537,\n",
       "    -76.00759868898776,\n",
       "    -72.9247807096126,\n",
       "    -68.89239951417063,\n",
       "    -75.21905351908418,\n",
       "    -61.994068151915805,\n",
       "    -65.36823463056436,\n",
       "    -66.97523795366176,\n",
       "    -71.27523738764536,\n",
       "    -65.74296697348875,\n",
       "    -69.30673420916959,\n",
       "    -58.360655493573034,\n",
       "    -72.67013419453232,\n",
       "    -62.47209986980434,\n",
       "    -88.92140680896807,\n",
       "    -67.53650954658097,\n",
       "    -63.78585163781674,\n",
       "    -68.97483836758666,\n",
       "    -63.44741985878155,\n",
       "    -65.60987363603229,\n",
       "    -67.80090979609282,\n",
       "    -59.87242313675106,\n",
       "    -63.433225619954065],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22131622838736495,\n",
       "   'mean_inference_ms': 0.5640579882050828,\n",
       "   'mean_action_processing_ms': 0.07595617313897893,\n",
       "   'mean_env_wait_ms': 1.14937243428215,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 57000,\n",
       "  'agent_timesteps_total': 57000,\n",
       "  'timers': {'learn_time_ms': 1.361, 'learn_throughput': 73465.704},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -11.821211,\n",
       "     'max_q': -4.0750976,\n",
       "     'min_q': -19.571852,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 57000,\n",
       "   'num_agent_steps_sampled': 57000,\n",
       "   'num_steps_trained': 5550100,\n",
       "   'num_agent_steps_trained': 5550100,\n",
       "   'last_target_update_ts': 57000,\n",
       "   'num_target_updates': 55501},\n",
       "  'done': False,\n",
       "  'episodes_total': 564,\n",
       "  'training_iteration': 38,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-03-09',\n",
       "  'timestamp': 1625500989,\n",
       "  'time_this_iter_s': 20.038901805877686,\n",
       "  'time_total_s': 732.3468499183655,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 732.3468499183655,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 38,\n",
       "  'perf': {'cpu_util_percent': 11.907407407407412,\n",
       "   'ram_util_percent': 45.9925925925926,\n",
       "   'gpu_util_percent0': 0.26037037037037036,\n",
       "   'vram_util_percent0': 0.527429756527174}},\n",
       " {'episode_reward_max': -37.747639697115204,\n",
       "  'episode_reward_min': -88.92140680896807,\n",
       "  'episode_reward_mean': -66.22494586877399,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-42.502694733262786,\n",
       "    -57.71953999273898,\n",
       "    -77.39341731256027,\n",
       "    -63.72068275285816,\n",
       "    -66.90717562698903,\n",
       "    -62.48422792175958,\n",
       "    -59.32900010978818,\n",
       "    -68.98336597151214,\n",
       "    -63.54075376641473,\n",
       "    -44.190877260170666,\n",
       "    -67.82606375390073,\n",
       "    -67.9851565945453,\n",
       "    -65.2977318763192,\n",
       "    -65.75603497242565,\n",
       "    -63.59310525115048,\n",
       "    -66.49468090535332,\n",
       "    -54.15274898666783,\n",
       "    -59.51502392512422,\n",
       "    -66.68603624175454,\n",
       "    -76.90956487988947,\n",
       "    -66.15916674017785,\n",
       "    -69.52381248641709,\n",
       "    -65.01865884083442,\n",
       "    -70.20372550169134,\n",
       "    -66.77056901771432,\n",
       "    -71.56687028499628,\n",
       "    -73.06573454258019,\n",
       "    -70.52039054583024,\n",
       "    -70.72167689242387,\n",
       "    -66.19107191299508,\n",
       "    -62.8775250598776,\n",
       "    -56.48969131940902,\n",
       "    -72.5733925426211,\n",
       "    -68.70800545098692,\n",
       "    -71.9543881027349,\n",
       "    -72.54158186741661,\n",
       "    -64.22717838632367,\n",
       "    -59.04237029526044,\n",
       "    -60.22780890467796,\n",
       "    -66.3012481714492,\n",
       "    -75.3592120390615,\n",
       "    -62.49582764537123,\n",
       "    -60.31278610482156,\n",
       "    -37.747639697115204,\n",
       "    -67.31463863581604,\n",
       "    -76.67877169024516,\n",
       "    -67.34120677104647,\n",
       "    -45.27211281435348,\n",
       "    -64.92274948533978,\n",
       "    -60.01084780186193,\n",
       "    -70.35551454314103,\n",
       "    -67.04269846245339,\n",
       "    -67.67423653502495,\n",
       "    -75.45020372077695,\n",
       "    -50.54257778986077,\n",
       "    -54.16110622248656,\n",
       "    -79.88430569824963,\n",
       "    -65.34586292581203,\n",
       "    -70.20312990270217,\n",
       "    -73.78166229011286,\n",
       "    -67.59548377611142,\n",
       "    -61.75224441422762,\n",
       "    -65.20215038466537,\n",
       "    -76.00759868898776,\n",
       "    -72.9247807096126,\n",
       "    -68.89239951417063,\n",
       "    -75.21905351908418,\n",
       "    -61.994068151915805,\n",
       "    -65.36823463056436,\n",
       "    -66.97523795366176,\n",
       "    -71.27523738764536,\n",
       "    -65.74296697348875,\n",
       "    -69.30673420916959,\n",
       "    -58.360655493573034,\n",
       "    -72.67013419453232,\n",
       "    -62.47209986980434,\n",
       "    -88.92140680896807,\n",
       "    -67.53650954658097,\n",
       "    -63.78585163781674,\n",
       "    -68.97483836758666,\n",
       "    -63.44741985878155,\n",
       "    -65.60987363603229,\n",
       "    -67.80090979609282,\n",
       "    -59.87242313675106,\n",
       "    -63.433225619954065,\n",
       "    -66.76489361213189,\n",
       "    -65.75468226428093,\n",
       "    -83.91723186407181,\n",
       "    -59.548982114902486,\n",
       "    -67.71222740865889,\n",
       "    -71.92776422843392,\n",
       "    -65.2188028592909,\n",
       "    -74.64805012377369,\n",
       "    -74.05917138285648,\n",
       "    -66.54948073379165,\n",
       "    -60.97740488239042,\n",
       "    -67.40071346946056,\n",
       "    -70.71416195327492,\n",
       "    -66.28331326480092,\n",
       "    -72.30632795824354],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2212234253882538,\n",
       "   'mean_inference_ms': 0.5644497584631875,\n",
       "   'mean_action_processing_ms': 0.07592676643570355,\n",
       "   'mean_env_wait_ms': 1.1458287817326605,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 58500,\n",
       "  'agent_timesteps_total': 58500,\n",
       "  'timers': {'learn_time_ms': 1.423, 'learn_throughput': 70289.315},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.857622,\n",
       "     'max_q': -3.1218271,\n",
       "     'min_q': -23.260267,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 58500,\n",
       "   'num_agent_steps_sampled': 58500,\n",
       "   'num_steps_trained': 5700100,\n",
       "   'num_agent_steps_trained': 5700100,\n",
       "   'last_target_update_ts': 58500,\n",
       "   'num_target_updates': 57001},\n",
       "  'done': False,\n",
       "  'episodes_total': 579,\n",
       "  'training_iteration': 39,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-03-29',\n",
       "  'timestamp': 1625501009,\n",
       "  'time_this_iter_s': 19.643303871154785,\n",
       "  'time_total_s': 751.9901537895203,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 751.9901537895203,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 39,\n",
       "  'perf': {'cpu_util_percent': 12.053846153846155,\n",
       "   'ram_util_percent': 46.0,\n",
       "   'gpu_util_percent0': 0.23346153846153847,\n",
       "   'vram_util_percent0': 0.5276045866687646}},\n",
       " {'episode_reward_max': -37.747639697115204,\n",
       "  'episode_reward_min': -88.92140680896807,\n",
       "  'episode_reward_mean': -67.31819644475742,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-66.49468090535332,\n",
       "    -54.15274898666783,\n",
       "    -59.51502392512422,\n",
       "    -66.68603624175454,\n",
       "    -76.90956487988947,\n",
       "    -66.15916674017785,\n",
       "    -69.52381248641709,\n",
       "    -65.01865884083442,\n",
       "    -70.20372550169134,\n",
       "    -66.77056901771432,\n",
       "    -71.56687028499628,\n",
       "    -73.06573454258019,\n",
       "    -70.52039054583024,\n",
       "    -70.72167689242387,\n",
       "    -66.19107191299508,\n",
       "    -62.8775250598776,\n",
       "    -56.48969131940902,\n",
       "    -72.5733925426211,\n",
       "    -68.70800545098692,\n",
       "    -71.9543881027349,\n",
       "    -72.54158186741661,\n",
       "    -64.22717838632367,\n",
       "    -59.04237029526044,\n",
       "    -60.22780890467796,\n",
       "    -66.3012481714492,\n",
       "    -75.3592120390615,\n",
       "    -62.49582764537123,\n",
       "    -60.31278610482156,\n",
       "    -37.747639697115204,\n",
       "    -67.31463863581604,\n",
       "    -76.67877169024516,\n",
       "    -67.34120677104647,\n",
       "    -45.27211281435348,\n",
       "    -64.92274948533978,\n",
       "    -60.01084780186193,\n",
       "    -70.35551454314103,\n",
       "    -67.04269846245339,\n",
       "    -67.67423653502495,\n",
       "    -75.45020372077695,\n",
       "    -50.54257778986077,\n",
       "    -54.16110622248656,\n",
       "    -79.88430569824963,\n",
       "    -65.34586292581203,\n",
       "    -70.20312990270217,\n",
       "    -73.78166229011286,\n",
       "    -67.59548377611142,\n",
       "    -61.75224441422762,\n",
       "    -65.20215038466537,\n",
       "    -76.00759868898776,\n",
       "    -72.9247807096126,\n",
       "    -68.89239951417063,\n",
       "    -75.21905351908418,\n",
       "    -61.994068151915805,\n",
       "    -65.36823463056436,\n",
       "    -66.97523795366176,\n",
       "    -71.27523738764536,\n",
       "    -65.74296697348875,\n",
       "    -69.30673420916959,\n",
       "    -58.360655493573034,\n",
       "    -72.67013419453232,\n",
       "    -62.47209986980434,\n",
       "    -88.92140680896807,\n",
       "    -67.53650954658097,\n",
       "    -63.78585163781674,\n",
       "    -68.97483836758666,\n",
       "    -63.44741985878155,\n",
       "    -65.60987363603229,\n",
       "    -67.80090979609282,\n",
       "    -59.87242313675106,\n",
       "    -63.433225619954065,\n",
       "    -66.76489361213189,\n",
       "    -65.75468226428093,\n",
       "    -83.91723186407181,\n",
       "    -59.548982114902486,\n",
       "    -67.71222740865889,\n",
       "    -71.92776422843392,\n",
       "    -65.2188028592909,\n",
       "    -74.64805012377369,\n",
       "    -74.05917138285648,\n",
       "    -66.54948073379165,\n",
       "    -60.97740488239042,\n",
       "    -67.40071346946056,\n",
       "    -70.71416195327492,\n",
       "    -66.28331326480092,\n",
       "    -72.30632795824354,\n",
       "    -71.24728295595466,\n",
       "    -67.52106366845697,\n",
       "    -58.7885504324811,\n",
       "    -85.92085305241378,\n",
       "    -68.28700442657136,\n",
       "    -68.84254456992046,\n",
       "    -61.27227265351238,\n",
       "    -66.03951349256266,\n",
       "    -65.24183622614007,\n",
       "    -74.85103698957673,\n",
       "    -68.52769275108291,\n",
       "    -74.07538332387415,\n",
       "    -72.53323370130279,\n",
       "    -72.15940609068065,\n",
       "    -71.24721116020925],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22113617478249523,\n",
       "   'mean_inference_ms': 0.564795764449229,\n",
       "   'mean_action_processing_ms': 0.0758962072445214,\n",
       "   'mean_env_wait_ms': 1.1421710412676969,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 60000,\n",
       "  'agent_timesteps_total': 60000,\n",
       "  'timers': {'learn_time_ms': 1.415, 'learn_throughput': 70659.95},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.563219,\n",
       "     'max_q': -3.7748075,\n",
       "     'min_q': -19.910189,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 60000,\n",
       "   'num_agent_steps_sampled': 60000,\n",
       "   'num_steps_trained': 5850100,\n",
       "   'num_agent_steps_trained': 5850100,\n",
       "   'last_target_update_ts': 60000,\n",
       "   'num_target_updates': 58501},\n",
       "  'done': False,\n",
       "  'episodes_total': 594,\n",
       "  'training_iteration': 40,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-03-49',\n",
       "  'timestamp': 1625501029,\n",
       "  'time_this_iter_s': 19.644579648971558,\n",
       "  'time_total_s': 771.6347334384918,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 771.6347334384918,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 40,\n",
       "  'perf': {'cpu_util_percent': 12.176923076923078,\n",
       "   'ram_util_percent': 46.00769230769231,\n",
       "   'gpu_util_percent0': 0.26692307692307693,\n",
       "   'vram_util_percent0': 0.5275259131050489}},\n",
       " {'episode_reward_max': -37.747639697115204,\n",
       "  'episode_reward_min': -88.92140680896807,\n",
       "  'episode_reward_mean': -67.17156906544234,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 14,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-66.19107191299508,\n",
       "    -62.8775250598776,\n",
       "    -56.48969131940902,\n",
       "    -72.5733925426211,\n",
       "    -68.70800545098692,\n",
       "    -71.9543881027349,\n",
       "    -72.54158186741661,\n",
       "    -64.22717838632367,\n",
       "    -59.04237029526044,\n",
       "    -60.22780890467796,\n",
       "    -66.3012481714492,\n",
       "    -75.3592120390615,\n",
       "    -62.49582764537123,\n",
       "    -60.31278610482156,\n",
       "    -37.747639697115204,\n",
       "    -67.31463863581604,\n",
       "    -76.67877169024516,\n",
       "    -67.34120677104647,\n",
       "    -45.27211281435348,\n",
       "    -64.92274948533978,\n",
       "    -60.01084780186193,\n",
       "    -70.35551454314103,\n",
       "    -67.04269846245339,\n",
       "    -67.67423653502495,\n",
       "    -75.45020372077695,\n",
       "    -50.54257778986077,\n",
       "    -54.16110622248656,\n",
       "    -79.88430569824963,\n",
       "    -65.34586292581203,\n",
       "    -70.20312990270217,\n",
       "    -73.78166229011286,\n",
       "    -67.59548377611142,\n",
       "    -61.75224441422762,\n",
       "    -65.20215038466537,\n",
       "    -76.00759868898776,\n",
       "    -72.9247807096126,\n",
       "    -68.89239951417063,\n",
       "    -75.21905351908418,\n",
       "    -61.994068151915805,\n",
       "    -65.36823463056436,\n",
       "    -66.97523795366176,\n",
       "    -71.27523738764536,\n",
       "    -65.74296697348875,\n",
       "    -69.30673420916959,\n",
       "    -58.360655493573034,\n",
       "    -72.67013419453232,\n",
       "    -62.47209986980434,\n",
       "    -88.92140680896807,\n",
       "    -67.53650954658097,\n",
       "    -63.78585163781674,\n",
       "    -68.97483836758666,\n",
       "    -63.44741985878155,\n",
       "    -65.60987363603229,\n",
       "    -67.80090979609282,\n",
       "    -59.87242313675106,\n",
       "    -63.433225619954065,\n",
       "    -66.76489361213189,\n",
       "    -65.75468226428093,\n",
       "    -83.91723186407181,\n",
       "    -59.548982114902486,\n",
       "    -67.71222740865889,\n",
       "    -71.92776422843392,\n",
       "    -65.2188028592909,\n",
       "    -74.64805012377369,\n",
       "    -74.05917138285648,\n",
       "    -66.54948073379165,\n",
       "    -60.97740488239042,\n",
       "    -67.40071346946056,\n",
       "    -70.71416195327492,\n",
       "    -66.28331326480092,\n",
       "    -72.30632795824354,\n",
       "    -71.24728295595466,\n",
       "    -67.52106366845697,\n",
       "    -58.7885504324811,\n",
       "    -85.92085305241378,\n",
       "    -68.28700442657136,\n",
       "    -68.84254456992046,\n",
       "    -61.27227265351238,\n",
       "    -66.03951349256266,\n",
       "    -65.24183622614007,\n",
       "    -74.85103698957673,\n",
       "    -68.52769275108291,\n",
       "    -74.07538332387415,\n",
       "    -72.53323370130279,\n",
       "    -72.15940609068065,\n",
       "    -71.24721116020925,\n",
       "    -65.84494822732148,\n",
       "    -42.3205717568607,\n",
       "    -70.21178734368536,\n",
       "    -74.15950160992652,\n",
       "    -79.0236589222395,\n",
       "    -68.30722337007596,\n",
       "    -46.420155794260474,\n",
       "    -68.7166102764315,\n",
       "    -61.498561960441144,\n",
       "    -69.27041350047436,\n",
       "    -79.06978136363395,\n",
       "    -73.68106829544075,\n",
       "    -65.12012869625096,\n",
       "    -69.00151074290372],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22106476566295355,\n",
       "   'mean_inference_ms': 0.5650709018363633,\n",
       "   'mean_action_processing_ms': 0.07586913648250024,\n",
       "   'mean_env_wait_ms': 1.1389160024393448,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 61500,\n",
       "  'agent_timesteps_total': 61500,\n",
       "  'timers': {'learn_time_ms': 1.53, 'learn_throughput': 65347.106},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.560594,\n",
       "     'max_q': -3.93329,\n",
       "     'min_q': -21.45335,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 61500,\n",
       "   'num_agent_steps_sampled': 61500,\n",
       "   'num_steps_trained': 6000100,\n",
       "   'num_agent_steps_trained': 6000100,\n",
       "   'last_target_update_ts': 61500,\n",
       "   'num_target_updates': 60001},\n",
       "  'done': False,\n",
       "  'episodes_total': 608,\n",
       "  'training_iteration': 41,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-04-09',\n",
       "  'timestamp': 1625501049,\n",
       "  'time_this_iter_s': 20.01934313774109,\n",
       "  'time_total_s': 791.6540765762329,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 791.6540765762329,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 41,\n",
       "  'perf': {'cpu_util_percent': 11.929629629629629,\n",
       "   'ram_util_percent': 46.096296296296295,\n",
       "   'gpu_util_percent0': 0.24037037037037035,\n",
       "   'vram_util_percent0': 0.527429756527174}},\n",
       " {'episode_reward_max': -34.11397507377022,\n",
       "  'episode_reward_min': -88.92140680896807,\n",
       "  'episode_reward_mean': -66.53269850865007,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-67.31463863581604,\n",
       "    -76.67877169024516,\n",
       "    -67.34120677104647,\n",
       "    -45.27211281435348,\n",
       "    -64.92274948533978,\n",
       "    -60.01084780186193,\n",
       "    -70.35551454314103,\n",
       "    -67.04269846245339,\n",
       "    -67.67423653502495,\n",
       "    -75.45020372077695,\n",
       "    -50.54257778986077,\n",
       "    -54.16110622248656,\n",
       "    -79.88430569824963,\n",
       "    -65.34586292581203,\n",
       "    -70.20312990270217,\n",
       "    -73.78166229011286,\n",
       "    -67.59548377611142,\n",
       "    -61.75224441422762,\n",
       "    -65.20215038466537,\n",
       "    -76.00759868898776,\n",
       "    -72.9247807096126,\n",
       "    -68.89239951417063,\n",
       "    -75.21905351908418,\n",
       "    -61.994068151915805,\n",
       "    -65.36823463056436,\n",
       "    -66.97523795366176,\n",
       "    -71.27523738764536,\n",
       "    -65.74296697348875,\n",
       "    -69.30673420916959,\n",
       "    -58.360655493573034,\n",
       "    -72.67013419453232,\n",
       "    -62.47209986980434,\n",
       "    -88.92140680896807,\n",
       "    -67.53650954658097,\n",
       "    -63.78585163781674,\n",
       "    -68.97483836758666,\n",
       "    -63.44741985878155,\n",
       "    -65.60987363603229,\n",
       "    -67.80090979609282,\n",
       "    -59.87242313675106,\n",
       "    -63.433225619954065,\n",
       "    -66.76489361213189,\n",
       "    -65.75468226428093,\n",
       "    -83.91723186407181,\n",
       "    -59.548982114902486,\n",
       "    -67.71222740865889,\n",
       "    -71.92776422843392,\n",
       "    -65.2188028592909,\n",
       "    -74.64805012377369,\n",
       "    -74.05917138285648,\n",
       "    -66.54948073379165,\n",
       "    -60.97740488239042,\n",
       "    -67.40071346946056,\n",
       "    -70.71416195327492,\n",
       "    -66.28331326480092,\n",
       "    -72.30632795824354,\n",
       "    -71.24728295595466,\n",
       "    -67.52106366845697,\n",
       "    -58.7885504324811,\n",
       "    -85.92085305241378,\n",
       "    -68.28700442657136,\n",
       "    -68.84254456992046,\n",
       "    -61.27227265351238,\n",
       "    -66.03951349256266,\n",
       "    -65.24183622614007,\n",
       "    -74.85103698957673,\n",
       "    -68.52769275108291,\n",
       "    -74.07538332387415,\n",
       "    -72.53323370130279,\n",
       "    -72.15940609068065,\n",
       "    -71.24721116020925,\n",
       "    -65.84494822732148,\n",
       "    -42.3205717568607,\n",
       "    -70.21178734368536,\n",
       "    -74.15950160992652,\n",
       "    -79.0236589222395,\n",
       "    -68.30722337007596,\n",
       "    -46.420155794260474,\n",
       "    -68.7166102764315,\n",
       "    -61.498561960441144,\n",
       "    -69.27041350047436,\n",
       "    -79.06978136363395,\n",
       "    -73.68106829544075,\n",
       "    -65.12012869625096,\n",
       "    -69.00151074290372,\n",
       "    -70.35019510026886,\n",
       "    -63.082196811192816,\n",
       "    -67.29101247057643,\n",
       "    -69.99206466519578,\n",
       "    -69.81139871533459,\n",
       "    -66.64992386994278,\n",
       "    -61.38482079626027,\n",
       "    -71.42998534748261,\n",
       "    -41.06942514965267,\n",
       "    -74.95730634864397,\n",
       "    -62.10098210617976,\n",
       "    -49.491021309294,\n",
       "    -39.954442556155115,\n",
       "    -51.48392150094405,\n",
       "    -34.11397507377022],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22099346793701535,\n",
       "   'mean_inference_ms': 0.5652296834456233,\n",
       "   'mean_action_processing_ms': 0.07583987856676681,\n",
       "   'mean_env_wait_ms': 1.1356316294047455,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 63000,\n",
       "  'agent_timesteps_total': 63000,\n",
       "  'timers': {'learn_time_ms': 1.367, 'learn_throughput': 73163.271},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.909521,\n",
       "     'max_q': -4.635729,\n",
       "     'min_q': -25.966063,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 63000,\n",
       "   'num_agent_steps_sampled': 63000,\n",
       "   'num_steps_trained': 6150100,\n",
       "   'num_agent_steps_trained': 6150100,\n",
       "   'last_target_update_ts': 63000,\n",
       "   'num_target_updates': 61501},\n",
       "  'done': False,\n",
       "  'episodes_total': 623,\n",
       "  'training_iteration': 42,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-04-28',\n",
       "  'timestamp': 1625501068,\n",
       "  'time_this_iter_s': 19.765257835388184,\n",
       "  'time_total_s': 811.4193344116211,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 811.4193344116211,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 42,\n",
       "  'perf': {'cpu_util_percent': 12.088461538461537,\n",
       "   'ram_util_percent': 46.107692307692304,\n",
       "   'gpu_util_percent0': 0.23615384615384613,\n",
       "   'vram_util_percent0': 0.5275259131050489}},\n",
       " {'episode_reward_max': -34.11397507377022,\n",
       "  'episode_reward_min': -88.92140680896807,\n",
       "  'episode_reward_mean': -66.65564622171145,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-73.78166229011286,\n",
       "    -67.59548377611142,\n",
       "    -61.75224441422762,\n",
       "    -65.20215038466537,\n",
       "    -76.00759868898776,\n",
       "    -72.9247807096126,\n",
       "    -68.89239951417063,\n",
       "    -75.21905351908418,\n",
       "    -61.994068151915805,\n",
       "    -65.36823463056436,\n",
       "    -66.97523795366176,\n",
       "    -71.27523738764536,\n",
       "    -65.74296697348875,\n",
       "    -69.30673420916959,\n",
       "    -58.360655493573034,\n",
       "    -72.67013419453232,\n",
       "    -62.47209986980434,\n",
       "    -88.92140680896807,\n",
       "    -67.53650954658097,\n",
       "    -63.78585163781674,\n",
       "    -68.97483836758666,\n",
       "    -63.44741985878155,\n",
       "    -65.60987363603229,\n",
       "    -67.80090979609282,\n",
       "    -59.87242313675106,\n",
       "    -63.433225619954065,\n",
       "    -66.76489361213189,\n",
       "    -65.75468226428093,\n",
       "    -83.91723186407181,\n",
       "    -59.548982114902486,\n",
       "    -67.71222740865889,\n",
       "    -71.92776422843392,\n",
       "    -65.2188028592909,\n",
       "    -74.64805012377369,\n",
       "    -74.05917138285648,\n",
       "    -66.54948073379165,\n",
       "    -60.97740488239042,\n",
       "    -67.40071346946056,\n",
       "    -70.71416195327492,\n",
       "    -66.28331326480092,\n",
       "    -72.30632795824354,\n",
       "    -71.24728295595466,\n",
       "    -67.52106366845697,\n",
       "    -58.7885504324811,\n",
       "    -85.92085305241378,\n",
       "    -68.28700442657136,\n",
       "    -68.84254456992046,\n",
       "    -61.27227265351238,\n",
       "    -66.03951349256266,\n",
       "    -65.24183622614007,\n",
       "    -74.85103698957673,\n",
       "    -68.52769275108291,\n",
       "    -74.07538332387415,\n",
       "    -72.53323370130279,\n",
       "    -72.15940609068065,\n",
       "    -71.24721116020925,\n",
       "    -65.84494822732148,\n",
       "    -42.3205717568607,\n",
       "    -70.21178734368536,\n",
       "    -74.15950160992652,\n",
       "    -79.0236589222395,\n",
       "    -68.30722337007596,\n",
       "    -46.420155794260474,\n",
       "    -68.7166102764315,\n",
       "    -61.498561960441144,\n",
       "    -69.27041350047436,\n",
       "    -79.06978136363395,\n",
       "    -73.68106829544075,\n",
       "    -65.12012869625096,\n",
       "    -69.00151074290372,\n",
       "    -70.35019510026886,\n",
       "    -63.082196811192816,\n",
       "    -67.29101247057643,\n",
       "    -69.99206466519578,\n",
       "    -69.81139871533459,\n",
       "    -66.64992386994278,\n",
       "    -61.38482079626027,\n",
       "    -71.42998534748261,\n",
       "    -41.06942514965267,\n",
       "    -74.95730634864397,\n",
       "    -62.10098210617976,\n",
       "    -49.491021309294,\n",
       "    -39.954442556155115,\n",
       "    -51.48392150094405,\n",
       "    -34.11397507377022,\n",
       "    -79.67184497418208,\n",
       "    -72.07095141483799,\n",
       "    -75.37012630514975,\n",
       "    -75.60207586906708,\n",
       "    -66.02733709535707,\n",
       "    -50.60328710599267,\n",
       "    -57.42665354812507,\n",
       "    -69.52059224867322,\n",
       "    -63.59025892294064,\n",
       "    -70.47725818047971,\n",
       "    -71.5097163998363,\n",
       "    -71.55254641060989,\n",
       "    -63.429878433809776,\n",
       "    -41.506403067295814,\n",
       "    -66.13580432895276],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22094229278039187,\n",
       "   'mean_inference_ms': 0.5655746122363429,\n",
       "   'mean_action_processing_ms': 0.07582490756832504,\n",
       "   'mean_env_wait_ms': 1.1325048663195962,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 64500,\n",
       "  'agent_timesteps_total': 64500,\n",
       "  'timers': {'learn_time_ms': 1.503, 'learn_throughput': 66544.566},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.887587,\n",
       "     'max_q': -4.233934,\n",
       "     'min_q': -21.045341,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 64500,\n",
       "   'num_agent_steps_sampled': 64500,\n",
       "   'num_steps_trained': 6300100,\n",
       "   'num_agent_steps_trained': 6300100,\n",
       "   'last_target_update_ts': 64500,\n",
       "   'num_target_updates': 63001},\n",
       "  'done': False,\n",
       "  'episodes_total': 638,\n",
       "  'training_iteration': 43,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-04-48',\n",
       "  'timestamp': 1625501088,\n",
       "  'time_this_iter_s': 20.124884605407715,\n",
       "  'time_total_s': 831.5442190170288,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 831.5442190170288,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 43,\n",
       "  'perf': {'cpu_util_percent': 13.025925925925925,\n",
       "   'ram_util_percent': 46.496296296296286,\n",
       "   'gpu_util_percent0': 0.21888888888888888,\n",
       "   'vram_util_percent0': 0.49776035304033256}},\n",
       " {'episode_reward_max': -34.11397507377022,\n",
       "  'episode_reward_min': -109.8198102691455,\n",
       "  'episode_reward_mean': -66.27437607944127,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-72.67013419453232,\n",
       "    -62.47209986980434,\n",
       "    -88.92140680896807,\n",
       "    -67.53650954658097,\n",
       "    -63.78585163781674,\n",
       "    -68.97483836758666,\n",
       "    -63.44741985878155,\n",
       "    -65.60987363603229,\n",
       "    -67.80090979609282,\n",
       "    -59.87242313675106,\n",
       "    -63.433225619954065,\n",
       "    -66.76489361213189,\n",
       "    -65.75468226428093,\n",
       "    -83.91723186407181,\n",
       "    -59.548982114902486,\n",
       "    -67.71222740865889,\n",
       "    -71.92776422843392,\n",
       "    -65.2188028592909,\n",
       "    -74.64805012377369,\n",
       "    -74.05917138285648,\n",
       "    -66.54948073379165,\n",
       "    -60.97740488239042,\n",
       "    -67.40071346946056,\n",
       "    -70.71416195327492,\n",
       "    -66.28331326480092,\n",
       "    -72.30632795824354,\n",
       "    -71.24728295595466,\n",
       "    -67.52106366845697,\n",
       "    -58.7885504324811,\n",
       "    -85.92085305241378,\n",
       "    -68.28700442657136,\n",
       "    -68.84254456992046,\n",
       "    -61.27227265351238,\n",
       "    -66.03951349256266,\n",
       "    -65.24183622614007,\n",
       "    -74.85103698957673,\n",
       "    -68.52769275108291,\n",
       "    -74.07538332387415,\n",
       "    -72.53323370130279,\n",
       "    -72.15940609068065,\n",
       "    -71.24721116020925,\n",
       "    -65.84494822732148,\n",
       "    -42.3205717568607,\n",
       "    -70.21178734368536,\n",
       "    -74.15950160992652,\n",
       "    -79.0236589222395,\n",
       "    -68.30722337007596,\n",
       "    -46.420155794260474,\n",
       "    -68.7166102764315,\n",
       "    -61.498561960441144,\n",
       "    -69.27041350047436,\n",
       "    -79.06978136363395,\n",
       "    -73.68106829544075,\n",
       "    -65.12012869625096,\n",
       "    -69.00151074290372,\n",
       "    -70.35019510026886,\n",
       "    -63.082196811192816,\n",
       "    -67.29101247057643,\n",
       "    -69.99206466519578,\n",
       "    -69.81139871533459,\n",
       "    -66.64992386994278,\n",
       "    -61.38482079626027,\n",
       "    -71.42998534748261,\n",
       "    -41.06942514965267,\n",
       "    -74.95730634864397,\n",
       "    -62.10098210617976,\n",
       "    -49.491021309294,\n",
       "    -39.954442556155115,\n",
       "    -51.48392150094405,\n",
       "    -34.11397507377022,\n",
       "    -79.67184497418208,\n",
       "    -72.07095141483799,\n",
       "    -75.37012630514975,\n",
       "    -75.60207586906708,\n",
       "    -66.02733709535707,\n",
       "    -50.60328710599267,\n",
       "    -57.42665354812507,\n",
       "    -69.52059224867322,\n",
       "    -63.59025892294064,\n",
       "    -70.47725818047971,\n",
       "    -71.5097163998363,\n",
       "    -71.55254641060989,\n",
       "    -63.429878433809776,\n",
       "    -41.506403067295814,\n",
       "    -66.13580432895276,\n",
       "    -63.852602229840905,\n",
       "    -58.60631929083194,\n",
       "    -62.374679881729584,\n",
       "    -66.94087200657685,\n",
       "    -74.09086739260715,\n",
       "    -49.93483509305261,\n",
       "    -69.45400811223324,\n",
       "    -62.08495055171867,\n",
       "    -63.70719055257781,\n",
       "    -109.8198102691455,\n",
       "    -49.56564015714066,\n",
       "    -65.00697809566041,\n",
       "    -66.24835559076348,\n",
       "    -74.55214832230064,\n",
       "    -46.032236323793796],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.220904316435219,\n",
       "   'mean_inference_ms': 0.5659516849730273,\n",
       "   'mean_action_processing_ms': 0.07581747278267592,\n",
       "   'mean_env_wait_ms': 1.1295211833378185,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 66000,\n",
       "  'agent_timesteps_total': 66000,\n",
       "  'timers': {'learn_time_ms': 1.502, 'learn_throughput': 66568.857},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.912698,\n",
       "     'max_q': -4.303664,\n",
       "     'min_q': -20.948635,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 66000,\n",
       "   'num_agent_steps_sampled': 66000,\n",
       "   'num_steps_trained': 6450100,\n",
       "   'num_agent_steps_trained': 6450100,\n",
       "   'last_target_update_ts': 66000,\n",
       "   'num_target_updates': 64501},\n",
       "  'done': False,\n",
       "  'episodes_total': 653,\n",
       "  'training_iteration': 44,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-05-08',\n",
       "  'timestamp': 1625501108,\n",
       "  'time_this_iter_s': 19.88532519340515,\n",
       "  'time_total_s': 851.429544210434,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 851.429544210434,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 44,\n",
       "  'perf': {'cpu_util_percent': 12.842307692307694,\n",
       "   'ram_util_percent': 46.642307692307696,\n",
       "   'gpu_util_percent0': 0.20307692307692313,\n",
       "   'vram_util_percent0': 0.49397163818028045}},\n",
       " {'episode_reward_max': -30.15886793138822,\n",
       "  'episode_reward_min': -126.84991304492816,\n",
       "  'episode_reward_mean': -66.50540548552024,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-67.71222740865889,\n",
       "    -71.92776422843392,\n",
       "    -65.2188028592909,\n",
       "    -74.64805012377369,\n",
       "    -74.05917138285648,\n",
       "    -66.54948073379165,\n",
       "    -60.97740488239042,\n",
       "    -67.40071346946056,\n",
       "    -70.71416195327492,\n",
       "    -66.28331326480092,\n",
       "    -72.30632795824354,\n",
       "    -71.24728295595466,\n",
       "    -67.52106366845697,\n",
       "    -58.7885504324811,\n",
       "    -85.92085305241378,\n",
       "    -68.28700442657136,\n",
       "    -68.84254456992046,\n",
       "    -61.27227265351238,\n",
       "    -66.03951349256266,\n",
       "    -65.24183622614007,\n",
       "    -74.85103698957673,\n",
       "    -68.52769275108291,\n",
       "    -74.07538332387415,\n",
       "    -72.53323370130279,\n",
       "    -72.15940609068065,\n",
       "    -71.24721116020925,\n",
       "    -65.84494822732148,\n",
       "    -42.3205717568607,\n",
       "    -70.21178734368536,\n",
       "    -74.15950160992652,\n",
       "    -79.0236589222395,\n",
       "    -68.30722337007596,\n",
       "    -46.420155794260474,\n",
       "    -68.7166102764315,\n",
       "    -61.498561960441144,\n",
       "    -69.27041350047436,\n",
       "    -79.06978136363395,\n",
       "    -73.68106829544075,\n",
       "    -65.12012869625096,\n",
       "    -69.00151074290372,\n",
       "    -70.35019510026886,\n",
       "    -63.082196811192816,\n",
       "    -67.29101247057643,\n",
       "    -69.99206466519578,\n",
       "    -69.81139871533459,\n",
       "    -66.64992386994278,\n",
       "    -61.38482079626027,\n",
       "    -71.42998534748261,\n",
       "    -41.06942514965267,\n",
       "    -74.95730634864397,\n",
       "    -62.10098210617976,\n",
       "    -49.491021309294,\n",
       "    -39.954442556155115,\n",
       "    -51.48392150094405,\n",
       "    -34.11397507377022,\n",
       "    -79.67184497418208,\n",
       "    -72.07095141483799,\n",
       "    -75.37012630514975,\n",
       "    -75.60207586906708,\n",
       "    -66.02733709535707,\n",
       "    -50.60328710599267,\n",
       "    -57.42665354812507,\n",
       "    -69.52059224867322,\n",
       "    -63.59025892294064,\n",
       "    -70.47725818047971,\n",
       "    -71.5097163998363,\n",
       "    -71.55254641060989,\n",
       "    -63.429878433809776,\n",
       "    -41.506403067295814,\n",
       "    -66.13580432895276,\n",
       "    -63.852602229840905,\n",
       "    -58.60631929083194,\n",
       "    -62.374679881729584,\n",
       "    -66.94087200657685,\n",
       "    -74.09086739260715,\n",
       "    -49.93483509305261,\n",
       "    -69.45400811223324,\n",
       "    -62.08495055171867,\n",
       "    -63.70719055257781,\n",
       "    -109.8198102691455,\n",
       "    -49.56564015714066,\n",
       "    -65.00697809566041,\n",
       "    -66.24835559076348,\n",
       "    -74.55214832230064,\n",
       "    -46.032236323793796,\n",
       "    -58.13551420852237,\n",
       "    -66.67670238696078,\n",
       "    -50.7089244640738,\n",
       "    -98.74498843945156,\n",
       "    -72.10434672871217,\n",
       "    -42.24482652905175,\n",
       "    -62.69430701948296,\n",
       "    -107.14916354504557,\n",
       "    -70.75359347795839,\n",
       "    -50.849997000744416,\n",
       "    -76.01994657764267,\n",
       "    -62.47357494859152,\n",
       "    -30.15886793138822,\n",
       "    -68.04875663363018,\n",
       "    -126.84991304492816],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22091939843532024,\n",
       "   'mean_inference_ms': 0.5664715496524747,\n",
       "   'mean_action_processing_ms': 0.07584642762429585,\n",
       "   'mean_env_wait_ms': 1.126705978866477,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 67500,\n",
       "  'agent_timesteps_total': 67500,\n",
       "  'timers': {'learn_time_ms': 1.353, 'learn_throughput': 73922.769},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.878315,\n",
       "     'max_q': -2.8619304,\n",
       "     'min_q': -22.554676,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 67500,\n",
       "   'num_agent_steps_sampled': 67500,\n",
       "   'num_steps_trained': 6600100,\n",
       "   'num_agent_steps_trained': 6600100,\n",
       "   'last_target_update_ts': 67500,\n",
       "   'num_target_updates': 66001},\n",
       "  'done': False,\n",
       "  'episodes_total': 668,\n",
       "  'training_iteration': 45,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-05-30',\n",
       "  'timestamp': 1625501130,\n",
       "  'time_this_iter_s': 21.169085025787354,\n",
       "  'time_total_s': 872.5986292362213,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 872.5986292362213,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 45,\n",
       "  'perf': {'cpu_util_percent': 16.278571428571432,\n",
       "   'ram_util_percent': 46.842857142857135,\n",
       "   'gpu_util_percent0': 0.30500000000000005,\n",
       "   'vram_util_percent0': 0.596248675895825}},\n",
       " {'episode_reward_max': -30.15886793138822,\n",
       "  'episode_reward_min': -126.84991304492816,\n",
       "  'episode_reward_mean': -66.87663799326073,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-68.28700442657136,\n",
       "    -68.84254456992046,\n",
       "    -61.27227265351238,\n",
       "    -66.03951349256266,\n",
       "    -65.24183622614007,\n",
       "    -74.85103698957673,\n",
       "    -68.52769275108291,\n",
       "    -74.07538332387415,\n",
       "    -72.53323370130279,\n",
       "    -72.15940609068065,\n",
       "    -71.24721116020925,\n",
       "    -65.84494822732148,\n",
       "    -42.3205717568607,\n",
       "    -70.21178734368536,\n",
       "    -74.15950160992652,\n",
       "    -79.0236589222395,\n",
       "    -68.30722337007596,\n",
       "    -46.420155794260474,\n",
       "    -68.7166102764315,\n",
       "    -61.498561960441144,\n",
       "    -69.27041350047436,\n",
       "    -79.06978136363395,\n",
       "    -73.68106829544075,\n",
       "    -65.12012869625096,\n",
       "    -69.00151074290372,\n",
       "    -70.35019510026886,\n",
       "    -63.082196811192816,\n",
       "    -67.29101247057643,\n",
       "    -69.99206466519578,\n",
       "    -69.81139871533459,\n",
       "    -66.64992386994278,\n",
       "    -61.38482079626027,\n",
       "    -71.42998534748261,\n",
       "    -41.06942514965267,\n",
       "    -74.95730634864397,\n",
       "    -62.10098210617976,\n",
       "    -49.491021309294,\n",
       "    -39.954442556155115,\n",
       "    -51.48392150094405,\n",
       "    -34.11397507377022,\n",
       "    -79.67184497418208,\n",
       "    -72.07095141483799,\n",
       "    -75.37012630514975,\n",
       "    -75.60207586906708,\n",
       "    -66.02733709535707,\n",
       "    -50.60328710599267,\n",
       "    -57.42665354812507,\n",
       "    -69.52059224867322,\n",
       "    -63.59025892294064,\n",
       "    -70.47725818047971,\n",
       "    -71.5097163998363,\n",
       "    -71.55254641060989,\n",
       "    -63.429878433809776,\n",
       "    -41.506403067295814,\n",
       "    -66.13580432895276,\n",
       "    -63.852602229840905,\n",
       "    -58.60631929083194,\n",
       "    -62.374679881729584,\n",
       "    -66.94087200657685,\n",
       "    -74.09086739260715,\n",
       "    -49.93483509305261,\n",
       "    -69.45400811223324,\n",
       "    -62.08495055171867,\n",
       "    -63.70719055257781,\n",
       "    -109.8198102691455,\n",
       "    -49.56564015714066,\n",
       "    -65.00697809566041,\n",
       "    -66.24835559076348,\n",
       "    -74.55214832230064,\n",
       "    -46.032236323793796,\n",
       "    -58.13551420852237,\n",
       "    -66.67670238696078,\n",
       "    -50.7089244640738,\n",
       "    -98.74498843945156,\n",
       "    -72.10434672871217,\n",
       "    -42.24482652905175,\n",
       "    -62.69430701948296,\n",
       "    -107.14916354504557,\n",
       "    -70.75359347795839,\n",
       "    -50.849997000744416,\n",
       "    -76.01994657764267,\n",
       "    -62.47357494859152,\n",
       "    -30.15886793138822,\n",
       "    -68.04875663363018,\n",
       "    -126.84991304492816,\n",
       "    -74.09607846070311,\n",
       "    -69.9750645925157,\n",
       "    -54.11147583723851,\n",
       "    -65.5547636255394,\n",
       "    -59.40747138260858,\n",
       "    -60.37577479233005,\n",
       "    -86.51480790665295,\n",
       "    -105.03532592308878,\n",
       "    -67.78092077486856,\n",
       "    -106.79201248492402,\n",
       "    -63.95983155618549,\n",
       "    -46.36047917758843,\n",
       "    -76.81925743365036,\n",
       "    -66.03692409392941,\n",
       "    -75.57823110650784],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2209585978788401,\n",
       "   'mean_inference_ms': 0.5670354065492508,\n",
       "   'mean_action_processing_ms': 0.07589246260853755,\n",
       "   'mean_env_wait_ms': 1.1242757863285155,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 69000,\n",
       "  'agent_timesteps_total': 69000,\n",
       "  'timers': {'learn_time_ms': 1.395, 'learn_throughput': 71702.407},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.274188,\n",
       "     'max_q': -2.3358111,\n",
       "     'min_q': -21.224726,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 69000,\n",
       "   'num_agent_steps_sampled': 69000,\n",
       "   'num_steps_trained': 6750100,\n",
       "   'num_agent_steps_trained': 6750100,\n",
       "   'last_target_update_ts': 69000,\n",
       "   'num_target_updates': 67501},\n",
       "  'done': False,\n",
       "  'episodes_total': 683,\n",
       "  'training_iteration': 46,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-05-50',\n",
       "  'timestamp': 1625501150,\n",
       "  'time_this_iter_s': 20.500977516174316,\n",
       "  'time_total_s': 893.0996067523956,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 893.0996067523956,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 46,\n",
       "  'perf': {'cpu_util_percent': 14.52962962962963,\n",
       "   'ram_util_percent': 46.7111111111111,\n",
       "   'gpu_util_percent0': 0.18703703703703703,\n",
       "   'vram_util_percent0': 0.6061062340786196}},\n",
       " {'episode_reward_max': -30.15886793138822,\n",
       "  'episode_reward_min': -126.84991304492816,\n",
       "  'episode_reward_mean': -66.30909083829165,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-79.0236589222395,\n",
       "    -68.30722337007596,\n",
       "    -46.420155794260474,\n",
       "    -68.7166102764315,\n",
       "    -61.498561960441144,\n",
       "    -69.27041350047436,\n",
       "    -79.06978136363395,\n",
       "    -73.68106829544075,\n",
       "    -65.12012869625096,\n",
       "    -69.00151074290372,\n",
       "    -70.35019510026886,\n",
       "    -63.082196811192816,\n",
       "    -67.29101247057643,\n",
       "    -69.99206466519578,\n",
       "    -69.81139871533459,\n",
       "    -66.64992386994278,\n",
       "    -61.38482079626027,\n",
       "    -71.42998534748261,\n",
       "    -41.06942514965267,\n",
       "    -74.95730634864397,\n",
       "    -62.10098210617976,\n",
       "    -49.491021309294,\n",
       "    -39.954442556155115,\n",
       "    -51.48392150094405,\n",
       "    -34.11397507377022,\n",
       "    -79.67184497418208,\n",
       "    -72.07095141483799,\n",
       "    -75.37012630514975,\n",
       "    -75.60207586906708,\n",
       "    -66.02733709535707,\n",
       "    -50.60328710599267,\n",
       "    -57.42665354812507,\n",
       "    -69.52059224867322,\n",
       "    -63.59025892294064,\n",
       "    -70.47725818047971,\n",
       "    -71.5097163998363,\n",
       "    -71.55254641060989,\n",
       "    -63.429878433809776,\n",
       "    -41.506403067295814,\n",
       "    -66.13580432895276,\n",
       "    -63.852602229840905,\n",
       "    -58.60631929083194,\n",
       "    -62.374679881729584,\n",
       "    -66.94087200657685,\n",
       "    -74.09086739260715,\n",
       "    -49.93483509305261,\n",
       "    -69.45400811223324,\n",
       "    -62.08495055171867,\n",
       "    -63.70719055257781,\n",
       "    -109.8198102691455,\n",
       "    -49.56564015714066,\n",
       "    -65.00697809566041,\n",
       "    -66.24835559076348,\n",
       "    -74.55214832230064,\n",
       "    -46.032236323793796,\n",
       "    -58.13551420852237,\n",
       "    -66.67670238696078,\n",
       "    -50.7089244640738,\n",
       "    -98.74498843945156,\n",
       "    -72.10434672871217,\n",
       "    -42.24482652905175,\n",
       "    -62.69430701948296,\n",
       "    -107.14916354504557,\n",
       "    -70.75359347795839,\n",
       "    -50.849997000744416,\n",
       "    -76.01994657764267,\n",
       "    -62.47357494859152,\n",
       "    -30.15886793138822,\n",
       "    -68.04875663363018,\n",
       "    -126.84991304492816,\n",
       "    -74.09607846070311,\n",
       "    -69.9750645925157,\n",
       "    -54.11147583723851,\n",
       "    -65.5547636255394,\n",
       "    -59.40747138260858,\n",
       "    -60.37577479233005,\n",
       "    -86.51480790665295,\n",
       "    -105.03532592308878,\n",
       "    -67.78092077486856,\n",
       "    -106.79201248492402,\n",
       "    -63.95983155618549,\n",
       "    -46.36047917758843,\n",
       "    -76.81925743365036,\n",
       "    -66.03692409392941,\n",
       "    -75.57823110650784,\n",
       "    -69.68319785958708,\n",
       "    -39.57490257860542,\n",
       "    -49.795066298678705,\n",
       "    -84.70677128136006,\n",
       "    -45.89900802294432,\n",
       "    -75.07701726831834,\n",
       "    -78.49098658810924,\n",
       "    -60.840398001018094,\n",
       "    -72.49361350494091,\n",
       "    -64.1873018447736,\n",
       "    -44.02829601142887,\n",
       "    -73.6022143629266,\n",
       "    -75.11408238475855,\n",
       "    -66.98381704915644,\n",
       "    -58.38255576971574],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22099616554325344,\n",
       "   'mean_inference_ms': 0.5676524371521046,\n",
       "   'mean_action_processing_ms': 0.07593935208301254,\n",
       "   'mean_env_wait_ms': 1.1222571292147003,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 70500,\n",
       "  'agent_timesteps_total': 70500,\n",
       "  'timers': {'learn_time_ms': 1.461, 'learn_throughput': 68466.137},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.851958,\n",
       "     'max_q': -0.9363319,\n",
       "     'min_q': -22.557337,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 70500,\n",
       "   'num_agent_steps_sampled': 70500,\n",
       "   'num_steps_trained': 6900100,\n",
       "   'num_agent_steps_trained': 6900100,\n",
       "   'last_target_update_ts': 70500,\n",
       "   'num_target_updates': 69001},\n",
       "  'done': False,\n",
       "  'episodes_total': 698,\n",
       "  'training_iteration': 47,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-06-10',\n",
       "  'timestamp': 1625501170,\n",
       "  'time_this_iter_s': 20.104637622833252,\n",
       "  'time_total_s': 913.2042443752289,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 913.2042443752289,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 47,\n",
       "  'perf': {'cpu_util_percent': 12.322222222222221,\n",
       "   'ram_util_percent': 46.51111111111111,\n",
       "   'gpu_util_percent0': 0.1062962962962963,\n",
       "   'vram_util_percent0': 0.5908595888140761}},\n",
       " {'episode_reward_max': -30.15886793138822,\n",
       "  'episode_reward_min': -126.84991304492816,\n",
       "  'episode_reward_mean': -66.18153252839987,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 14,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-69.81139871533459,\n",
       "    -66.64992386994278,\n",
       "    -61.38482079626027,\n",
       "    -71.42998534748261,\n",
       "    -41.06942514965267,\n",
       "    -74.95730634864397,\n",
       "    -62.10098210617976,\n",
       "    -49.491021309294,\n",
       "    -39.954442556155115,\n",
       "    -51.48392150094405,\n",
       "    -34.11397507377022,\n",
       "    -79.67184497418208,\n",
       "    -72.07095141483799,\n",
       "    -75.37012630514975,\n",
       "    -75.60207586906708,\n",
       "    -66.02733709535707,\n",
       "    -50.60328710599267,\n",
       "    -57.42665354812507,\n",
       "    -69.52059224867322,\n",
       "    -63.59025892294064,\n",
       "    -70.47725818047971,\n",
       "    -71.5097163998363,\n",
       "    -71.55254641060989,\n",
       "    -63.429878433809776,\n",
       "    -41.506403067295814,\n",
       "    -66.13580432895276,\n",
       "    -63.852602229840905,\n",
       "    -58.60631929083194,\n",
       "    -62.374679881729584,\n",
       "    -66.94087200657685,\n",
       "    -74.09086739260715,\n",
       "    -49.93483509305261,\n",
       "    -69.45400811223324,\n",
       "    -62.08495055171867,\n",
       "    -63.70719055257781,\n",
       "    -109.8198102691455,\n",
       "    -49.56564015714066,\n",
       "    -65.00697809566041,\n",
       "    -66.24835559076348,\n",
       "    -74.55214832230064,\n",
       "    -46.032236323793796,\n",
       "    -58.13551420852237,\n",
       "    -66.67670238696078,\n",
       "    -50.7089244640738,\n",
       "    -98.74498843945156,\n",
       "    -72.10434672871217,\n",
       "    -42.24482652905175,\n",
       "    -62.69430701948296,\n",
       "    -107.14916354504557,\n",
       "    -70.75359347795839,\n",
       "    -50.849997000744416,\n",
       "    -76.01994657764267,\n",
       "    -62.47357494859152,\n",
       "    -30.15886793138822,\n",
       "    -68.04875663363018,\n",
       "    -126.84991304492816,\n",
       "    -74.09607846070311,\n",
       "    -69.9750645925157,\n",
       "    -54.11147583723851,\n",
       "    -65.5547636255394,\n",
       "    -59.40747138260858,\n",
       "    -60.37577479233005,\n",
       "    -86.51480790665295,\n",
       "    -105.03532592308878,\n",
       "    -67.78092077486856,\n",
       "    -106.79201248492402,\n",
       "    -63.95983155618549,\n",
       "    -46.36047917758843,\n",
       "    -76.81925743365036,\n",
       "    -66.03692409392941,\n",
       "    -75.57823110650784,\n",
       "    -69.68319785958708,\n",
       "    -39.57490257860542,\n",
       "    -49.795066298678705,\n",
       "    -84.70677128136006,\n",
       "    -45.89900802294432,\n",
       "    -75.07701726831834,\n",
       "    -78.49098658810924,\n",
       "    -60.840398001018094,\n",
       "    -72.49361350494091,\n",
       "    -64.1873018447736,\n",
       "    -44.02829601142887,\n",
       "    -73.6022143629266,\n",
       "    -75.11408238475855,\n",
       "    -66.98381704915644,\n",
       "    -58.38255576971574,\n",
       "    -33.11370969328171,\n",
       "    -85.04360635578227,\n",
       "    -78.46255133730052,\n",
       "    -104.64415304215386,\n",
       "    -62.178136800650876,\n",
       "    -67.49153704251358,\n",
       "    -86.54433765350574,\n",
       "    -63.05033647369743,\n",
       "    -52.28259895958932,\n",
       "    -65.22612024666915,\n",
       "    -63.10045587783128,\n",
       "    -67.76463659823975,\n",
       "    -42.40961347278348,\n",
       "    -66.75695742620705],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2210324566053243,\n",
       "   'mean_inference_ms': 0.5681589568184859,\n",
       "   'mean_action_processing_ms': 0.07598131528955855,\n",
       "   'mean_env_wait_ms': 1.1212957200380649,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 72000,\n",
       "  'agent_timesteps_total': 72000,\n",
       "  'timers': {'learn_time_ms': 1.432, 'learn_throughput': 69838.72},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.91072,\n",
       "     'max_q': -3.5509887,\n",
       "     'min_q': -23.447216,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 72000,\n",
       "   'num_agent_steps_sampled': 72000,\n",
       "   'num_steps_trained': 7050100,\n",
       "   'num_agent_steps_trained': 7050100,\n",
       "   'last_target_update_ts': 72000,\n",
       "   'num_target_updates': 70501},\n",
       "  'done': False,\n",
       "  'episodes_total': 712,\n",
       "  'training_iteration': 48,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-06-31',\n",
       "  'timestamp': 1625501191,\n",
       "  'time_this_iter_s': 20.362881660461426,\n",
       "  'time_total_s': 933.5671260356903,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 933.5671260356903,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 48,\n",
       "  'perf': {'cpu_util_percent': 12.125925925925925,\n",
       "   'ram_util_percent': 46.507407407407406,\n",
       "   'gpu_util_percent0': 0.09703703703703705,\n",
       "   'vram_util_percent0': 0.5909164086100931}},\n",
       " {'episode_reward_max': -30.15886793138822,\n",
       "  'episode_reward_min': -126.84991304492816,\n",
       "  'episode_reward_mean': -67.25308358653338,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-66.02733709535707,\n",
       "    -50.60328710599267,\n",
       "    -57.42665354812507,\n",
       "    -69.52059224867322,\n",
       "    -63.59025892294064,\n",
       "    -70.47725818047971,\n",
       "    -71.5097163998363,\n",
       "    -71.55254641060989,\n",
       "    -63.429878433809776,\n",
       "    -41.506403067295814,\n",
       "    -66.13580432895276,\n",
       "    -63.852602229840905,\n",
       "    -58.60631929083194,\n",
       "    -62.374679881729584,\n",
       "    -66.94087200657685,\n",
       "    -74.09086739260715,\n",
       "    -49.93483509305261,\n",
       "    -69.45400811223324,\n",
       "    -62.08495055171867,\n",
       "    -63.70719055257781,\n",
       "    -109.8198102691455,\n",
       "    -49.56564015714066,\n",
       "    -65.00697809566041,\n",
       "    -66.24835559076348,\n",
       "    -74.55214832230064,\n",
       "    -46.032236323793796,\n",
       "    -58.13551420852237,\n",
       "    -66.67670238696078,\n",
       "    -50.7089244640738,\n",
       "    -98.74498843945156,\n",
       "    -72.10434672871217,\n",
       "    -42.24482652905175,\n",
       "    -62.69430701948296,\n",
       "    -107.14916354504557,\n",
       "    -70.75359347795839,\n",
       "    -50.849997000744416,\n",
       "    -76.01994657764267,\n",
       "    -62.47357494859152,\n",
       "    -30.15886793138822,\n",
       "    -68.04875663363018,\n",
       "    -126.84991304492816,\n",
       "    -74.09607846070311,\n",
       "    -69.9750645925157,\n",
       "    -54.11147583723851,\n",
       "    -65.5547636255394,\n",
       "    -59.40747138260858,\n",
       "    -60.37577479233005,\n",
       "    -86.51480790665295,\n",
       "    -105.03532592308878,\n",
       "    -67.78092077486856,\n",
       "    -106.79201248492402,\n",
       "    -63.95983155618549,\n",
       "    -46.36047917758843,\n",
       "    -76.81925743365036,\n",
       "    -66.03692409392941,\n",
       "    -75.57823110650784,\n",
       "    -69.68319785958708,\n",
       "    -39.57490257860542,\n",
       "    -49.795066298678705,\n",
       "    -84.70677128136006,\n",
       "    -45.89900802294432,\n",
       "    -75.07701726831834,\n",
       "    -78.49098658810924,\n",
       "    -60.840398001018094,\n",
       "    -72.49361350494091,\n",
       "    -64.1873018447736,\n",
       "    -44.02829601142887,\n",
       "    -73.6022143629266,\n",
       "    -75.11408238475855,\n",
       "    -66.98381704915644,\n",
       "    -58.38255576971574,\n",
       "    -33.11370969328171,\n",
       "    -85.04360635578227,\n",
       "    -78.46255133730052,\n",
       "    -104.64415304215386,\n",
       "    -62.178136800650876,\n",
       "    -67.49153704251358,\n",
       "    -86.54433765350574,\n",
       "    -63.05033647369743,\n",
       "    -52.28259895958932,\n",
       "    -65.22612024666915,\n",
       "    -63.10045587783128,\n",
       "    -67.76463659823975,\n",
       "    -42.40961347278348,\n",
       "    -66.75695742620705,\n",
       "    -68.96317104211201,\n",
       "    -72.31878967934091,\n",
       "    -61.977168948366845,\n",
       "    -64.07603637486739,\n",
       "    -66.98559271993264,\n",
       "    -68.81335920521775,\n",
       "    -87.05168799324,\n",
       "    -64.3993497120439,\n",
       "    -66.65580508082726,\n",
       "    -60.52197311361094,\n",
       "    -48.776852746792464,\n",
       "    -68.31740355025266,\n",
       "    -69.21184707361442,\n",
       "    -60.53470324188774,\n",
       "    -103.71356666814343],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22106999676020436,\n",
       "   'mean_inference_ms': 0.5686054807829513,\n",
       "   'mean_action_processing_ms': 0.07602535034002357,\n",
       "   'mean_env_wait_ms': 1.122087115874312,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 73500,\n",
       "  'agent_timesteps_total': 73500,\n",
       "  'timers': {'learn_time_ms': 1.427, 'learn_throughput': 70084.951},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.6311455,\n",
       "     'max_q': -3.25451,\n",
       "     'min_q': -22.238049,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 73500,\n",
       "   'num_agent_steps_sampled': 73500,\n",
       "   'num_steps_trained': 7200100,\n",
       "   'num_agent_steps_trained': 7200100,\n",
       "   'last_target_update_ts': 73500,\n",
       "   'num_target_updates': 72001},\n",
       "  'done': False,\n",
       "  'episodes_total': 727,\n",
       "  'training_iteration': 49,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-06-52',\n",
       "  'timestamp': 1625501212,\n",
       "  'time_this_iter_s': 21.181647300720215,\n",
       "  'time_total_s': 954.7487733364105,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 954.7487733364105,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 49,\n",
       "  'perf': {'cpu_util_percent': 12.15,\n",
       "   'ram_util_percent': 46.50714285714286,\n",
       "   'gpu_util_percent0': 0.11,\n",
       "   'vram_util_percent0': 0.5908974686780875}},\n",
       " {'episode_reward_max': -30.15886793138822,\n",
       "  'episode_reward_min': -126.84991304492816,\n",
       "  'episode_reward_mean': -67.28657854377961,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-74.09086739260715,\n",
       "    -49.93483509305261,\n",
       "    -69.45400811223324,\n",
       "    -62.08495055171867,\n",
       "    -63.70719055257781,\n",
       "    -109.8198102691455,\n",
       "    -49.56564015714066,\n",
       "    -65.00697809566041,\n",
       "    -66.24835559076348,\n",
       "    -74.55214832230064,\n",
       "    -46.032236323793796,\n",
       "    -58.13551420852237,\n",
       "    -66.67670238696078,\n",
       "    -50.7089244640738,\n",
       "    -98.74498843945156,\n",
       "    -72.10434672871217,\n",
       "    -42.24482652905175,\n",
       "    -62.69430701948296,\n",
       "    -107.14916354504557,\n",
       "    -70.75359347795839,\n",
       "    -50.849997000744416,\n",
       "    -76.01994657764267,\n",
       "    -62.47357494859152,\n",
       "    -30.15886793138822,\n",
       "    -68.04875663363018,\n",
       "    -126.84991304492816,\n",
       "    -74.09607846070311,\n",
       "    -69.9750645925157,\n",
       "    -54.11147583723851,\n",
       "    -65.5547636255394,\n",
       "    -59.40747138260858,\n",
       "    -60.37577479233005,\n",
       "    -86.51480790665295,\n",
       "    -105.03532592308878,\n",
       "    -67.78092077486856,\n",
       "    -106.79201248492402,\n",
       "    -63.95983155618549,\n",
       "    -46.36047917758843,\n",
       "    -76.81925743365036,\n",
       "    -66.03692409392941,\n",
       "    -75.57823110650784,\n",
       "    -69.68319785958708,\n",
       "    -39.57490257860542,\n",
       "    -49.795066298678705,\n",
       "    -84.70677128136006,\n",
       "    -45.89900802294432,\n",
       "    -75.07701726831834,\n",
       "    -78.49098658810924,\n",
       "    -60.840398001018094,\n",
       "    -72.49361350494091,\n",
       "    -64.1873018447736,\n",
       "    -44.02829601142887,\n",
       "    -73.6022143629266,\n",
       "    -75.11408238475855,\n",
       "    -66.98381704915644,\n",
       "    -58.38255576971574,\n",
       "    -33.11370969328171,\n",
       "    -85.04360635578227,\n",
       "    -78.46255133730052,\n",
       "    -104.64415304215386,\n",
       "    -62.178136800650876,\n",
       "    -67.49153704251358,\n",
       "    -86.54433765350574,\n",
       "    -63.05033647369743,\n",
       "    -52.28259895958932,\n",
       "    -65.22612024666915,\n",
       "    -63.10045587783128,\n",
       "    -67.76463659823975,\n",
       "    -42.40961347278348,\n",
       "    -66.75695742620705,\n",
       "    -68.96317104211201,\n",
       "    -72.31878967934091,\n",
       "    -61.977168948366845,\n",
       "    -64.07603637486739,\n",
       "    -66.98559271993264,\n",
       "    -68.81335920521775,\n",
       "    -87.05168799324,\n",
       "    -64.3993497120439,\n",
       "    -66.65580508082726,\n",
       "    -60.52197311361094,\n",
       "    -48.776852746792464,\n",
       "    -68.31740355025266,\n",
       "    -69.21184707361442,\n",
       "    -60.53470324188774,\n",
       "    -103.71356666814343,\n",
       "    -66.62167650380209,\n",
       "    -58.641390355536366,\n",
       "    -56.99962855583728,\n",
       "    -55.6235162116474,\n",
       "    -71.23744795113662,\n",
       "    -56.92856492806135,\n",
       "    -68.22625745476292,\n",
       "    -69.10788484344656,\n",
       "    -43.431274282900226,\n",
       "    -67.68144351951048,\n",
       "    -63.55952010493124,\n",
       "    -67.57843256838635,\n",
       "    -49.306724157701055,\n",
       "    -80.34594362655376,\n",
       "    -71.61399981145951],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22109237912371352,\n",
       "   'mean_inference_ms': 0.5688373974688911,\n",
       "   'mean_action_processing_ms': 0.07605744576940701,\n",
       "   'mean_env_wait_ms': 1.1238281546959008,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 75000,\n",
       "  'agent_timesteps_total': 75000,\n",
       "  'timers': {'learn_time_ms': 1.444, 'learn_throughput': 69274.667},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.250701,\n",
       "     'max_q': -3.244951,\n",
       "     'min_q': -21.818565,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 75000,\n",
       "   'num_agent_steps_sampled': 75000,\n",
       "   'num_steps_trained': 7350100,\n",
       "   'num_agent_steps_trained': 7350100,\n",
       "   'last_target_update_ts': 75000,\n",
       "   'num_target_updates': 73501},\n",
       "  'done': False,\n",
       "  'episodes_total': 742,\n",
       "  'training_iteration': 50,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-07-12',\n",
       "  'timestamp': 1625501232,\n",
       "  'time_this_iter_s': 20.23740577697754,\n",
       "  'time_total_s': 974.9861791133881,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 974.9861791133881,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 50,\n",
       "  'perf': {'cpu_util_percent': 12.403703703703703,\n",
       "   'ram_util_percent': 46.529629629629625,\n",
       "   'gpu_util_percent0': 0.10074074074074074,\n",
       "   'vram_util_percent0': 0.5909164086100931}},\n",
       " {'episode_reward_max': -30.15886793138822,\n",
       "  'episode_reward_min': -126.84991304492816,\n",
       "  'episode_reward_mean': -67.55038761337698,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-72.10434672871217,\n",
       "    -42.24482652905175,\n",
       "    -62.69430701948296,\n",
       "    -107.14916354504557,\n",
       "    -70.75359347795839,\n",
       "    -50.849997000744416,\n",
       "    -76.01994657764267,\n",
       "    -62.47357494859152,\n",
       "    -30.15886793138822,\n",
       "    -68.04875663363018,\n",
       "    -126.84991304492816,\n",
       "    -74.09607846070311,\n",
       "    -69.9750645925157,\n",
       "    -54.11147583723851,\n",
       "    -65.5547636255394,\n",
       "    -59.40747138260858,\n",
       "    -60.37577479233005,\n",
       "    -86.51480790665295,\n",
       "    -105.03532592308878,\n",
       "    -67.78092077486856,\n",
       "    -106.79201248492402,\n",
       "    -63.95983155618549,\n",
       "    -46.36047917758843,\n",
       "    -76.81925743365036,\n",
       "    -66.03692409392941,\n",
       "    -75.57823110650784,\n",
       "    -69.68319785958708,\n",
       "    -39.57490257860542,\n",
       "    -49.795066298678705,\n",
       "    -84.70677128136006,\n",
       "    -45.89900802294432,\n",
       "    -75.07701726831834,\n",
       "    -78.49098658810924,\n",
       "    -60.840398001018094,\n",
       "    -72.49361350494091,\n",
       "    -64.1873018447736,\n",
       "    -44.02829601142887,\n",
       "    -73.6022143629266,\n",
       "    -75.11408238475855,\n",
       "    -66.98381704915644,\n",
       "    -58.38255576971574,\n",
       "    -33.11370969328171,\n",
       "    -85.04360635578227,\n",
       "    -78.46255133730052,\n",
       "    -104.64415304215386,\n",
       "    -62.178136800650876,\n",
       "    -67.49153704251358,\n",
       "    -86.54433765350574,\n",
       "    -63.05033647369743,\n",
       "    -52.28259895958932,\n",
       "    -65.22612024666915,\n",
       "    -63.10045587783128,\n",
       "    -67.76463659823975,\n",
       "    -42.40961347278348,\n",
       "    -66.75695742620705,\n",
       "    -68.96317104211201,\n",
       "    -72.31878967934091,\n",
       "    -61.977168948366845,\n",
       "    -64.07603637486739,\n",
       "    -66.98559271993264,\n",
       "    -68.81335920521775,\n",
       "    -87.05168799324,\n",
       "    -64.3993497120439,\n",
       "    -66.65580508082726,\n",
       "    -60.52197311361094,\n",
       "    -48.776852746792464,\n",
       "    -68.31740355025266,\n",
       "    -69.21184707361442,\n",
       "    -60.53470324188774,\n",
       "    -103.71356666814343,\n",
       "    -66.62167650380209,\n",
       "    -58.641390355536366,\n",
       "    -56.99962855583728,\n",
       "    -55.6235162116474,\n",
       "    -71.23744795113662,\n",
       "    -56.92856492806135,\n",
       "    -68.22625745476292,\n",
       "    -69.10788484344656,\n",
       "    -43.431274282900226,\n",
       "    -67.68144351951048,\n",
       "    -63.55952010493124,\n",
       "    -67.57843256838635,\n",
       "    -49.306724157701055,\n",
       "    -80.34594362655376,\n",
       "    -71.61399981145951,\n",
       "    -53.99647187437878,\n",
       "    -40.84302432932159,\n",
       "    -113.19121790305353,\n",
       "    -67.8929759554018,\n",
       "    -84.97231165593668,\n",
       "    -74.96532472946356,\n",
       "    -72.95013843490841,\n",
       "    -36.54636489706553,\n",
       "    -45.56350269663549,\n",
       "    -67.87582708725324,\n",
       "    -67.82168320788372,\n",
       "    -87.15507886067587,\n",
       "    -44.75961202796806,\n",
       "    -95.7739038603489,\n",
       "    -76.83661939944508],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22109518267366832,\n",
       "   'mean_inference_ms': 0.5689543670961447,\n",
       "   'mean_action_processing_ms': 0.07607238359996664,\n",
       "   'mean_env_wait_ms': 1.1264791651722426,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 76500,\n",
       "  'agent_timesteps_total': 76500,\n",
       "  'timers': {'learn_time_ms': 1.413, 'learn_throughput': 70748.149},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.384038,\n",
       "     'max_q': -4.1129446,\n",
       "     'min_q': -24.063572,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 76500,\n",
       "   'num_agent_steps_sampled': 76500,\n",
       "   'num_steps_trained': 7500100,\n",
       "   'num_agent_steps_trained': 7500100,\n",
       "   'last_target_update_ts': 76500,\n",
       "   'num_target_updates': 75001},\n",
       "  'done': False,\n",
       "  'episodes_total': 757,\n",
       "  'training_iteration': 51,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-07-32',\n",
       "  'timestamp': 1625501252,\n",
       "  'time_this_iter_s': 20.37527108192444,\n",
       "  'time_total_s': 995.3614501953125,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 995.3614501953125,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 51,\n",
       "  'perf': {'cpu_util_percent': 12.425925925925926,\n",
       "   'ram_util_percent': 46.5037037037037,\n",
       "   'gpu_util_percent0': 0.1159259259259259,\n",
       "   'vram_util_percent0': 0.5568340009659365}},\n",
       " {'episode_reward_max': -33.11370969328171,\n",
       "  'episode_reward_min': -113.19121790305353,\n",
       "  'episode_reward_mean': -67.6759085644249,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-59.40747138260858,\n",
       "    -60.37577479233005,\n",
       "    -86.51480790665295,\n",
       "    -105.03532592308878,\n",
       "    -67.78092077486856,\n",
       "    -106.79201248492402,\n",
       "    -63.95983155618549,\n",
       "    -46.36047917758843,\n",
       "    -76.81925743365036,\n",
       "    -66.03692409392941,\n",
       "    -75.57823110650784,\n",
       "    -69.68319785958708,\n",
       "    -39.57490257860542,\n",
       "    -49.795066298678705,\n",
       "    -84.70677128136006,\n",
       "    -45.89900802294432,\n",
       "    -75.07701726831834,\n",
       "    -78.49098658810924,\n",
       "    -60.840398001018094,\n",
       "    -72.49361350494091,\n",
       "    -64.1873018447736,\n",
       "    -44.02829601142887,\n",
       "    -73.6022143629266,\n",
       "    -75.11408238475855,\n",
       "    -66.98381704915644,\n",
       "    -58.38255576971574,\n",
       "    -33.11370969328171,\n",
       "    -85.04360635578227,\n",
       "    -78.46255133730052,\n",
       "    -104.64415304215386,\n",
       "    -62.178136800650876,\n",
       "    -67.49153704251358,\n",
       "    -86.54433765350574,\n",
       "    -63.05033647369743,\n",
       "    -52.28259895958932,\n",
       "    -65.22612024666915,\n",
       "    -63.10045587783128,\n",
       "    -67.76463659823975,\n",
       "    -42.40961347278348,\n",
       "    -66.75695742620705,\n",
       "    -68.96317104211201,\n",
       "    -72.31878967934091,\n",
       "    -61.977168948366845,\n",
       "    -64.07603637486739,\n",
       "    -66.98559271993264,\n",
       "    -68.81335920521775,\n",
       "    -87.05168799324,\n",
       "    -64.3993497120439,\n",
       "    -66.65580508082726,\n",
       "    -60.52197311361094,\n",
       "    -48.776852746792464,\n",
       "    -68.31740355025266,\n",
       "    -69.21184707361442,\n",
       "    -60.53470324188774,\n",
       "    -103.71356666814343,\n",
       "    -66.62167650380209,\n",
       "    -58.641390355536366,\n",
       "    -56.99962855583728,\n",
       "    -55.6235162116474,\n",
       "    -71.23744795113662,\n",
       "    -56.92856492806135,\n",
       "    -68.22625745476292,\n",
       "    -69.10788484344656,\n",
       "    -43.431274282900226,\n",
       "    -67.68144351951048,\n",
       "    -63.55952010493124,\n",
       "    -67.57843256838635,\n",
       "    -49.306724157701055,\n",
       "    -80.34594362655376,\n",
       "    -71.61399981145951,\n",
       "    -53.99647187437878,\n",
       "    -40.84302432932159,\n",
       "    -113.19121790305353,\n",
       "    -67.8929759554018,\n",
       "    -84.97231165593668,\n",
       "    -74.96532472946356,\n",
       "    -72.95013843490841,\n",
       "    -36.54636489706553,\n",
       "    -45.56350269663549,\n",
       "    -67.87582708725324,\n",
       "    -67.82168320788372,\n",
       "    -87.15507886067587,\n",
       "    -44.75961202796806,\n",
       "    -95.7739038603489,\n",
       "    -76.83661939944508,\n",
       "    -69.70471828430787,\n",
       "    -61.46120881447971,\n",
       "    -89.670477855539,\n",
       "    -61.90399886230052,\n",
       "    -82.10021232277182,\n",
       "    -110.68014185632101,\n",
       "    -67.08521250379096,\n",
       "    -77.69950096257514,\n",
       "    -70.24514675770315,\n",
       "    -64.17436849663969,\n",
       "    -41.74145798984015,\n",
       "    -73.54040895877974,\n",
       "    -67.87252838941717,\n",
       "    -69.91101284445061,\n",
       "    -37.84637615904659],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22106315463553808,\n",
       "   'mean_inference_ms': 0.569085440999364,\n",
       "   'mean_action_processing_ms': 0.07606331560444496,\n",
       "   'mean_env_wait_ms': 1.1292735551863975,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 78000,\n",
       "  'agent_timesteps_total': 78000,\n",
       "  'timers': {'learn_time_ms': 1.417, 'learn_throughput': 70575.534},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.507464,\n",
       "     'max_q': -3.9478846,\n",
       "     'min_q': -21.572556,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 78000,\n",
       "   'num_agent_steps_sampled': 78000,\n",
       "   'num_steps_trained': 7650100,\n",
       "   'num_agent_steps_trained': 7650100,\n",
       "   'last_target_update_ts': 78000,\n",
       "   'num_target_updates': 76501},\n",
       "  'done': False,\n",
       "  'episodes_total': 772,\n",
       "  'training_iteration': 52,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-07-53',\n",
       "  'timestamp': 1625501273,\n",
       "  'time_this_iter_s': 20.17283034324646,\n",
       "  'time_total_s': 1015.534280538559,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1015.534280538559,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 52,\n",
       "  'perf': {'cpu_util_percent': 12.884615384615385,\n",
       "   'ram_util_percent': 46.52692307692307,\n",
       "   'gpu_util_percent0': 0.15730769230769232,\n",
       "   'vram_util_percent0': 0.5534390181539249}},\n",
       " {'episode_reward_max': -33.11370969328171,\n",
       "  'episode_reward_min': -113.19121790305353,\n",
       "  'episode_reward_mean': -67.55989107794845,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-45.89900802294432,\n",
       "    -75.07701726831834,\n",
       "    -78.49098658810924,\n",
       "    -60.840398001018094,\n",
       "    -72.49361350494091,\n",
       "    -64.1873018447736,\n",
       "    -44.02829601142887,\n",
       "    -73.6022143629266,\n",
       "    -75.11408238475855,\n",
       "    -66.98381704915644,\n",
       "    -58.38255576971574,\n",
       "    -33.11370969328171,\n",
       "    -85.04360635578227,\n",
       "    -78.46255133730052,\n",
       "    -104.64415304215386,\n",
       "    -62.178136800650876,\n",
       "    -67.49153704251358,\n",
       "    -86.54433765350574,\n",
       "    -63.05033647369743,\n",
       "    -52.28259895958932,\n",
       "    -65.22612024666915,\n",
       "    -63.10045587783128,\n",
       "    -67.76463659823975,\n",
       "    -42.40961347278348,\n",
       "    -66.75695742620705,\n",
       "    -68.96317104211201,\n",
       "    -72.31878967934091,\n",
       "    -61.977168948366845,\n",
       "    -64.07603637486739,\n",
       "    -66.98559271993264,\n",
       "    -68.81335920521775,\n",
       "    -87.05168799324,\n",
       "    -64.3993497120439,\n",
       "    -66.65580508082726,\n",
       "    -60.52197311361094,\n",
       "    -48.776852746792464,\n",
       "    -68.31740355025266,\n",
       "    -69.21184707361442,\n",
       "    -60.53470324188774,\n",
       "    -103.71356666814343,\n",
       "    -66.62167650380209,\n",
       "    -58.641390355536366,\n",
       "    -56.99962855583728,\n",
       "    -55.6235162116474,\n",
       "    -71.23744795113662,\n",
       "    -56.92856492806135,\n",
       "    -68.22625745476292,\n",
       "    -69.10788484344656,\n",
       "    -43.431274282900226,\n",
       "    -67.68144351951048,\n",
       "    -63.55952010493124,\n",
       "    -67.57843256838635,\n",
       "    -49.306724157701055,\n",
       "    -80.34594362655376,\n",
       "    -71.61399981145951,\n",
       "    -53.99647187437878,\n",
       "    -40.84302432932159,\n",
       "    -113.19121790305353,\n",
       "    -67.8929759554018,\n",
       "    -84.97231165593668,\n",
       "    -74.96532472946356,\n",
       "    -72.95013843490841,\n",
       "    -36.54636489706553,\n",
       "    -45.56350269663549,\n",
       "    -67.87582708725324,\n",
       "    -67.82168320788372,\n",
       "    -87.15507886067587,\n",
       "    -44.75961202796806,\n",
       "    -95.7739038603489,\n",
       "    -76.83661939944508,\n",
       "    -69.70471828430787,\n",
       "    -61.46120881447971,\n",
       "    -89.670477855539,\n",
       "    -61.90399886230052,\n",
       "    -82.10021232277182,\n",
       "    -110.68014185632101,\n",
       "    -67.08521250379096,\n",
       "    -77.69950096257514,\n",
       "    -70.24514675770315,\n",
       "    -64.17436849663969,\n",
       "    -41.74145798984015,\n",
       "    -73.54040895877974,\n",
       "    -67.87252838941717,\n",
       "    -69.91101284445061,\n",
       "    -37.84637615904659,\n",
       "    -85.82084712031724,\n",
       "    -60.148684710918786,\n",
       "    -61.488583960770285,\n",
       "    -56.3352300515344,\n",
       "    -101.68213023754463,\n",
       "    -50.33273576058737,\n",
       "    -43.68990473151006,\n",
       "    -97.41145542437334,\n",
       "    -69.74366560448246,\n",
       "    -69.78762189646723,\n",
       "    -70.99999307350417,\n",
       "    -67.02026540783983,\n",
       "    -63.77541610377382,\n",
       "    -65.53490647918781,\n",
       "    -83.04778544010999],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22102349835622753,\n",
       "   'mean_inference_ms': 0.5691507090987864,\n",
       "   'mean_action_processing_ms': 0.07604484782159236,\n",
       "   'mean_env_wait_ms': 1.1323324496742204,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 79500,\n",
       "  'agent_timesteps_total': 79500,\n",
       "  'timers': {'learn_time_ms': 1.411, 'learn_throughput': 70871.278},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.888339,\n",
       "     'max_q': -3.1447794,\n",
       "     'min_q': -24.043524,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 79500,\n",
       "   'num_agent_steps_sampled': 79500,\n",
       "   'num_steps_trained': 7800100,\n",
       "   'num_agent_steps_trained': 7800100,\n",
       "   'last_target_update_ts': 79500,\n",
       "   'num_target_updates': 78001},\n",
       "  'done': False,\n",
       "  'episodes_total': 787,\n",
       "  'training_iteration': 53,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-08-13',\n",
       "  'timestamp': 1625501293,\n",
       "  'time_this_iter_s': 20.50963807106018,\n",
       "  'time_total_s': 1036.0439186096191,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1036.0439186096191,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 53,\n",
       "  'perf': {'cpu_util_percent': 12.107407407407404,\n",
       "   'ram_util_percent': 46.599999999999994,\n",
       "   'gpu_util_percent0': 0.2403703703703704,\n",
       "   'vram_util_percent0': 0.5531501841908388}},\n",
       " {'episode_reward_max': -36.54636489706553,\n",
       "  'episode_reward_min': -113.19121790305353,\n",
       "  'episode_reward_mean': -67.91546109955308,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 14,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-104.64415304215386,\n",
       "    -62.178136800650876,\n",
       "    -67.49153704251358,\n",
       "    -86.54433765350574,\n",
       "    -63.05033647369743,\n",
       "    -52.28259895958932,\n",
       "    -65.22612024666915,\n",
       "    -63.10045587783128,\n",
       "    -67.76463659823975,\n",
       "    -42.40961347278348,\n",
       "    -66.75695742620705,\n",
       "    -68.96317104211201,\n",
       "    -72.31878967934091,\n",
       "    -61.977168948366845,\n",
       "    -64.07603637486739,\n",
       "    -66.98559271993264,\n",
       "    -68.81335920521775,\n",
       "    -87.05168799324,\n",
       "    -64.3993497120439,\n",
       "    -66.65580508082726,\n",
       "    -60.52197311361094,\n",
       "    -48.776852746792464,\n",
       "    -68.31740355025266,\n",
       "    -69.21184707361442,\n",
       "    -60.53470324188774,\n",
       "    -103.71356666814343,\n",
       "    -66.62167650380209,\n",
       "    -58.641390355536366,\n",
       "    -56.99962855583728,\n",
       "    -55.6235162116474,\n",
       "    -71.23744795113662,\n",
       "    -56.92856492806135,\n",
       "    -68.22625745476292,\n",
       "    -69.10788484344656,\n",
       "    -43.431274282900226,\n",
       "    -67.68144351951048,\n",
       "    -63.55952010493124,\n",
       "    -67.57843256838635,\n",
       "    -49.306724157701055,\n",
       "    -80.34594362655376,\n",
       "    -71.61399981145951,\n",
       "    -53.99647187437878,\n",
       "    -40.84302432932159,\n",
       "    -113.19121790305353,\n",
       "    -67.8929759554018,\n",
       "    -84.97231165593668,\n",
       "    -74.96532472946356,\n",
       "    -72.95013843490841,\n",
       "    -36.54636489706553,\n",
       "    -45.56350269663549,\n",
       "    -67.87582708725324,\n",
       "    -67.82168320788372,\n",
       "    -87.15507886067587,\n",
       "    -44.75961202796806,\n",
       "    -95.7739038603489,\n",
       "    -76.83661939944508,\n",
       "    -69.70471828430787,\n",
       "    -61.46120881447971,\n",
       "    -89.670477855539,\n",
       "    -61.90399886230052,\n",
       "    -82.10021232277182,\n",
       "    -110.68014185632101,\n",
       "    -67.08521250379096,\n",
       "    -77.69950096257514,\n",
       "    -70.24514675770315,\n",
       "    -64.17436849663969,\n",
       "    -41.74145798984015,\n",
       "    -73.54040895877974,\n",
       "    -67.87252838941717,\n",
       "    -69.91101284445061,\n",
       "    -37.84637615904659,\n",
       "    -85.82084712031724,\n",
       "    -60.148684710918786,\n",
       "    -61.488583960770285,\n",
       "    -56.3352300515344,\n",
       "    -101.68213023754463,\n",
       "    -50.33273576058737,\n",
       "    -43.68990473151006,\n",
       "    -97.41145542437334,\n",
       "    -69.74366560448246,\n",
       "    -69.78762189646723,\n",
       "    -70.99999307350417,\n",
       "    -67.02026540783983,\n",
       "    -63.77541610377382,\n",
       "    -65.53490647918781,\n",
       "    -83.04778544010999,\n",
       "    -62.661315690169666,\n",
       "    -49.54198290745583,\n",
       "    -68.31701333568941,\n",
       "    -50.77409388274395,\n",
       "    -104.06052342255525,\n",
       "    -71.59297935962763,\n",
       "    -52.64472254305488,\n",
       "    -75.24756458826604,\n",
       "    -65.74113794073324,\n",
       "    -70.62956778435573,\n",
       "    -73.76896227949591,\n",
       "    -61.592280583815175,\n",
       "    -67.90439614059281,\n",
       "    -72.79961989636169],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22099007709207816,\n",
       "   'mean_inference_ms': 0.5692705596226014,\n",
       "   'mean_action_processing_ms': 0.07603326467401678,\n",
       "   'mean_env_wait_ms': 1.135129063575513,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 81000,\n",
       "  'agent_timesteps_total': 81000,\n",
       "  'timers': {'learn_time_ms': 1.48, 'learn_throughput': 67571.594},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.613363,\n",
       "     'max_q': -3.824527,\n",
       "     'min_q': -25.0149,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 81000,\n",
       "   'num_agent_steps_sampled': 81000,\n",
       "   'num_steps_trained': 7950100,\n",
       "   'num_agent_steps_trained': 7950100,\n",
       "   'last_target_update_ts': 81000,\n",
       "   'num_target_updates': 79501},\n",
       "  'done': False,\n",
       "  'episodes_total': 801,\n",
       "  'training_iteration': 54,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-08-33',\n",
       "  'timestamp': 1625501313,\n",
       "  'time_this_iter_s': 20.405027151107788,\n",
       "  'time_total_s': 1056.448945760727,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1056.448945760727,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 54,\n",
       "  'perf': {'cpu_util_percent': 12.28148148148148,\n",
       "   'ram_util_percent': 46.61851851851851,\n",
       "   'gpu_util_percent0': 0.21222222222222223,\n",
       "   'vram_util_percent0': 0.5533490534768981}},\n",
       " {'episode_reward_max': -36.54636489706553,\n",
       "  'episode_reward_min': -113.19121790305353,\n",
       "  'episode_reward_mean': -67.81825003306048,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-66.98559271993264,\n",
       "    -68.81335920521775,\n",
       "    -87.05168799324,\n",
       "    -64.3993497120439,\n",
       "    -66.65580508082726,\n",
       "    -60.52197311361094,\n",
       "    -48.776852746792464,\n",
       "    -68.31740355025266,\n",
       "    -69.21184707361442,\n",
       "    -60.53470324188774,\n",
       "    -103.71356666814343,\n",
       "    -66.62167650380209,\n",
       "    -58.641390355536366,\n",
       "    -56.99962855583728,\n",
       "    -55.6235162116474,\n",
       "    -71.23744795113662,\n",
       "    -56.92856492806135,\n",
       "    -68.22625745476292,\n",
       "    -69.10788484344656,\n",
       "    -43.431274282900226,\n",
       "    -67.68144351951048,\n",
       "    -63.55952010493124,\n",
       "    -67.57843256838635,\n",
       "    -49.306724157701055,\n",
       "    -80.34594362655376,\n",
       "    -71.61399981145951,\n",
       "    -53.99647187437878,\n",
       "    -40.84302432932159,\n",
       "    -113.19121790305353,\n",
       "    -67.8929759554018,\n",
       "    -84.97231165593668,\n",
       "    -74.96532472946356,\n",
       "    -72.95013843490841,\n",
       "    -36.54636489706553,\n",
       "    -45.56350269663549,\n",
       "    -67.87582708725324,\n",
       "    -67.82168320788372,\n",
       "    -87.15507886067587,\n",
       "    -44.75961202796806,\n",
       "    -95.7739038603489,\n",
       "    -76.83661939944508,\n",
       "    -69.70471828430787,\n",
       "    -61.46120881447971,\n",
       "    -89.670477855539,\n",
       "    -61.90399886230052,\n",
       "    -82.10021232277182,\n",
       "    -110.68014185632101,\n",
       "    -67.08521250379096,\n",
       "    -77.69950096257514,\n",
       "    -70.24514675770315,\n",
       "    -64.17436849663969,\n",
       "    -41.74145798984015,\n",
       "    -73.54040895877974,\n",
       "    -67.87252838941717,\n",
       "    -69.91101284445061,\n",
       "    -37.84637615904659,\n",
       "    -85.82084712031724,\n",
       "    -60.148684710918786,\n",
       "    -61.488583960770285,\n",
       "    -56.3352300515344,\n",
       "    -101.68213023754463,\n",
       "    -50.33273576058737,\n",
       "    -43.68990473151006,\n",
       "    -97.41145542437334,\n",
       "    -69.74366560448246,\n",
       "    -69.78762189646723,\n",
       "    -70.99999307350417,\n",
       "    -67.02026540783983,\n",
       "    -63.77541610377382,\n",
       "    -65.53490647918781,\n",
       "    -83.04778544010999,\n",
       "    -62.661315690169666,\n",
       "    -49.54198290745583,\n",
       "    -68.31701333568941,\n",
       "    -50.77409388274395,\n",
       "    -104.06052342255525,\n",
       "    -71.59297935962763,\n",
       "    -52.64472254305488,\n",
       "    -75.24756458826604,\n",
       "    -65.74113794073324,\n",
       "    -70.62956778435573,\n",
       "    -73.76896227949591,\n",
       "    -61.592280583815175,\n",
       "    -67.90439614059281,\n",
       "    -72.79961989636169,\n",
       "    -70.85625778827225,\n",
       "    -70.79512555120856,\n",
       "    -66.76146447263963,\n",
       "    -62.8680896802631,\n",
       "    -65.97420138751262,\n",
       "    -68.80885757133204,\n",
       "    -72.94362144805115,\n",
       "    -66.55936276443563,\n",
       "    -65.77110274114067,\n",
       "    -40.3743439790754,\n",
       "    -74.73865077140705,\n",
       "    -79.1835315989487,\n",
       "    -63.376725688697405,\n",
       "    -71.01276151594345,\n",
       "    -59.03884603034237],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22095579808774524,\n",
       "   'mean_inference_ms': 0.569540015808629,\n",
       "   'mean_action_processing_ms': 0.07602518595748341,\n",
       "   'mean_env_wait_ms': 1.1373246609752892,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 82500,\n",
       "  'agent_timesteps_total': 82500,\n",
       "  'timers': {'learn_time_ms': 1.548, 'learn_throughput': 64583.395},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.890683,\n",
       "     'max_q': -4.3293614,\n",
       "     'min_q': -22.603058,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 82500,\n",
       "   'num_agent_steps_sampled': 82500,\n",
       "   'num_steps_trained': 8100100,\n",
       "   'num_agent_steps_trained': 8100100,\n",
       "   'last_target_update_ts': 82500,\n",
       "   'num_target_updates': 81001},\n",
       "  'done': False,\n",
       "  'episodes_total': 816,\n",
       "  'training_iteration': 55,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-08-54',\n",
       "  'timestamp': 1625501334,\n",
       "  'time_this_iter_s': 20.30689311027527,\n",
       "  'time_total_s': 1076.7558388710022,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1076.7558388710022,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 55,\n",
       "  'perf': {'cpu_util_percent': 12.214814814814817,\n",
       "   'ram_util_percent': 46.69629629629631,\n",
       "   'gpu_util_percent0': 0.2581481481481481,\n",
       "   'vram_util_percent0': 0.5532827637148783}},\n",
       " {'episode_reward_max': -36.54636489706553,\n",
       "  'episode_reward_min': -116.1494655720994,\n",
       "  'episode_reward_mean': -68.47934023851444,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-71.23744795113662,\n",
       "    -56.92856492806135,\n",
       "    -68.22625745476292,\n",
       "    -69.10788484344656,\n",
       "    -43.431274282900226,\n",
       "    -67.68144351951048,\n",
       "    -63.55952010493124,\n",
       "    -67.57843256838635,\n",
       "    -49.306724157701055,\n",
       "    -80.34594362655376,\n",
       "    -71.61399981145951,\n",
       "    -53.99647187437878,\n",
       "    -40.84302432932159,\n",
       "    -113.19121790305353,\n",
       "    -67.8929759554018,\n",
       "    -84.97231165593668,\n",
       "    -74.96532472946356,\n",
       "    -72.95013843490841,\n",
       "    -36.54636489706553,\n",
       "    -45.56350269663549,\n",
       "    -67.87582708725324,\n",
       "    -67.82168320788372,\n",
       "    -87.15507886067587,\n",
       "    -44.75961202796806,\n",
       "    -95.7739038603489,\n",
       "    -76.83661939944508,\n",
       "    -69.70471828430787,\n",
       "    -61.46120881447971,\n",
       "    -89.670477855539,\n",
       "    -61.90399886230052,\n",
       "    -82.10021232277182,\n",
       "    -110.68014185632101,\n",
       "    -67.08521250379096,\n",
       "    -77.69950096257514,\n",
       "    -70.24514675770315,\n",
       "    -64.17436849663969,\n",
       "    -41.74145798984015,\n",
       "    -73.54040895877974,\n",
       "    -67.87252838941717,\n",
       "    -69.91101284445061,\n",
       "    -37.84637615904659,\n",
       "    -85.82084712031724,\n",
       "    -60.148684710918786,\n",
       "    -61.488583960770285,\n",
       "    -56.3352300515344,\n",
       "    -101.68213023754463,\n",
       "    -50.33273576058737,\n",
       "    -43.68990473151006,\n",
       "    -97.41145542437334,\n",
       "    -69.74366560448246,\n",
       "    -69.78762189646723,\n",
       "    -70.99999307350417,\n",
       "    -67.02026540783983,\n",
       "    -63.77541610377382,\n",
       "    -65.53490647918781,\n",
       "    -83.04778544010999,\n",
       "    -62.661315690169666,\n",
       "    -49.54198290745583,\n",
       "    -68.31701333568941,\n",
       "    -50.77409388274395,\n",
       "    -104.06052342255525,\n",
       "    -71.59297935962763,\n",
       "    -52.64472254305488,\n",
       "    -75.24756458826604,\n",
       "    -65.74113794073324,\n",
       "    -70.62956778435573,\n",
       "    -73.76896227949591,\n",
       "    -61.592280583815175,\n",
       "    -67.90439614059281,\n",
       "    -72.79961989636169,\n",
       "    -70.85625778827225,\n",
       "    -70.79512555120856,\n",
       "    -66.76146447263963,\n",
       "    -62.8680896802631,\n",
       "    -65.97420138751262,\n",
       "    -68.80885757133204,\n",
       "    -72.94362144805115,\n",
       "    -66.55936276443563,\n",
       "    -65.77110274114067,\n",
       "    -40.3743439790754,\n",
       "    -74.73865077140705,\n",
       "    -79.1835315989487,\n",
       "    -63.376725688697405,\n",
       "    -71.01276151594345,\n",
       "    -59.03884603034237,\n",
       "    -70.36451916768158,\n",
       "    -65.38278418182145,\n",
       "    -60.816647503026964,\n",
       "    -116.1494655720994,\n",
       "    -64.2136393616671,\n",
       "    -60.89794537327549,\n",
       "    -67.50068112693641,\n",
       "    -63.867410192745254,\n",
       "    -60.02175862962226,\n",
       "    -67.11362054511157,\n",
       "    -73.12944648129312,\n",
       "    -61.92876137078322,\n",
       "    -73.08008297614136,\n",
       "    -68.3286512587571,\n",
       "    -96.18195953682057],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2209239307617277,\n",
       "   'mean_inference_ms': 0.5698052794598921,\n",
       "   'mean_action_processing_ms': 0.07601728954603011,\n",
       "   'mean_env_wait_ms': 1.1384084224135995,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 84000,\n",
       "  'agent_timesteps_total': 84000,\n",
       "  'timers': {'learn_time_ms': 1.374, 'learn_throughput': 72767.245},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.708275,\n",
       "     'max_q': -6.3937,\n",
       "     'min_q': -22.466675,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 84000,\n",
       "   'num_agent_steps_sampled': 84000,\n",
       "   'num_steps_trained': 8250100,\n",
       "   'num_agent_steps_trained': 8250100,\n",
       "   'last_target_update_ts': 84000,\n",
       "   'num_target_updates': 82501},\n",
       "  'done': False,\n",
       "  'episodes_total': 831,\n",
       "  'training_iteration': 56,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-09-14',\n",
       "  'timestamp': 1625501354,\n",
       "  'time_this_iter_s': 20.045953035354614,\n",
       "  'time_total_s': 1096.8017919063568,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1096.8017919063568,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 56,\n",
       "  'perf': {'cpu_util_percent': 12.034615384615389,\n",
       "   'ram_util_percent': 46.70000000000001,\n",
       "   'gpu_util_percent0': 0.24615384615384617,\n",
       "   'vram_util_percent0': 0.5533308420038157}},\n",
       " {'episode_reward_max': -36.54636489706553,\n",
       "  'episode_reward_min': -116.1494655720994,\n",
       "  'episode_reward_mean': -68.4845923655641,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-84.97231165593668,\n",
       "    -74.96532472946356,\n",
       "    -72.95013843490841,\n",
       "    -36.54636489706553,\n",
       "    -45.56350269663549,\n",
       "    -67.87582708725324,\n",
       "    -67.82168320788372,\n",
       "    -87.15507886067587,\n",
       "    -44.75961202796806,\n",
       "    -95.7739038603489,\n",
       "    -76.83661939944508,\n",
       "    -69.70471828430787,\n",
       "    -61.46120881447971,\n",
       "    -89.670477855539,\n",
       "    -61.90399886230052,\n",
       "    -82.10021232277182,\n",
       "    -110.68014185632101,\n",
       "    -67.08521250379096,\n",
       "    -77.69950096257514,\n",
       "    -70.24514675770315,\n",
       "    -64.17436849663969,\n",
       "    -41.74145798984015,\n",
       "    -73.54040895877974,\n",
       "    -67.87252838941717,\n",
       "    -69.91101284445061,\n",
       "    -37.84637615904659,\n",
       "    -85.82084712031724,\n",
       "    -60.148684710918786,\n",
       "    -61.488583960770285,\n",
       "    -56.3352300515344,\n",
       "    -101.68213023754463,\n",
       "    -50.33273576058737,\n",
       "    -43.68990473151006,\n",
       "    -97.41145542437334,\n",
       "    -69.74366560448246,\n",
       "    -69.78762189646723,\n",
       "    -70.99999307350417,\n",
       "    -67.02026540783983,\n",
       "    -63.77541610377382,\n",
       "    -65.53490647918781,\n",
       "    -83.04778544010999,\n",
       "    -62.661315690169666,\n",
       "    -49.54198290745583,\n",
       "    -68.31701333568941,\n",
       "    -50.77409388274395,\n",
       "    -104.06052342255525,\n",
       "    -71.59297935962763,\n",
       "    -52.64472254305488,\n",
       "    -75.24756458826604,\n",
       "    -65.74113794073324,\n",
       "    -70.62956778435573,\n",
       "    -73.76896227949591,\n",
       "    -61.592280583815175,\n",
       "    -67.90439614059281,\n",
       "    -72.79961989636169,\n",
       "    -70.85625778827225,\n",
       "    -70.79512555120856,\n",
       "    -66.76146447263963,\n",
       "    -62.8680896802631,\n",
       "    -65.97420138751262,\n",
       "    -68.80885757133204,\n",
       "    -72.94362144805115,\n",
       "    -66.55936276443563,\n",
       "    -65.77110274114067,\n",
       "    -40.3743439790754,\n",
       "    -74.73865077140705,\n",
       "    -79.1835315989487,\n",
       "    -63.376725688697405,\n",
       "    -71.01276151594345,\n",
       "    -59.03884603034237,\n",
       "    -70.36451916768158,\n",
       "    -65.38278418182145,\n",
       "    -60.816647503026964,\n",
       "    -116.1494655720994,\n",
       "    -64.2136393616671,\n",
       "    -60.89794537327549,\n",
       "    -67.50068112693641,\n",
       "    -63.867410192745254,\n",
       "    -60.02175862962226,\n",
       "    -67.11362054511157,\n",
       "    -73.12944648129312,\n",
       "    -61.92876137078322,\n",
       "    -73.08008297614136,\n",
       "    -68.3286512587571,\n",
       "    -96.18195953682057,\n",
       "    -62.061728986488774,\n",
       "    -68.8801436657608,\n",
       "    -67.80342781174282,\n",
       "    -66.7521613977031,\n",
       "    -63.166851231820225,\n",
       "    -64.61764809208084,\n",
       "    -69.75887228299906,\n",
       "    -70.0414225553602,\n",
       "    -65.55349109841646,\n",
       "    -64.15841156921006,\n",
       "    -64.50348328203539,\n",
       "    -68.2744631580702,\n",
       "    -69.27297273072449,\n",
       "    -54.499972394707754,\n",
       "    -66.12134575885096],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22089840101754604,\n",
       "   'mean_inference_ms': 0.5702245015776437,\n",
       "   'mean_action_processing_ms': 0.07601361241057752,\n",
       "   'mean_env_wait_ms': 1.1390935135238864,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 85500,\n",
       "  'agent_timesteps_total': 85500,\n",
       "  'timers': {'learn_time_ms': 1.355, 'learn_throughput': 73827.783},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.402196,\n",
       "     'max_q': -3.7234116,\n",
       "     'min_q': -22.38988,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 85500,\n",
       "   'num_agent_steps_sampled': 85500,\n",
       "   'num_steps_trained': 8400100,\n",
       "   'num_agent_steps_trained': 8400100,\n",
       "   'last_target_update_ts': 85500,\n",
       "   'num_target_updates': 84001},\n",
       "  'done': False,\n",
       "  'episodes_total': 846,\n",
       "  'training_iteration': 57,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-09-34',\n",
       "  'timestamp': 1625501374,\n",
       "  'time_this_iter_s': 20.413099765777588,\n",
       "  'time_total_s': 1117.2148916721344,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1117.2148916721344,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 57,\n",
       "  'perf': {'cpu_util_percent': 12.162962962962965,\n",
       "   'ram_util_percent': 46.8074074074074,\n",
       "   'gpu_util_percent0': 0.22888888888888892,\n",
       "   'vram_util_percent0': 0.5522221275225623}},\n",
       " {'episode_reward_max': -37.84637615904659,\n",
       "  'episode_reward_min': -117.14890305530149,\n",
       "  'episode_reward_mean': -68.42070196108686,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-82.10021232277182,\n",
       "    -110.68014185632101,\n",
       "    -67.08521250379096,\n",
       "    -77.69950096257514,\n",
       "    -70.24514675770315,\n",
       "    -64.17436849663969,\n",
       "    -41.74145798984015,\n",
       "    -73.54040895877974,\n",
       "    -67.87252838941717,\n",
       "    -69.91101284445061,\n",
       "    -37.84637615904659,\n",
       "    -85.82084712031724,\n",
       "    -60.148684710918786,\n",
       "    -61.488583960770285,\n",
       "    -56.3352300515344,\n",
       "    -101.68213023754463,\n",
       "    -50.33273576058737,\n",
       "    -43.68990473151006,\n",
       "    -97.41145542437334,\n",
       "    -69.74366560448246,\n",
       "    -69.78762189646723,\n",
       "    -70.99999307350417,\n",
       "    -67.02026540783983,\n",
       "    -63.77541610377382,\n",
       "    -65.53490647918781,\n",
       "    -83.04778544010999,\n",
       "    -62.661315690169666,\n",
       "    -49.54198290745583,\n",
       "    -68.31701333568941,\n",
       "    -50.77409388274395,\n",
       "    -104.06052342255525,\n",
       "    -71.59297935962763,\n",
       "    -52.64472254305488,\n",
       "    -75.24756458826604,\n",
       "    -65.74113794073324,\n",
       "    -70.62956778435573,\n",
       "    -73.76896227949591,\n",
       "    -61.592280583815175,\n",
       "    -67.90439614059281,\n",
       "    -72.79961989636169,\n",
       "    -70.85625778827225,\n",
       "    -70.79512555120856,\n",
       "    -66.76146447263963,\n",
       "    -62.8680896802631,\n",
       "    -65.97420138751262,\n",
       "    -68.80885757133204,\n",
       "    -72.94362144805115,\n",
       "    -66.55936276443563,\n",
       "    -65.77110274114067,\n",
       "    -40.3743439790754,\n",
       "    -74.73865077140705,\n",
       "    -79.1835315989487,\n",
       "    -63.376725688697405,\n",
       "    -71.01276151594345,\n",
       "    -59.03884603034237,\n",
       "    -70.36451916768158,\n",
       "    -65.38278418182145,\n",
       "    -60.816647503026964,\n",
       "    -116.1494655720994,\n",
       "    -64.2136393616671,\n",
       "    -60.89794537327549,\n",
       "    -67.50068112693641,\n",
       "    -63.867410192745254,\n",
       "    -60.02175862962226,\n",
       "    -67.11362054511157,\n",
       "    -73.12944648129312,\n",
       "    -61.92876137078322,\n",
       "    -73.08008297614136,\n",
       "    -68.3286512587571,\n",
       "    -96.18195953682057,\n",
       "    -62.061728986488774,\n",
       "    -68.8801436657608,\n",
       "    -67.80342781174282,\n",
       "    -66.7521613977031,\n",
       "    -63.166851231820225,\n",
       "    -64.61764809208084,\n",
       "    -69.75887228299906,\n",
       "    -70.0414225553602,\n",
       "    -65.55349109841646,\n",
       "    -64.15841156921006,\n",
       "    -64.50348328203539,\n",
       "    -68.2744631580702,\n",
       "    -69.27297273072449,\n",
       "    -54.499972394707754,\n",
       "    -66.12134575885096,\n",
       "    -117.14890305530149,\n",
       "    -69.9610906470103,\n",
       "    -59.28734392288296,\n",
       "    -59.7541801896703,\n",
       "    -67.8042151717646,\n",
       "    -68.31762265259528,\n",
       "    -65.01497659453396,\n",
       "    -73.10569115247371,\n",
       "    -82.55926298470432,\n",
       "    -55.079243083419016,\n",
       "    -63.36274141566443,\n",
       "    -74.58744342564313,\n",
       "    -63.25802751288948,\n",
       "    -44.603797380767304,\n",
       "    -67.72719103716697],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2208710758334151,\n",
       "   'mean_inference_ms': 0.5706314975502798,\n",
       "   'mean_action_processing_ms': 0.07600952467382961,\n",
       "   'mean_env_wait_ms': 1.139534759253028,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 87000,\n",
       "  'agent_timesteps_total': 87000,\n",
       "  'timers': {'learn_time_ms': 1.408, 'learn_throughput': 71026.095},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.356,\n",
       "     'max_q': -4.2993417,\n",
       "     'min_q': -18.972174,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 87000,\n",
       "   'num_agent_steps_sampled': 87000,\n",
       "   'num_steps_trained': 8550100,\n",
       "   'num_agent_steps_trained': 8550100,\n",
       "   'last_target_update_ts': 87000,\n",
       "   'num_target_updates': 85501},\n",
       "  'done': False,\n",
       "  'episodes_total': 861,\n",
       "  'training_iteration': 58,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-09-55',\n",
       "  'timestamp': 1625501395,\n",
       "  'time_this_iter_s': 20.31250286102295,\n",
       "  'time_total_s': 1137.5273945331573,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1137.5273945331573,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 58,\n",
       "  'perf': {'cpu_util_percent': 12.311111111111112,\n",
       "   'ram_util_percent': 47.0,\n",
       "   'gpu_util_percent0': 0.24629629629629635,\n",
       "   'vram_util_percent0': 0.5354886975955757}},\n",
       " {'episode_reward_max': -40.3743439790754,\n",
       "  'episode_reward_min': -117.14890305530149,\n",
       "  'episode_reward_mean': -69.02810669950021,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-101.68213023754463,\n",
       "    -50.33273576058737,\n",
       "    -43.68990473151006,\n",
       "    -97.41145542437334,\n",
       "    -69.74366560448246,\n",
       "    -69.78762189646723,\n",
       "    -70.99999307350417,\n",
       "    -67.02026540783983,\n",
       "    -63.77541610377382,\n",
       "    -65.53490647918781,\n",
       "    -83.04778544010999,\n",
       "    -62.661315690169666,\n",
       "    -49.54198290745583,\n",
       "    -68.31701333568941,\n",
       "    -50.77409388274395,\n",
       "    -104.06052342255525,\n",
       "    -71.59297935962763,\n",
       "    -52.64472254305488,\n",
       "    -75.24756458826604,\n",
       "    -65.74113794073324,\n",
       "    -70.62956778435573,\n",
       "    -73.76896227949591,\n",
       "    -61.592280583815175,\n",
       "    -67.90439614059281,\n",
       "    -72.79961989636169,\n",
       "    -70.85625778827225,\n",
       "    -70.79512555120856,\n",
       "    -66.76146447263963,\n",
       "    -62.8680896802631,\n",
       "    -65.97420138751262,\n",
       "    -68.80885757133204,\n",
       "    -72.94362144805115,\n",
       "    -66.55936276443563,\n",
       "    -65.77110274114067,\n",
       "    -40.3743439790754,\n",
       "    -74.73865077140705,\n",
       "    -79.1835315989487,\n",
       "    -63.376725688697405,\n",
       "    -71.01276151594345,\n",
       "    -59.03884603034237,\n",
       "    -70.36451916768158,\n",
       "    -65.38278418182145,\n",
       "    -60.816647503026964,\n",
       "    -116.1494655720994,\n",
       "    -64.2136393616671,\n",
       "    -60.89794537327549,\n",
       "    -67.50068112693641,\n",
       "    -63.867410192745254,\n",
       "    -60.02175862962226,\n",
       "    -67.11362054511157,\n",
       "    -73.12944648129312,\n",
       "    -61.92876137078322,\n",
       "    -73.08008297614136,\n",
       "    -68.3286512587571,\n",
       "    -96.18195953682057,\n",
       "    -62.061728986488774,\n",
       "    -68.8801436657608,\n",
       "    -67.80342781174282,\n",
       "    -66.7521613977031,\n",
       "    -63.166851231820225,\n",
       "    -64.61764809208084,\n",
       "    -69.75887228299906,\n",
       "    -70.0414225553602,\n",
       "    -65.55349109841646,\n",
       "    -64.15841156921006,\n",
       "    -64.50348328203539,\n",
       "    -68.2744631580702,\n",
       "    -69.27297273072449,\n",
       "    -54.499972394707754,\n",
       "    -66.12134575885096,\n",
       "    -117.14890305530149,\n",
       "    -69.9610906470103,\n",
       "    -59.28734392288296,\n",
       "    -59.7541801896703,\n",
       "    -67.8042151717646,\n",
       "    -68.31762265259528,\n",
       "    -65.01497659453396,\n",
       "    -73.10569115247371,\n",
       "    -82.55926298470432,\n",
       "    -55.079243083419016,\n",
       "    -63.36274141566443,\n",
       "    -74.58744342564313,\n",
       "    -63.25802751288948,\n",
       "    -44.603797380767304,\n",
       "    -67.72719103716697,\n",
       "    -64.9860683043828,\n",
       "    -116.8125856203505,\n",
       "    -70.70259990271029,\n",
       "    -101.28016149513478,\n",
       "    -71.54548942305193,\n",
       "    -48.948135084075815,\n",
       "    -75.16918573570602,\n",
       "    -67.19630202925359,\n",
       "    -54.74202131291452,\n",
       "    -59.036711116608664,\n",
       "    -74.95629520591811,\n",
       "    -68.39559502862501,\n",
       "    -69.0983053523873,\n",
       "    -71.22356650892885,\n",
       "    -73.33716480616407],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22083996180379153,\n",
       "   'mean_inference_ms': 0.5709625266544254,\n",
       "   'mean_action_processing_ms': 0.07600212399711107,\n",
       "   'mean_env_wait_ms': 1.1401035696342916,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 88500,\n",
       "  'agent_timesteps_total': 88500,\n",
       "  'timers': {'learn_time_ms': 1.71, 'learn_throughput': 58475.944},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.8890085,\n",
       "     'max_q': -2.5599358,\n",
       "     'min_q': -23.088543,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 88500,\n",
       "   'num_agent_steps_sampled': 88500,\n",
       "   'num_steps_trained': 8700100,\n",
       "   'num_agent_steps_trained': 8700100,\n",
       "   'last_target_update_ts': 88500,\n",
       "   'num_target_updates': 87001},\n",
       "  'done': False,\n",
       "  'episodes_total': 876,\n",
       "  'training_iteration': 59,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-10-15',\n",
       "  'timestamp': 1625501415,\n",
       "  'time_this_iter_s': 20.34515690803528,\n",
       "  'time_total_s': 1157.8725514411926,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1157.8725514411926,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 59,\n",
       "  'perf': {'cpu_util_percent': 12.348148148148145,\n",
       "   'ram_util_percent': 47.099999999999994,\n",
       "   'gpu_util_percent0': 0.23666666666666666,\n",
       "   'vram_util_percent0': 0.5355455173915927}},\n",
       " {'episode_reward_max': -38.11275716816903,\n",
       "  'episode_reward_min': -117.14890305530149,\n",
       "  'episode_reward_mean': -68.82312454763854,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-104.06052342255525,\n",
       "    -71.59297935962763,\n",
       "    -52.64472254305488,\n",
       "    -75.24756458826604,\n",
       "    -65.74113794073324,\n",
       "    -70.62956778435573,\n",
       "    -73.76896227949591,\n",
       "    -61.592280583815175,\n",
       "    -67.90439614059281,\n",
       "    -72.79961989636169,\n",
       "    -70.85625778827225,\n",
       "    -70.79512555120856,\n",
       "    -66.76146447263963,\n",
       "    -62.8680896802631,\n",
       "    -65.97420138751262,\n",
       "    -68.80885757133204,\n",
       "    -72.94362144805115,\n",
       "    -66.55936276443563,\n",
       "    -65.77110274114067,\n",
       "    -40.3743439790754,\n",
       "    -74.73865077140705,\n",
       "    -79.1835315989487,\n",
       "    -63.376725688697405,\n",
       "    -71.01276151594345,\n",
       "    -59.03884603034237,\n",
       "    -70.36451916768158,\n",
       "    -65.38278418182145,\n",
       "    -60.816647503026964,\n",
       "    -116.1494655720994,\n",
       "    -64.2136393616671,\n",
       "    -60.89794537327549,\n",
       "    -67.50068112693641,\n",
       "    -63.867410192745254,\n",
       "    -60.02175862962226,\n",
       "    -67.11362054511157,\n",
       "    -73.12944648129312,\n",
       "    -61.92876137078322,\n",
       "    -73.08008297614136,\n",
       "    -68.3286512587571,\n",
       "    -96.18195953682057,\n",
       "    -62.061728986488774,\n",
       "    -68.8801436657608,\n",
       "    -67.80342781174282,\n",
       "    -66.7521613977031,\n",
       "    -63.166851231820225,\n",
       "    -64.61764809208084,\n",
       "    -69.75887228299906,\n",
       "    -70.0414225553602,\n",
       "    -65.55349109841646,\n",
       "    -64.15841156921006,\n",
       "    -64.50348328203539,\n",
       "    -68.2744631580702,\n",
       "    -69.27297273072449,\n",
       "    -54.499972394707754,\n",
       "    -66.12134575885096,\n",
       "    -117.14890305530149,\n",
       "    -69.9610906470103,\n",
       "    -59.28734392288296,\n",
       "    -59.7541801896703,\n",
       "    -67.8042151717646,\n",
       "    -68.31762265259528,\n",
       "    -65.01497659453396,\n",
       "    -73.10569115247371,\n",
       "    -82.55926298470432,\n",
       "    -55.079243083419016,\n",
       "    -63.36274141566443,\n",
       "    -74.58744342564313,\n",
       "    -63.25802751288948,\n",
       "    -44.603797380767304,\n",
       "    -67.72719103716697,\n",
       "    -64.9860683043828,\n",
       "    -116.8125856203505,\n",
       "    -70.70259990271029,\n",
       "    -101.28016149513478,\n",
       "    -71.54548942305193,\n",
       "    -48.948135084075815,\n",
       "    -75.16918573570602,\n",
       "    -67.19630202925359,\n",
       "    -54.74202131291452,\n",
       "    -59.036711116608664,\n",
       "    -74.95629520591811,\n",
       "    -68.39559502862501,\n",
       "    -69.0983053523873,\n",
       "    -71.22356650892885,\n",
       "    -73.33716480616407,\n",
       "    -38.522670516028214,\n",
       "    -65.24351284718362,\n",
       "    -113.30964425049497,\n",
       "    -92.12805268308048,\n",
       "    -71.95130075237304,\n",
       "    -64.61015798122881,\n",
       "    -63.43934116986591,\n",
       "    -73.16998209626905,\n",
       "    -67.56823308293218,\n",
       "    -80.01686066765781,\n",
       "    -61.18453585949286,\n",
       "    -43.656375700424555,\n",
       "    -38.11275716816903,\n",
       "    -56.86373135106804,\n",
       "    -64.04491466300337],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22080515276146,\n",
       "   'mean_inference_ms': 0.5712110024471926,\n",
       "   'mean_action_processing_ms': 0.07599287832407423,\n",
       "   'mean_env_wait_ms': 1.140545606882895,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 90000,\n",
       "  'agent_timesteps_total': 90000,\n",
       "  'timers': {'learn_time_ms': 1.557, 'learn_throughput': 64236.22},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.189775,\n",
       "     'max_q': -4.5601983,\n",
       "     'min_q': -21.860762,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 90000,\n",
       "   'num_agent_steps_sampled': 90000,\n",
       "   'num_steps_trained': 8850100,\n",
       "   'num_agent_steps_trained': 8850100,\n",
       "   'last_target_update_ts': 90000,\n",
       "   'num_target_updates': 88501},\n",
       "  'done': False,\n",
       "  'episodes_total': 891,\n",
       "  'training_iteration': 60,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-10-35',\n",
       "  'timestamp': 1625501435,\n",
       "  'time_this_iter_s': 20.183229684829712,\n",
       "  'time_total_s': 1178.0557811260223,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1178.0557811260223,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 60,\n",
       "  'perf': {'cpu_util_percent': 12.553846153846155,\n",
       "   'ram_util_percent': 47.099999999999994,\n",
       "   'gpu_util_percent0': 0.2569230769230769,\n",
       "   'vram_util_percent0': 0.5355112798221978}},\n",
       " {'episode_reward_max': -35.06967786924983,\n",
       "  'episode_reward_min': -117.14890305530149,\n",
       "  'episode_reward_mean': -68.10991385523522,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 14,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-65.97420138751262,\n",
       "    -68.80885757133204,\n",
       "    -72.94362144805115,\n",
       "    -66.55936276443563,\n",
       "    -65.77110274114067,\n",
       "    -40.3743439790754,\n",
       "    -74.73865077140705,\n",
       "    -79.1835315989487,\n",
       "    -63.376725688697405,\n",
       "    -71.01276151594345,\n",
       "    -59.03884603034237,\n",
       "    -70.36451916768158,\n",
       "    -65.38278418182145,\n",
       "    -60.816647503026964,\n",
       "    -116.1494655720994,\n",
       "    -64.2136393616671,\n",
       "    -60.89794537327549,\n",
       "    -67.50068112693641,\n",
       "    -63.867410192745254,\n",
       "    -60.02175862962226,\n",
       "    -67.11362054511157,\n",
       "    -73.12944648129312,\n",
       "    -61.92876137078322,\n",
       "    -73.08008297614136,\n",
       "    -68.3286512587571,\n",
       "    -96.18195953682057,\n",
       "    -62.061728986488774,\n",
       "    -68.8801436657608,\n",
       "    -67.80342781174282,\n",
       "    -66.7521613977031,\n",
       "    -63.166851231820225,\n",
       "    -64.61764809208084,\n",
       "    -69.75887228299906,\n",
       "    -70.0414225553602,\n",
       "    -65.55349109841646,\n",
       "    -64.15841156921006,\n",
       "    -64.50348328203539,\n",
       "    -68.2744631580702,\n",
       "    -69.27297273072449,\n",
       "    -54.499972394707754,\n",
       "    -66.12134575885096,\n",
       "    -117.14890305530149,\n",
       "    -69.9610906470103,\n",
       "    -59.28734392288296,\n",
       "    -59.7541801896703,\n",
       "    -67.8042151717646,\n",
       "    -68.31762265259528,\n",
       "    -65.01497659453396,\n",
       "    -73.10569115247371,\n",
       "    -82.55926298470432,\n",
       "    -55.079243083419016,\n",
       "    -63.36274141566443,\n",
       "    -74.58744342564313,\n",
       "    -63.25802751288948,\n",
       "    -44.603797380767304,\n",
       "    -67.72719103716697,\n",
       "    -64.9860683043828,\n",
       "    -116.8125856203505,\n",
       "    -70.70259990271029,\n",
       "    -101.28016149513478,\n",
       "    -71.54548942305193,\n",
       "    -48.948135084075815,\n",
       "    -75.16918573570602,\n",
       "    -67.19630202925359,\n",
       "    -54.74202131291452,\n",
       "    -59.036711116608664,\n",
       "    -74.95629520591811,\n",
       "    -68.39559502862501,\n",
       "    -69.0983053523873,\n",
       "    -71.22356650892885,\n",
       "    -73.33716480616407,\n",
       "    -38.522670516028214,\n",
       "    -65.24351284718362,\n",
       "    -113.30964425049497,\n",
       "    -92.12805268308048,\n",
       "    -71.95130075237304,\n",
       "    -64.61015798122881,\n",
       "    -63.43934116986591,\n",
       "    -73.16998209626905,\n",
       "    -67.56823308293218,\n",
       "    -80.01686066765781,\n",
       "    -61.18453585949286,\n",
       "    -43.656375700424555,\n",
       "    -38.11275716816903,\n",
       "    -56.86373135106804,\n",
       "    -64.04491466300337,\n",
       "    -101.71482132552961,\n",
       "    -66.34295374005956,\n",
       "    -64.32231620153159,\n",
       "    -68.02894412352799,\n",
       "    -41.530872716761706,\n",
       "    -53.19723839564521,\n",
       "    -64.66777917486169,\n",
       "    -73.68734568350608,\n",
       "    -64.9537033312937,\n",
       "    -67.16794528101366,\n",
       "    -109.10978685783694,\n",
       "    -49.394107144813354,\n",
       "    -56.75413094527836,\n",
       "    -35.06967786924983],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22077534468969226,\n",
       "   'mean_inference_ms': 0.5714924412811,\n",
       "   'mean_action_processing_ms': 0.07598360684069215,\n",
       "   'mean_env_wait_ms': 1.1407862551080472,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 91500,\n",
       "  'agent_timesteps_total': 91500,\n",
       "  'timers': {'learn_time_ms': 1.405, 'learn_throughput': 71177.966},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.410518,\n",
       "     'max_q': -4.9896708,\n",
       "     'min_q': -22.802738,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 91500,\n",
       "   'num_agent_steps_sampled': 91500,\n",
       "   'num_steps_trained': 9000100,\n",
       "   'num_agent_steps_trained': 9000100,\n",
       "   'last_target_update_ts': 91500,\n",
       "   'num_target_updates': 90001},\n",
       "  'done': False,\n",
       "  'episodes_total': 905,\n",
       "  'training_iteration': 61,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-10-56',\n",
       "  'timestamp': 1625501456,\n",
       "  'time_this_iter_s': 20.598267793655396,\n",
       "  'time_total_s': 1198.6540489196777,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1198.6540489196777,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 61,\n",
       "  'perf': {'cpu_util_percent': 12.370370370370372,\n",
       "   'ram_util_percent': 47.20000000000001,\n",
       "   'gpu_util_percent0': 0.22740740740740742,\n",
       "   'vram_util_percent0': 0.5355076375275813}},\n",
       " {'episode_reward_max': -35.06967786924983,\n",
       "  'episode_reward_min': -117.14890305530149,\n",
       "  'episode_reward_mean': -67.4017752412056,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-64.2136393616671,\n",
       "    -60.89794537327549,\n",
       "    -67.50068112693641,\n",
       "    -63.867410192745254,\n",
       "    -60.02175862962226,\n",
       "    -67.11362054511157,\n",
       "    -73.12944648129312,\n",
       "    -61.92876137078322,\n",
       "    -73.08008297614136,\n",
       "    -68.3286512587571,\n",
       "    -96.18195953682057,\n",
       "    -62.061728986488774,\n",
       "    -68.8801436657608,\n",
       "    -67.80342781174282,\n",
       "    -66.7521613977031,\n",
       "    -63.166851231820225,\n",
       "    -64.61764809208084,\n",
       "    -69.75887228299906,\n",
       "    -70.0414225553602,\n",
       "    -65.55349109841646,\n",
       "    -64.15841156921006,\n",
       "    -64.50348328203539,\n",
       "    -68.2744631580702,\n",
       "    -69.27297273072449,\n",
       "    -54.499972394707754,\n",
       "    -66.12134575885096,\n",
       "    -117.14890305530149,\n",
       "    -69.9610906470103,\n",
       "    -59.28734392288296,\n",
       "    -59.7541801896703,\n",
       "    -67.8042151717646,\n",
       "    -68.31762265259528,\n",
       "    -65.01497659453396,\n",
       "    -73.10569115247371,\n",
       "    -82.55926298470432,\n",
       "    -55.079243083419016,\n",
       "    -63.36274141566443,\n",
       "    -74.58744342564313,\n",
       "    -63.25802751288948,\n",
       "    -44.603797380767304,\n",
       "    -67.72719103716697,\n",
       "    -64.9860683043828,\n",
       "    -116.8125856203505,\n",
       "    -70.70259990271029,\n",
       "    -101.28016149513478,\n",
       "    -71.54548942305193,\n",
       "    -48.948135084075815,\n",
       "    -75.16918573570602,\n",
       "    -67.19630202925359,\n",
       "    -54.74202131291452,\n",
       "    -59.036711116608664,\n",
       "    -74.95629520591811,\n",
       "    -68.39559502862501,\n",
       "    -69.0983053523873,\n",
       "    -71.22356650892885,\n",
       "    -73.33716480616407,\n",
       "    -38.522670516028214,\n",
       "    -65.24351284718362,\n",
       "    -113.30964425049497,\n",
       "    -92.12805268308048,\n",
       "    -71.95130075237304,\n",
       "    -64.61015798122881,\n",
       "    -63.43934116986591,\n",
       "    -73.16998209626905,\n",
       "    -67.56823308293218,\n",
       "    -80.01686066765781,\n",
       "    -61.18453585949286,\n",
       "    -43.656375700424555,\n",
       "    -38.11275716816903,\n",
       "    -56.86373135106804,\n",
       "    -64.04491466300337,\n",
       "    -101.71482132552961,\n",
       "    -66.34295374005956,\n",
       "    -64.32231620153159,\n",
       "    -68.02894412352799,\n",
       "    -41.530872716761706,\n",
       "    -53.19723839564521,\n",
       "    -64.66777917486169,\n",
       "    -73.68734568350608,\n",
       "    -64.9537033312937,\n",
       "    -67.16794528101366,\n",
       "    -109.10978685783694,\n",
       "    -49.394107144813354,\n",
       "    -56.75413094527836,\n",
       "    -35.06967786924983,\n",
       "    -67.0278688120624,\n",
       "    -67.7969399132846,\n",
       "    -68.86941589657218,\n",
       "    -64.21370599435058,\n",
       "    -62.000370018773275,\n",
       "    -62.5503544348368,\n",
       "    -66.76950677650098,\n",
       "    -66.47421723701952,\n",
       "    -62.2373812905244,\n",
       "    -64.63347309536655,\n",
       "    -68.18117901348968,\n",
       "    -72.69746395027322,\n",
       "    -72.10050541109645,\n",
       "    -38.95217724786652,\n",
       "    -65.17700142653865],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2207436432894764,\n",
       "   'mean_inference_ms': 0.5717324413066645,\n",
       "   'mean_action_processing_ms': 0.07597532286721995,\n",
       "   'mean_env_wait_ms': 1.1409951862531194,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 93000,\n",
       "  'agent_timesteps_total': 93000,\n",
       "  'timers': {'learn_time_ms': 1.407, 'learn_throughput': 71070.625},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.240437,\n",
       "     'max_q': -4.4705057,\n",
       "     'min_q': -22.96716,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 93000,\n",
       "   'num_agent_steps_sampled': 93000,\n",
       "   'num_steps_trained': 9150100,\n",
       "   'num_agent_steps_trained': 9150100,\n",
       "   'last_target_update_ts': 93000,\n",
       "   'num_target_updates': 91501},\n",
       "  'done': False,\n",
       "  'episodes_total': 920,\n",
       "  'training_iteration': 62,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-11-16',\n",
       "  'timestamp': 1625501476,\n",
       "  'time_this_iter_s': 20.548941373825073,\n",
       "  'time_total_s': 1219.2029902935028,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1219.2029902935028,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 62,\n",
       "  'perf': {'cpu_util_percent': 12.37037037037037,\n",
       "   'ram_util_percent': 47.20740740740741,\n",
       "   'gpu_util_percent0': 0.25592592592592595,\n",
       "   'vram_util_percent0': 0.5354886975955757}},\n",
       " {'episode_reward_max': -35.06967786924983,\n",
       "  'episode_reward_min': -117.14890305530149,\n",
       "  'episode_reward_mean': -66.43691146788098,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-63.166851231820225,\n",
       "    -64.61764809208084,\n",
       "    -69.75887228299906,\n",
       "    -70.0414225553602,\n",
       "    -65.55349109841646,\n",
       "    -64.15841156921006,\n",
       "    -64.50348328203539,\n",
       "    -68.2744631580702,\n",
       "    -69.27297273072449,\n",
       "    -54.499972394707754,\n",
       "    -66.12134575885096,\n",
       "    -117.14890305530149,\n",
       "    -69.9610906470103,\n",
       "    -59.28734392288296,\n",
       "    -59.7541801896703,\n",
       "    -67.8042151717646,\n",
       "    -68.31762265259528,\n",
       "    -65.01497659453396,\n",
       "    -73.10569115247371,\n",
       "    -82.55926298470432,\n",
       "    -55.079243083419016,\n",
       "    -63.36274141566443,\n",
       "    -74.58744342564313,\n",
       "    -63.25802751288948,\n",
       "    -44.603797380767304,\n",
       "    -67.72719103716697,\n",
       "    -64.9860683043828,\n",
       "    -116.8125856203505,\n",
       "    -70.70259990271029,\n",
       "    -101.28016149513478,\n",
       "    -71.54548942305193,\n",
       "    -48.948135084075815,\n",
       "    -75.16918573570602,\n",
       "    -67.19630202925359,\n",
       "    -54.74202131291452,\n",
       "    -59.036711116608664,\n",
       "    -74.95629520591811,\n",
       "    -68.39559502862501,\n",
       "    -69.0983053523873,\n",
       "    -71.22356650892885,\n",
       "    -73.33716480616407,\n",
       "    -38.522670516028214,\n",
       "    -65.24351284718362,\n",
       "    -113.30964425049497,\n",
       "    -92.12805268308048,\n",
       "    -71.95130075237304,\n",
       "    -64.61015798122881,\n",
       "    -63.43934116986591,\n",
       "    -73.16998209626905,\n",
       "    -67.56823308293218,\n",
       "    -80.01686066765781,\n",
       "    -61.18453585949286,\n",
       "    -43.656375700424555,\n",
       "    -38.11275716816903,\n",
       "    -56.86373135106804,\n",
       "    -64.04491466300337,\n",
       "    -101.71482132552961,\n",
       "    -66.34295374005956,\n",
       "    -64.32231620153159,\n",
       "    -68.02894412352799,\n",
       "    -41.530872716761706,\n",
       "    -53.19723839564521,\n",
       "    -64.66777917486169,\n",
       "    -73.68734568350608,\n",
       "    -64.9537033312937,\n",
       "    -67.16794528101366,\n",
       "    -109.10978685783694,\n",
       "    -49.394107144813354,\n",
       "    -56.75413094527836,\n",
       "    -35.06967786924983,\n",
       "    -67.0278688120624,\n",
       "    -67.7969399132846,\n",
       "    -68.86941589657218,\n",
       "    -64.21370599435058,\n",
       "    -62.000370018773275,\n",
       "    -62.5503544348368,\n",
       "    -66.76950677650098,\n",
       "    -66.47421723701952,\n",
       "    -62.2373812905244,\n",
       "    -64.63347309536655,\n",
       "    -68.18117901348968,\n",
       "    -72.69746395027322,\n",
       "    -72.10050541109645,\n",
       "    -38.95217724786652,\n",
       "    -65.17700142653865,\n",
       "    -64.73357277443519,\n",
       "    -46.74205426262428,\n",
       "    -47.4623818584376,\n",
       "    -62.6358117597889,\n",
       "    -66.16291252239013,\n",
       "    -71.74020371917665,\n",
       "    -65.65618754838286,\n",
       "    -60.29304251147894,\n",
       "    -65.87239166106504,\n",
       "    -103.65339490229107,\n",
       "    -66.61999421169297,\n",
       "    -40.82714953723617,\n",
       "    -35.57419946966036,\n",
       "    -61.249863336629915,\n",
       "    -66.05188130709512],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22071340308280488,\n",
       "   'mean_inference_ms': 0.5719932194530729,\n",
       "   'mean_action_processing_ms': 0.07596911407900166,\n",
       "   'mean_env_wait_ms': 1.1409521072106381,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 94500,\n",
       "  'agent_timesteps_total': 94500,\n",
       "  'timers': {'learn_time_ms': 1.487, 'learn_throughput': 67271.392},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.430511,\n",
       "     'max_q': -5.111969,\n",
       "     'min_q': -21.238857,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 94500,\n",
       "   'num_agent_steps_sampled': 94500,\n",
       "   'num_steps_trained': 9300100,\n",
       "   'num_agent_steps_trained': 9300100,\n",
       "   'last_target_update_ts': 94500,\n",
       "   'num_target_updates': 93001},\n",
       "  'done': False,\n",
       "  'episodes_total': 935,\n",
       "  'training_iteration': 63,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-11-37',\n",
       "  'timestamp': 1625501497,\n",
       "  'time_this_iter_s': 20.57982063293457,\n",
       "  'time_total_s': 1239.7828109264374,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1239.7828109264374,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 63,\n",
       "  'perf': {'cpu_util_percent': 12.62962962962963,\n",
       "   'ram_util_percent': 47.04074074074074,\n",
       "   'gpu_util_percent0': 0.24037037037037035,\n",
       "   'vram_util_percent0': 0.5355455173915926}},\n",
       " {'episode_reward_max': -35.06967786924983,\n",
       "  'episode_reward_min': -116.8125856203505,\n",
       "  'episode_reward_mean': -67.52476609368598,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-67.8042151717646,\n",
       "    -68.31762265259528,\n",
       "    -65.01497659453396,\n",
       "    -73.10569115247371,\n",
       "    -82.55926298470432,\n",
       "    -55.079243083419016,\n",
       "    -63.36274141566443,\n",
       "    -74.58744342564313,\n",
       "    -63.25802751288948,\n",
       "    -44.603797380767304,\n",
       "    -67.72719103716697,\n",
       "    -64.9860683043828,\n",
       "    -116.8125856203505,\n",
       "    -70.70259990271029,\n",
       "    -101.28016149513478,\n",
       "    -71.54548942305193,\n",
       "    -48.948135084075815,\n",
       "    -75.16918573570602,\n",
       "    -67.19630202925359,\n",
       "    -54.74202131291452,\n",
       "    -59.036711116608664,\n",
       "    -74.95629520591811,\n",
       "    -68.39559502862501,\n",
       "    -69.0983053523873,\n",
       "    -71.22356650892885,\n",
       "    -73.33716480616407,\n",
       "    -38.522670516028214,\n",
       "    -65.24351284718362,\n",
       "    -113.30964425049497,\n",
       "    -92.12805268308048,\n",
       "    -71.95130075237304,\n",
       "    -64.61015798122881,\n",
       "    -63.43934116986591,\n",
       "    -73.16998209626905,\n",
       "    -67.56823308293218,\n",
       "    -80.01686066765781,\n",
       "    -61.18453585949286,\n",
       "    -43.656375700424555,\n",
       "    -38.11275716816903,\n",
       "    -56.86373135106804,\n",
       "    -64.04491466300337,\n",
       "    -101.71482132552961,\n",
       "    -66.34295374005956,\n",
       "    -64.32231620153159,\n",
       "    -68.02894412352799,\n",
       "    -41.530872716761706,\n",
       "    -53.19723839564521,\n",
       "    -64.66777917486169,\n",
       "    -73.68734568350608,\n",
       "    -64.9537033312937,\n",
       "    -67.16794528101366,\n",
       "    -109.10978685783694,\n",
       "    -49.394107144813354,\n",
       "    -56.75413094527836,\n",
       "    -35.06967786924983,\n",
       "    -67.0278688120624,\n",
       "    -67.7969399132846,\n",
       "    -68.86941589657218,\n",
       "    -64.21370599435058,\n",
       "    -62.000370018773275,\n",
       "    -62.5503544348368,\n",
       "    -66.76950677650098,\n",
       "    -66.47421723701952,\n",
       "    -62.2373812905244,\n",
       "    -64.63347309536655,\n",
       "    -68.18117901348968,\n",
       "    -72.69746395027322,\n",
       "    -72.10050541109645,\n",
       "    -38.95217724786652,\n",
       "    -65.17700142653865,\n",
       "    -64.73357277443519,\n",
       "    -46.74205426262428,\n",
       "    -47.4623818584376,\n",
       "    -62.6358117597889,\n",
       "    -66.16291252239013,\n",
       "    -71.74020371917665,\n",
       "    -65.65618754838286,\n",
       "    -60.29304251147894,\n",
       "    -65.87239166106504,\n",
       "    -103.65339490229107,\n",
       "    -66.61999421169297,\n",
       "    -40.82714953723617,\n",
       "    -35.57419946966036,\n",
       "    -61.249863336629915,\n",
       "    -66.05188130709512,\n",
       "    -65.43389608496088,\n",
       "    -67.92621691307652,\n",
       "    -68.44118440007676,\n",
       "    -60.82521157023855,\n",
       "    -80.5706655978052,\n",
       "    -108.35589974322085,\n",
       "    -71.79276954645,\n",
       "    -77.0367945948122,\n",
       "    -70.40406942382113,\n",
       "    -64.7458730411956,\n",
       "    -85.78466075099247,\n",
       "    -62.95600260183133,\n",
       "    -65.24278628633773,\n",
       "    -115.75136708347257,\n",
       "    -69.63851691135038],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22068715889947832,\n",
       "   'mean_inference_ms': 0.5722478348591536,\n",
       "   'mean_action_processing_ms': 0.07596767492350529,\n",
       "   'mean_env_wait_ms': 1.1406532992204628,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 96000,\n",
       "  'agent_timesteps_total': 96000,\n",
       "  'timers': {'learn_time_ms': 1.512, 'learn_throughput': 66123.883},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.718281,\n",
       "     'max_q': -5.363883,\n",
       "     'min_q': -20.835627,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 96000,\n",
       "   'num_agent_steps_sampled': 96000,\n",
       "   'num_steps_trained': 9450100,\n",
       "   'num_agent_steps_trained': 9450100,\n",
       "   'last_target_update_ts': 96000,\n",
       "   'num_target_updates': 94501},\n",
       "  'done': False,\n",
       "  'episodes_total': 950,\n",
       "  'training_iteration': 64,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-11-57',\n",
       "  'timestamp': 1625501517,\n",
       "  'time_this_iter_s': 20.553284168243408,\n",
       "  'time_total_s': 1260.3360950946808,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1260.3360950946808,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 64,\n",
       "  'perf': {'cpu_util_percent': 12.959259259259259,\n",
       "   'ram_util_percent': 47.0037037037037,\n",
       "   'gpu_util_percent0': 0.24925925925925924,\n",
       "   'vram_util_percent0': 0.535895906133697}},\n",
       " {'episode_reward_max': -35.06967786924983,\n",
       "  'episode_reward_min': -115.75136708347257,\n",
       "  'episode_reward_mean': -66.41170620722721,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-71.54548942305193,\n",
       "    -48.948135084075815,\n",
       "    -75.16918573570602,\n",
       "    -67.19630202925359,\n",
       "    -54.74202131291452,\n",
       "    -59.036711116608664,\n",
       "    -74.95629520591811,\n",
       "    -68.39559502862501,\n",
       "    -69.0983053523873,\n",
       "    -71.22356650892885,\n",
       "    -73.33716480616407,\n",
       "    -38.522670516028214,\n",
       "    -65.24351284718362,\n",
       "    -113.30964425049497,\n",
       "    -92.12805268308048,\n",
       "    -71.95130075237304,\n",
       "    -64.61015798122881,\n",
       "    -63.43934116986591,\n",
       "    -73.16998209626905,\n",
       "    -67.56823308293218,\n",
       "    -80.01686066765781,\n",
       "    -61.18453585949286,\n",
       "    -43.656375700424555,\n",
       "    -38.11275716816903,\n",
       "    -56.86373135106804,\n",
       "    -64.04491466300337,\n",
       "    -101.71482132552961,\n",
       "    -66.34295374005956,\n",
       "    -64.32231620153159,\n",
       "    -68.02894412352799,\n",
       "    -41.530872716761706,\n",
       "    -53.19723839564521,\n",
       "    -64.66777917486169,\n",
       "    -73.68734568350608,\n",
       "    -64.9537033312937,\n",
       "    -67.16794528101366,\n",
       "    -109.10978685783694,\n",
       "    -49.394107144813354,\n",
       "    -56.75413094527836,\n",
       "    -35.06967786924983,\n",
       "    -67.0278688120624,\n",
       "    -67.7969399132846,\n",
       "    -68.86941589657218,\n",
       "    -64.21370599435058,\n",
       "    -62.000370018773275,\n",
       "    -62.5503544348368,\n",
       "    -66.76950677650098,\n",
       "    -66.47421723701952,\n",
       "    -62.2373812905244,\n",
       "    -64.63347309536655,\n",
       "    -68.18117901348968,\n",
       "    -72.69746395027322,\n",
       "    -72.10050541109645,\n",
       "    -38.95217724786652,\n",
       "    -65.17700142653865,\n",
       "    -64.73357277443519,\n",
       "    -46.74205426262428,\n",
       "    -47.4623818584376,\n",
       "    -62.6358117597889,\n",
       "    -66.16291252239013,\n",
       "    -71.74020371917665,\n",
       "    -65.65618754838286,\n",
       "    -60.29304251147894,\n",
       "    -65.87239166106504,\n",
       "    -103.65339490229107,\n",
       "    -66.61999421169297,\n",
       "    -40.82714953723617,\n",
       "    -35.57419946966036,\n",
       "    -61.249863336629915,\n",
       "    -66.05188130709512,\n",
       "    -65.43389608496088,\n",
       "    -67.92621691307652,\n",
       "    -68.44118440007676,\n",
       "    -60.82521157023855,\n",
       "    -80.5706655978052,\n",
       "    -108.35589974322085,\n",
       "    -71.79276954645,\n",
       "    -77.0367945948122,\n",
       "    -70.40406942382113,\n",
       "    -64.7458730411956,\n",
       "    -85.78466075099247,\n",
       "    -62.95600260183133,\n",
       "    -65.24278628633773,\n",
       "    -115.75136708347257,\n",
       "    -69.63851691135038,\n",
       "    -67.25593900981487,\n",
       "    -70.75627539629865,\n",
       "    -69.28896810345432,\n",
       "    -53.758871836383115,\n",
       "    -65.61251891869999,\n",
       "    -61.867298510821136,\n",
       "    -36.80115849134961,\n",
       "    -69.97062187818197,\n",
       "    -62.313540129562526,\n",
       "    -75.47174345311674,\n",
       "    -76.97135070592464,\n",
       "    -63.22471292124002,\n",
       "    -62.59318319351331,\n",
       "    -61.74580797643405,\n",
       "    -70.26364856352838],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22067926215991157,\n",
       "   'mean_inference_ms': 0.5726660641884276,\n",
       "   'mean_action_processing_ms': 0.07598225069863958,\n",
       "   'mean_env_wait_ms': 1.1402082018393351,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 97500,\n",
       "  'agent_timesteps_total': 97500,\n",
       "  'timers': {'learn_time_ms': 1.684, 'learn_throughput': 59380.808},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.013858,\n",
       "     'max_q': -4.5872345,\n",
       "     'min_q': -20.548616,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 97500,\n",
       "   'num_agent_steps_sampled': 97500,\n",
       "   'num_steps_trained': 9600100,\n",
       "   'num_agent_steps_trained': 9600100,\n",
       "   'last_target_update_ts': 97500,\n",
       "   'num_target_updates': 96001},\n",
       "  'done': False,\n",
       "  'episodes_total': 965,\n",
       "  'training_iteration': 65,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-12-19',\n",
       "  'timestamp': 1625501539,\n",
       "  'time_this_iter_s': 21.26039743423462,\n",
       "  'time_total_s': 1281.5964925289154,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1281.5964925289154,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 65,\n",
       "  'perf': {'cpu_util_percent': 14.185714285714283,\n",
       "   'ram_util_percent': 47.05,\n",
       "   'gpu_util_percent0': 0.2271428571428571,\n",
       "   'vram_util_percent0': 0.5544343792234356}},\n",
       " {'episode_reward_max': -35.06967786924983,\n",
       "  'episode_reward_min': -115.75136708347257,\n",
       "  'episode_reward_mean': -66.17297421545148,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-71.95130075237304,\n",
       "    -64.61015798122881,\n",
       "    -63.43934116986591,\n",
       "    -73.16998209626905,\n",
       "    -67.56823308293218,\n",
       "    -80.01686066765781,\n",
       "    -61.18453585949286,\n",
       "    -43.656375700424555,\n",
       "    -38.11275716816903,\n",
       "    -56.86373135106804,\n",
       "    -64.04491466300337,\n",
       "    -101.71482132552961,\n",
       "    -66.34295374005956,\n",
       "    -64.32231620153159,\n",
       "    -68.02894412352799,\n",
       "    -41.530872716761706,\n",
       "    -53.19723839564521,\n",
       "    -64.66777917486169,\n",
       "    -73.68734568350608,\n",
       "    -64.9537033312937,\n",
       "    -67.16794528101366,\n",
       "    -109.10978685783694,\n",
       "    -49.394107144813354,\n",
       "    -56.75413094527836,\n",
       "    -35.06967786924983,\n",
       "    -67.0278688120624,\n",
       "    -67.7969399132846,\n",
       "    -68.86941589657218,\n",
       "    -64.21370599435058,\n",
       "    -62.000370018773275,\n",
       "    -62.5503544348368,\n",
       "    -66.76950677650098,\n",
       "    -66.47421723701952,\n",
       "    -62.2373812905244,\n",
       "    -64.63347309536655,\n",
       "    -68.18117901348968,\n",
       "    -72.69746395027322,\n",
       "    -72.10050541109645,\n",
       "    -38.95217724786652,\n",
       "    -65.17700142653865,\n",
       "    -64.73357277443519,\n",
       "    -46.74205426262428,\n",
       "    -47.4623818584376,\n",
       "    -62.6358117597889,\n",
       "    -66.16291252239013,\n",
       "    -71.74020371917665,\n",
       "    -65.65618754838286,\n",
       "    -60.29304251147894,\n",
       "    -65.87239166106504,\n",
       "    -103.65339490229107,\n",
       "    -66.61999421169297,\n",
       "    -40.82714953723617,\n",
       "    -35.57419946966036,\n",
       "    -61.249863336629915,\n",
       "    -66.05188130709512,\n",
       "    -65.43389608496088,\n",
       "    -67.92621691307652,\n",
       "    -68.44118440007676,\n",
       "    -60.82521157023855,\n",
       "    -80.5706655978052,\n",
       "    -108.35589974322085,\n",
       "    -71.79276954645,\n",
       "    -77.0367945948122,\n",
       "    -70.40406942382113,\n",
       "    -64.7458730411956,\n",
       "    -85.78466075099247,\n",
       "    -62.95600260183133,\n",
       "    -65.24278628633773,\n",
       "    -115.75136708347257,\n",
       "    -69.63851691135038,\n",
       "    -67.25593900981487,\n",
       "    -70.75627539629865,\n",
       "    -69.28896810345432,\n",
       "    -53.758871836383115,\n",
       "    -65.61251891869999,\n",
       "    -61.867298510821136,\n",
       "    -36.80115849134961,\n",
       "    -69.97062187818197,\n",
       "    -62.313540129562526,\n",
       "    -75.47174345311674,\n",
       "    -76.97135070592464,\n",
       "    -63.22471292124002,\n",
       "    -62.59318319351331,\n",
       "    -61.74580797643405,\n",
       "    -70.26364856352838,\n",
       "    -58.354122004198466,\n",
       "    -67.79801205310606,\n",
       "    -70.2679961430935,\n",
       "    -65.04617311662223,\n",
       "    -80.98699304924817,\n",
       "    -71.14442652837845,\n",
       "    -61.06628387378711,\n",
       "    -71.91711119829286,\n",
       "    -66.66182160728786,\n",
       "    -55.159950379141236,\n",
       "    -79.04543938027513,\n",
       "    -69.02792442432862,\n",
       "    -63.27644878883916,\n",
       "    -81.35776146791085,\n",
       "    -57.868988708338584],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22071793504143222,\n",
       "   'mean_inference_ms': 0.5730960901412169,\n",
       "   'mean_action_processing_ms': 0.07600756067102625,\n",
       "   'mean_env_wait_ms': 1.1397538149663022,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 99000,\n",
       "  'agent_timesteps_total': 99000,\n",
       "  'timers': {'learn_time_ms': 1.476, 'learn_throughput': 67729.811},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -14.73187,\n",
       "     'max_q': -4.386341,\n",
       "     'min_q': -23.540134,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 99000,\n",
       "   'num_agent_steps_sampled': 99000,\n",
       "   'num_steps_trained': 9750100,\n",
       "   'num_agent_steps_trained': 9750100,\n",
       "   'last_target_update_ts': 99000,\n",
       "   'num_target_updates': 97501},\n",
       "  'done': False,\n",
       "  'episodes_total': 980,\n",
       "  'training_iteration': 66,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-12-40',\n",
       "  'timestamp': 1625501560,\n",
       "  'time_this_iter_s': 21.028478622436523,\n",
       "  'time_total_s': 1302.624971151352,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1302.624971151352,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 66,\n",
       "  'perf': {'cpu_util_percent': 14.08888888888889,\n",
       "   'ram_util_percent': 46.87777777777779,\n",
       "   'gpu_util_percent0': 0.21185185185185187,\n",
       "   'vram_util_percent0': 0.5408392283871701}},\n",
       " {'episode_reward_max': -35.06967786924983,\n",
       "  'episode_reward_min': -115.75136708347257,\n",
       "  'episode_reward_mean': -66.18264925204232,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-41.530872716761706,\n",
       "    -53.19723839564521,\n",
       "    -64.66777917486169,\n",
       "    -73.68734568350608,\n",
       "    -64.9537033312937,\n",
       "    -67.16794528101366,\n",
       "    -109.10978685783694,\n",
       "    -49.394107144813354,\n",
       "    -56.75413094527836,\n",
       "    -35.06967786924983,\n",
       "    -67.0278688120624,\n",
       "    -67.7969399132846,\n",
       "    -68.86941589657218,\n",
       "    -64.21370599435058,\n",
       "    -62.000370018773275,\n",
       "    -62.5503544348368,\n",
       "    -66.76950677650098,\n",
       "    -66.47421723701952,\n",
       "    -62.2373812905244,\n",
       "    -64.63347309536655,\n",
       "    -68.18117901348968,\n",
       "    -72.69746395027322,\n",
       "    -72.10050541109645,\n",
       "    -38.95217724786652,\n",
       "    -65.17700142653865,\n",
       "    -64.73357277443519,\n",
       "    -46.74205426262428,\n",
       "    -47.4623818584376,\n",
       "    -62.6358117597889,\n",
       "    -66.16291252239013,\n",
       "    -71.74020371917665,\n",
       "    -65.65618754838286,\n",
       "    -60.29304251147894,\n",
       "    -65.87239166106504,\n",
       "    -103.65339490229107,\n",
       "    -66.61999421169297,\n",
       "    -40.82714953723617,\n",
       "    -35.57419946966036,\n",
       "    -61.249863336629915,\n",
       "    -66.05188130709512,\n",
       "    -65.43389608496088,\n",
       "    -67.92621691307652,\n",
       "    -68.44118440007676,\n",
       "    -60.82521157023855,\n",
       "    -80.5706655978052,\n",
       "    -108.35589974322085,\n",
       "    -71.79276954645,\n",
       "    -77.0367945948122,\n",
       "    -70.40406942382113,\n",
       "    -64.7458730411956,\n",
       "    -85.78466075099247,\n",
       "    -62.95600260183133,\n",
       "    -65.24278628633773,\n",
       "    -115.75136708347257,\n",
       "    -69.63851691135038,\n",
       "    -67.25593900981487,\n",
       "    -70.75627539629865,\n",
       "    -69.28896810345432,\n",
       "    -53.758871836383115,\n",
       "    -65.61251891869999,\n",
       "    -61.867298510821136,\n",
       "    -36.80115849134961,\n",
       "    -69.97062187818197,\n",
       "    -62.313540129562526,\n",
       "    -75.47174345311674,\n",
       "    -76.97135070592464,\n",
       "    -63.22471292124002,\n",
       "    -62.59318319351331,\n",
       "    -61.74580797643405,\n",
       "    -70.26364856352838,\n",
       "    -58.354122004198466,\n",
       "    -67.79801205310606,\n",
       "    -70.2679961430935,\n",
       "    -65.04617311662223,\n",
       "    -80.98699304924817,\n",
       "    -71.14442652837845,\n",
       "    -61.06628387378711,\n",
       "    -71.91711119829286,\n",
       "    -66.66182160728786,\n",
       "    -55.159950379141236,\n",
       "    -79.04543938027513,\n",
       "    -69.02792442432862,\n",
       "    -63.27644878883916,\n",
       "    -81.35776146791085,\n",
       "    -57.868988708338584,\n",
       "    -69.66841231046354,\n",
       "    -48.96550582198179,\n",
       "    -66.38045080640235,\n",
       "    -67.13603731999036,\n",
       "    -73.00286989429215,\n",
       "    -69.595305040884,\n",
       "    -69.2434960817763,\n",
       "    -51.78848616074407,\n",
       "    -59.05858788488524,\n",
       "    -51.51637187581709,\n",
       "    -110.94077079803134,\n",
       "    -56.775784043472036,\n",
       "    -63.35141726506677,\n",
       "    -62.968471838170345,\n",
       "    -65.60276240023859],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22077020428640487,\n",
       "   'mean_inference_ms': 0.5735134348363919,\n",
       "   'mean_action_processing_ms': 0.07604091032279263,\n",
       "   'mean_env_wait_ms': 1.1393263475490683,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 100500,\n",
       "  'agent_timesteps_total': 100500,\n",
       "  'timers': {'learn_time_ms': 1.382, 'learn_throughput': 72335.541},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.69884,\n",
       "     'max_q': -4.1292152,\n",
       "     'min_q': -23.591043,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 100500,\n",
       "   'num_agent_steps_sampled': 100500,\n",
       "   'num_steps_trained': 9900100,\n",
       "   'num_agent_steps_trained': 9900100,\n",
       "   'last_target_update_ts': 100500,\n",
       "   'num_target_updates': 99001},\n",
       "  'done': False,\n",
       "  'episodes_total': 995,\n",
       "  'training_iteration': 67,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-13-00',\n",
       "  'timestamp': 1625501580,\n",
       "  'time_this_iter_s': 20.560384035110474,\n",
       "  'time_total_s': 1323.1853551864624,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1323.1853551864624,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 67,\n",
       "  'perf': {'cpu_util_percent': 13.81851851851852,\n",
       "   'ram_util_percent': 46.87777777777777,\n",
       "   'gpu_util_percent0': 0.1414814814814815,\n",
       "   'vram_util_percent0': 0.5501860848319554}},\n",
       " {'episode_reward_max': -35.57419946966036,\n",
       "  'episode_reward_min': -115.75136708347257,\n",
       "  'episode_reward_mean': -66.20081334465952,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 14,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-62.000370018773275,\n",
       "    -62.5503544348368,\n",
       "    -66.76950677650098,\n",
       "    -66.47421723701952,\n",
       "    -62.2373812905244,\n",
       "    -64.63347309536655,\n",
       "    -68.18117901348968,\n",
       "    -72.69746395027322,\n",
       "    -72.10050541109645,\n",
       "    -38.95217724786652,\n",
       "    -65.17700142653865,\n",
       "    -64.73357277443519,\n",
       "    -46.74205426262428,\n",
       "    -47.4623818584376,\n",
       "    -62.6358117597889,\n",
       "    -66.16291252239013,\n",
       "    -71.74020371917665,\n",
       "    -65.65618754838286,\n",
       "    -60.29304251147894,\n",
       "    -65.87239166106504,\n",
       "    -103.65339490229107,\n",
       "    -66.61999421169297,\n",
       "    -40.82714953723617,\n",
       "    -35.57419946966036,\n",
       "    -61.249863336629915,\n",
       "    -66.05188130709512,\n",
       "    -65.43389608496088,\n",
       "    -67.92621691307652,\n",
       "    -68.44118440007676,\n",
       "    -60.82521157023855,\n",
       "    -80.5706655978052,\n",
       "    -108.35589974322085,\n",
       "    -71.79276954645,\n",
       "    -77.0367945948122,\n",
       "    -70.40406942382113,\n",
       "    -64.7458730411956,\n",
       "    -85.78466075099247,\n",
       "    -62.95600260183133,\n",
       "    -65.24278628633773,\n",
       "    -115.75136708347257,\n",
       "    -69.63851691135038,\n",
       "    -67.25593900981487,\n",
       "    -70.75627539629865,\n",
       "    -69.28896810345432,\n",
       "    -53.758871836383115,\n",
       "    -65.61251891869999,\n",
       "    -61.867298510821136,\n",
       "    -36.80115849134961,\n",
       "    -69.97062187818197,\n",
       "    -62.313540129562526,\n",
       "    -75.47174345311674,\n",
       "    -76.97135070592464,\n",
       "    -63.22471292124002,\n",
       "    -62.59318319351331,\n",
       "    -61.74580797643405,\n",
       "    -70.26364856352838,\n",
       "    -58.354122004198466,\n",
       "    -67.79801205310606,\n",
       "    -70.2679961430935,\n",
       "    -65.04617311662223,\n",
       "    -80.98699304924817,\n",
       "    -71.14442652837845,\n",
       "    -61.06628387378711,\n",
       "    -71.91711119829286,\n",
       "    -66.66182160728786,\n",
       "    -55.159950379141236,\n",
       "    -79.04543938027513,\n",
       "    -69.02792442432862,\n",
       "    -63.27644878883916,\n",
       "    -81.35776146791085,\n",
       "    -57.868988708338584,\n",
       "    -69.66841231046354,\n",
       "    -48.96550582198179,\n",
       "    -66.38045080640235,\n",
       "    -67.13603731999036,\n",
       "    -73.00286989429215,\n",
       "    -69.595305040884,\n",
       "    -69.2434960817763,\n",
       "    -51.78848616074407,\n",
       "    -59.05858788488524,\n",
       "    -51.51637187581709,\n",
       "    -110.94077079803134,\n",
       "    -56.775784043472036,\n",
       "    -63.35141726506677,\n",
       "    -62.968471838170345,\n",
       "    -65.60276240023859,\n",
       "    -67.97434127824522,\n",
       "    -53.58327196756974,\n",
       "    -60.31493794010647,\n",
       "    -66.83381297561193,\n",
       "    -72.79668094745652,\n",
       "    -66.34387575619114,\n",
       "    -62.55405820676121,\n",
       "    -56.68398998524689,\n",
       "    -63.41453208839491,\n",
       "    -59.24135232439338,\n",
       "    -71.27022802574756,\n",
       "    -65.98170009792311,\n",
       "    -67.6755355607271,\n",
       "    -50.58861012387705],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22082670004826696,\n",
       "   'mean_inference_ms': 0.5739093346229354,\n",
       "   'mean_action_processing_ms': 0.07607715331693632,\n",
       "   'mean_env_wait_ms': 1.138942868067584,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 102000,\n",
       "  'agent_timesteps_total': 102000,\n",
       "  'timers': {'learn_time_ms': 1.71, 'learn_throughput': 58479.205},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.442343,\n",
       "     'max_q': -5.4882793,\n",
       "     'min_q': -21.241568,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 102000,\n",
       "   'num_agent_steps_sampled': 102000,\n",
       "   'num_steps_trained': 10050100,\n",
       "   'num_agent_steps_trained': 10050100,\n",
       "   'last_target_update_ts': 102000,\n",
       "   'num_target_updates': 100501},\n",
       "  'done': False,\n",
       "  'episodes_total': 1009,\n",
       "  'training_iteration': 68,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-13-21',\n",
       "  'timestamp': 1625501601,\n",
       "  'time_this_iter_s': 20.49019742012024,\n",
       "  'time_total_s': 1343.6755526065826,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1343.6755526065826,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 68,\n",
       "  'perf': {'cpu_util_percent': 13.481481481481481,\n",
       "   'ram_util_percent': 46.88148148148149,\n",
       "   'gpu_util_percent0': 0.17592592592592596,\n",
       "   'vram_util_percent0': 0.5584817750504276}},\n",
       " {'episode_reward_max': -35.57419946966036,\n",
       "  'episode_reward_min': -115.75136708347257,\n",
       "  'episode_reward_mean': -68.31411288448375,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-66.16291252239013,\n",
       "    -71.74020371917665,\n",
       "    -65.65618754838286,\n",
       "    -60.29304251147894,\n",
       "    -65.87239166106504,\n",
       "    -103.65339490229107,\n",
       "    -66.61999421169297,\n",
       "    -40.82714953723617,\n",
       "    -35.57419946966036,\n",
       "    -61.249863336629915,\n",
       "    -66.05188130709512,\n",
       "    -65.43389608496088,\n",
       "    -67.92621691307652,\n",
       "    -68.44118440007676,\n",
       "    -60.82521157023855,\n",
       "    -80.5706655978052,\n",
       "    -108.35589974322085,\n",
       "    -71.79276954645,\n",
       "    -77.0367945948122,\n",
       "    -70.40406942382113,\n",
       "    -64.7458730411956,\n",
       "    -85.78466075099247,\n",
       "    -62.95600260183133,\n",
       "    -65.24278628633773,\n",
       "    -115.75136708347257,\n",
       "    -69.63851691135038,\n",
       "    -67.25593900981487,\n",
       "    -70.75627539629865,\n",
       "    -69.28896810345432,\n",
       "    -53.758871836383115,\n",
       "    -65.61251891869999,\n",
       "    -61.867298510821136,\n",
       "    -36.80115849134961,\n",
       "    -69.97062187818197,\n",
       "    -62.313540129562526,\n",
       "    -75.47174345311674,\n",
       "    -76.97135070592464,\n",
       "    -63.22471292124002,\n",
       "    -62.59318319351331,\n",
       "    -61.74580797643405,\n",
       "    -70.26364856352838,\n",
       "    -58.354122004198466,\n",
       "    -67.79801205310606,\n",
       "    -70.2679961430935,\n",
       "    -65.04617311662223,\n",
       "    -80.98699304924817,\n",
       "    -71.14442652837845,\n",
       "    -61.06628387378711,\n",
       "    -71.91711119829286,\n",
       "    -66.66182160728786,\n",
       "    -55.159950379141236,\n",
       "    -79.04543938027513,\n",
       "    -69.02792442432862,\n",
       "    -63.27644878883916,\n",
       "    -81.35776146791085,\n",
       "    -57.868988708338584,\n",
       "    -69.66841231046354,\n",
       "    -48.96550582198179,\n",
       "    -66.38045080640235,\n",
       "    -67.13603731999036,\n",
       "    -73.00286989429215,\n",
       "    -69.595305040884,\n",
       "    -69.2434960817763,\n",
       "    -51.78848616074407,\n",
       "    -59.05858788488524,\n",
       "    -51.51637187581709,\n",
       "    -110.94077079803134,\n",
       "    -56.775784043472036,\n",
       "    -63.35141726506677,\n",
       "    -62.968471838170345,\n",
       "    -65.60276240023859,\n",
       "    -67.97434127824522,\n",
       "    -53.58327196756974,\n",
       "    -60.31493794010647,\n",
       "    -66.83381297561193,\n",
       "    -72.79668094745652,\n",
       "    -66.34387575619114,\n",
       "    -62.55405820676121,\n",
       "    -56.68398998524689,\n",
       "    -63.41453208839491,\n",
       "    -59.24135232439338,\n",
       "    -71.27022802574756,\n",
       "    -65.98170009792311,\n",
       "    -67.6755355607271,\n",
       "    -50.58861012387705,\n",
       "    -62.784199032264354,\n",
       "    -81.40558543854533,\n",
       "    -67.37423798910457,\n",
       "    -66.83244512723698,\n",
       "    -87.57704309591246,\n",
       "    -100.27627885360825,\n",
       "    -65.88973484836892,\n",
       "    -58.77502109780637,\n",
       "    -66.19476641944333,\n",
       "    -80.28137768881363,\n",
       "    -94.67145133717747,\n",
       "    -72.1867406352445,\n",
       "    -68.70357560005584,\n",
       "    -78.20083449252459,\n",
       "    -83.52411288388686],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22089404525904535,\n",
       "   'mean_inference_ms': 0.5743247832684609,\n",
       "   'mean_action_processing_ms': 0.07611836483651761,\n",
       "   'mean_env_wait_ms': 1.1386768739347632,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 103500,\n",
       "  'agent_timesteps_total': 103500,\n",
       "  'timers': {'learn_time_ms': 1.299, 'learn_throughput': 76961.119},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.069278,\n",
       "     'max_q': -5.8425994,\n",
       "     'min_q': -21.596285,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 103500,\n",
       "   'num_agent_steps_sampled': 103500,\n",
       "   'num_steps_trained': 10200100,\n",
       "   'num_agent_steps_trained': 10200100,\n",
       "   'last_target_update_ts': 103500,\n",
       "   'num_target_updates': 102001},\n",
       "  'done': False,\n",
       "  'episodes_total': 1024,\n",
       "  'training_iteration': 69,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-13-42',\n",
       "  'timestamp': 1625501622,\n",
       "  'time_this_iter_s': 20.880375862121582,\n",
       "  'time_total_s': 1364.5559284687042,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1364.5559284687042,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 69,\n",
       "  'perf': {'cpu_util_percent': 12.837037037037035,\n",
       "   'ram_util_percent': 46.900000000000006,\n",
       "   'gpu_util_percent0': 0.12999999999999998,\n",
       "   'vram_util_percent0': 0.5561995132437475}},\n",
       " {'episode_reward_max': -36.80115849134961,\n",
       "  'episode_reward_min': -115.75136708347257,\n",
       "  'episode_reward_mean': -68.67444575818342,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-80.5706655978052,\n",
       "    -108.35589974322085,\n",
       "    -71.79276954645,\n",
       "    -77.0367945948122,\n",
       "    -70.40406942382113,\n",
       "    -64.7458730411956,\n",
       "    -85.78466075099247,\n",
       "    -62.95600260183133,\n",
       "    -65.24278628633773,\n",
       "    -115.75136708347257,\n",
       "    -69.63851691135038,\n",
       "    -67.25593900981487,\n",
       "    -70.75627539629865,\n",
       "    -69.28896810345432,\n",
       "    -53.758871836383115,\n",
       "    -65.61251891869999,\n",
       "    -61.867298510821136,\n",
       "    -36.80115849134961,\n",
       "    -69.97062187818197,\n",
       "    -62.313540129562526,\n",
       "    -75.47174345311674,\n",
       "    -76.97135070592464,\n",
       "    -63.22471292124002,\n",
       "    -62.59318319351331,\n",
       "    -61.74580797643405,\n",
       "    -70.26364856352838,\n",
       "    -58.354122004198466,\n",
       "    -67.79801205310606,\n",
       "    -70.2679961430935,\n",
       "    -65.04617311662223,\n",
       "    -80.98699304924817,\n",
       "    -71.14442652837845,\n",
       "    -61.06628387378711,\n",
       "    -71.91711119829286,\n",
       "    -66.66182160728786,\n",
       "    -55.159950379141236,\n",
       "    -79.04543938027513,\n",
       "    -69.02792442432862,\n",
       "    -63.27644878883916,\n",
       "    -81.35776146791085,\n",
       "    -57.868988708338584,\n",
       "    -69.66841231046354,\n",
       "    -48.96550582198179,\n",
       "    -66.38045080640235,\n",
       "    -67.13603731999036,\n",
       "    -73.00286989429215,\n",
       "    -69.595305040884,\n",
       "    -69.2434960817763,\n",
       "    -51.78848616074407,\n",
       "    -59.05858788488524,\n",
       "    -51.51637187581709,\n",
       "    -110.94077079803134,\n",
       "    -56.775784043472036,\n",
       "    -63.35141726506677,\n",
       "    -62.968471838170345,\n",
       "    -65.60276240023859,\n",
       "    -67.97434127824522,\n",
       "    -53.58327196756974,\n",
       "    -60.31493794010647,\n",
       "    -66.83381297561193,\n",
       "    -72.79668094745652,\n",
       "    -66.34387575619114,\n",
       "    -62.55405820676121,\n",
       "    -56.68398998524689,\n",
       "    -63.41453208839491,\n",
       "    -59.24135232439338,\n",
       "    -71.27022802574756,\n",
       "    -65.98170009792311,\n",
       "    -67.6755355607271,\n",
       "    -50.58861012387705,\n",
       "    -62.784199032264354,\n",
       "    -81.40558543854533,\n",
       "    -67.37423798910457,\n",
       "    -66.83244512723698,\n",
       "    -87.57704309591246,\n",
       "    -100.27627885360825,\n",
       "    -65.88973484836892,\n",
       "    -58.77502109780637,\n",
       "    -66.19476641944333,\n",
       "    -80.28137768881363,\n",
       "    -94.67145133717747,\n",
       "    -72.1867406352445,\n",
       "    -68.70357560005584,\n",
       "    -78.20083449252459,\n",
       "    -83.52411288388686,\n",
       "    -58.817736446893015,\n",
       "    -66.65441954388689,\n",
       "    -69.57172299846563,\n",
       "    -48.48323290867855,\n",
       "    -58.83402978164545,\n",
       "    -76.68764832195022,\n",
       "    -67.72705113032497,\n",
       "    -48.49750299180549,\n",
       "    -74.62008324626308,\n",
       "    -58.98082865650065,\n",
       "    -79.564266493328,\n",
       "    -69.57772854692176,\n",
       "    -99.67556954381037,\n",
       "    -64.39485901831182,\n",
       "    -60.274337436635015],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2209566935825559,\n",
       "   'mean_inference_ms': 0.5746655055404963,\n",
       "   'mean_action_processing_ms': 0.07615415434184487,\n",
       "   'mean_env_wait_ms': 1.1384439978463556,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 105000,\n",
       "  'agent_timesteps_total': 105000,\n",
       "  'timers': {'learn_time_ms': 1.541, 'learn_throughput': 64904.198},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.270659,\n",
       "     'max_q': -5.514013,\n",
       "     'min_q': -23.497234,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 105000,\n",
       "   'num_agent_steps_sampled': 105000,\n",
       "   'num_steps_trained': 10350100,\n",
       "   'num_agent_steps_trained': 10350100,\n",
       "   'last_target_update_ts': 105000,\n",
       "   'num_target_updates': 103501},\n",
       "  'done': False,\n",
       "  'episodes_total': 1039,\n",
       "  'training_iteration': 70,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-14-02',\n",
       "  'timestamp': 1625501642,\n",
       "  'time_this_iter_s': 20.218623876571655,\n",
       "  'time_total_s': 1384.7745523452759,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1384.7745523452759,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 70,\n",
       "  'perf': {'cpu_util_percent': 12.346153846153847,\n",
       "   'ram_util_percent': 46.93076923076923,\n",
       "   'gpu_util_percent0': 0.11961538461538461,\n",
       "   'vram_util_percent0': 0.5557992250653974}},\n",
       " {'episode_reward_max': -36.80115849134961,\n",
       "  'episode_reward_min': -115.49399314044751,\n",
       "  'episode_reward_mean': -68.02177719465114,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-65.61251891869999,\n",
       "    -61.867298510821136,\n",
       "    -36.80115849134961,\n",
       "    -69.97062187818197,\n",
       "    -62.313540129562526,\n",
       "    -75.47174345311674,\n",
       "    -76.97135070592464,\n",
       "    -63.22471292124002,\n",
       "    -62.59318319351331,\n",
       "    -61.74580797643405,\n",
       "    -70.26364856352838,\n",
       "    -58.354122004198466,\n",
       "    -67.79801205310606,\n",
       "    -70.2679961430935,\n",
       "    -65.04617311662223,\n",
       "    -80.98699304924817,\n",
       "    -71.14442652837845,\n",
       "    -61.06628387378711,\n",
       "    -71.91711119829286,\n",
       "    -66.66182160728786,\n",
       "    -55.159950379141236,\n",
       "    -79.04543938027513,\n",
       "    -69.02792442432862,\n",
       "    -63.27644878883916,\n",
       "    -81.35776146791085,\n",
       "    -57.868988708338584,\n",
       "    -69.66841231046354,\n",
       "    -48.96550582198179,\n",
       "    -66.38045080640235,\n",
       "    -67.13603731999036,\n",
       "    -73.00286989429215,\n",
       "    -69.595305040884,\n",
       "    -69.2434960817763,\n",
       "    -51.78848616074407,\n",
       "    -59.05858788488524,\n",
       "    -51.51637187581709,\n",
       "    -110.94077079803134,\n",
       "    -56.775784043472036,\n",
       "    -63.35141726506677,\n",
       "    -62.968471838170345,\n",
       "    -65.60276240023859,\n",
       "    -67.97434127824522,\n",
       "    -53.58327196756974,\n",
       "    -60.31493794010647,\n",
       "    -66.83381297561193,\n",
       "    -72.79668094745652,\n",
       "    -66.34387575619114,\n",
       "    -62.55405820676121,\n",
       "    -56.68398998524689,\n",
       "    -63.41453208839491,\n",
       "    -59.24135232439338,\n",
       "    -71.27022802574756,\n",
       "    -65.98170009792311,\n",
       "    -67.6755355607271,\n",
       "    -50.58861012387705,\n",
       "    -62.784199032264354,\n",
       "    -81.40558543854533,\n",
       "    -67.37423798910457,\n",
       "    -66.83244512723698,\n",
       "    -87.57704309591246,\n",
       "    -100.27627885360825,\n",
       "    -65.88973484836892,\n",
       "    -58.77502109780637,\n",
       "    -66.19476641944333,\n",
       "    -80.28137768881363,\n",
       "    -94.67145133717747,\n",
       "    -72.1867406352445,\n",
       "    -68.70357560005584,\n",
       "    -78.20083449252459,\n",
       "    -83.52411288388686,\n",
       "    -58.817736446893015,\n",
       "    -66.65441954388689,\n",
       "    -69.57172299846563,\n",
       "    -48.48323290867855,\n",
       "    -58.83402978164545,\n",
       "    -76.68764832195022,\n",
       "    -67.72705113032497,\n",
       "    -48.49750299180549,\n",
       "    -74.62008324626308,\n",
       "    -58.98082865650065,\n",
       "    -79.564266493328,\n",
       "    -69.57772854692176,\n",
       "    -99.67556954381037,\n",
       "    -64.39485901831182,\n",
       "    -60.274337436635015,\n",
       "    -78.56598660184194,\n",
       "    -42.466087703370235,\n",
       "    -115.49399314044751,\n",
       "    -99.15422138525176,\n",
       "    -65.1998060683744,\n",
       "    -75.64719572945445,\n",
       "    -63.504001969943715,\n",
       "    -66.45255991906564,\n",
       "    -62.61559610242008,\n",
       "    -100.16427179250041,\n",
       "    -39.46167826740754,\n",
       "    -58.966728375650156,\n",
       "    -65.53362114060032,\n",
       "    -65.73089404508168,\n",
       "    -69.11596133260126],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22100909461095214,\n",
       "   'mean_inference_ms': 0.5749784469648003,\n",
       "   'mean_action_processing_ms': 0.07618177318497438,\n",
       "   'mean_env_wait_ms': 1.1381649637856825,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 106500,\n",
       "  'agent_timesteps_total': 106500,\n",
       "  'timers': {'learn_time_ms': 1.487, 'learn_throughput': 67232.572},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.485691,\n",
       "     'max_q': -6.614374,\n",
       "     'min_q': -21.894999,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 106500,\n",
       "   'num_agent_steps_sampled': 106500,\n",
       "   'num_steps_trained': 10500100,\n",
       "   'num_agent_steps_trained': 10500100,\n",
       "   'last_target_update_ts': 106500,\n",
       "   'num_target_updates': 105001},\n",
       "  'done': False,\n",
       "  'episodes_total': 1054,\n",
       "  'training_iteration': 71,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-14-22',\n",
       "  'timestamp': 1625501662,\n",
       "  'time_this_iter_s': 20.402750253677368,\n",
       "  'time_total_s': 1405.1773025989532,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1405.1773025989532,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 71,\n",
       "  'perf': {'cpu_util_percent': 12.58148148148148,\n",
       "   'ram_util_percent': 47.0,\n",
       "   'gpu_util_percent0': 0.12111111111111113,\n",
       "   'vram_util_percent0': 0.5554229760315161}},\n",
       " {'episode_reward_max': -39.46167826740754,\n",
       "  'episode_reward_min': -115.49399314044751,\n",
       "  'episode_reward_mean': -68.79005845925289,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-80.98699304924817,\n",
       "    -71.14442652837845,\n",
       "    -61.06628387378711,\n",
       "    -71.91711119829286,\n",
       "    -66.66182160728786,\n",
       "    -55.159950379141236,\n",
       "    -79.04543938027513,\n",
       "    -69.02792442432862,\n",
       "    -63.27644878883916,\n",
       "    -81.35776146791085,\n",
       "    -57.868988708338584,\n",
       "    -69.66841231046354,\n",
       "    -48.96550582198179,\n",
       "    -66.38045080640235,\n",
       "    -67.13603731999036,\n",
       "    -73.00286989429215,\n",
       "    -69.595305040884,\n",
       "    -69.2434960817763,\n",
       "    -51.78848616074407,\n",
       "    -59.05858788488524,\n",
       "    -51.51637187581709,\n",
       "    -110.94077079803134,\n",
       "    -56.775784043472036,\n",
       "    -63.35141726506677,\n",
       "    -62.968471838170345,\n",
       "    -65.60276240023859,\n",
       "    -67.97434127824522,\n",
       "    -53.58327196756974,\n",
       "    -60.31493794010647,\n",
       "    -66.83381297561193,\n",
       "    -72.79668094745652,\n",
       "    -66.34387575619114,\n",
       "    -62.55405820676121,\n",
       "    -56.68398998524689,\n",
       "    -63.41453208839491,\n",
       "    -59.24135232439338,\n",
       "    -71.27022802574756,\n",
       "    -65.98170009792311,\n",
       "    -67.6755355607271,\n",
       "    -50.58861012387705,\n",
       "    -62.784199032264354,\n",
       "    -81.40558543854533,\n",
       "    -67.37423798910457,\n",
       "    -66.83244512723698,\n",
       "    -87.57704309591246,\n",
       "    -100.27627885360825,\n",
       "    -65.88973484836892,\n",
       "    -58.77502109780637,\n",
       "    -66.19476641944333,\n",
       "    -80.28137768881363,\n",
       "    -94.67145133717747,\n",
       "    -72.1867406352445,\n",
       "    -68.70357560005584,\n",
       "    -78.20083449252459,\n",
       "    -83.52411288388686,\n",
       "    -58.817736446893015,\n",
       "    -66.65441954388689,\n",
       "    -69.57172299846563,\n",
       "    -48.48323290867855,\n",
       "    -58.83402978164545,\n",
       "    -76.68764832195022,\n",
       "    -67.72705113032497,\n",
       "    -48.49750299180549,\n",
       "    -74.62008324626308,\n",
       "    -58.98082865650065,\n",
       "    -79.564266493328,\n",
       "    -69.57772854692176,\n",
       "    -99.67556954381037,\n",
       "    -64.39485901831182,\n",
       "    -60.274337436635015,\n",
       "    -78.56598660184194,\n",
       "    -42.466087703370235,\n",
       "    -115.49399314044751,\n",
       "    -99.15422138525176,\n",
       "    -65.1998060683744,\n",
       "    -75.64719572945445,\n",
       "    -63.504001969943715,\n",
       "    -66.45255991906564,\n",
       "    -62.61559610242008,\n",
       "    -100.16427179250041,\n",
       "    -39.46167826740754,\n",
       "    -58.966728375650156,\n",
       "    -65.53362114060032,\n",
       "    -65.73089404508168,\n",
       "    -69.11596133260126,\n",
       "    -45.0532370890922,\n",
       "    -65.71778090738975,\n",
       "    -95.631036574221,\n",
       "    -64.20223931265764,\n",
       "    -69.16730075901994,\n",
       "    -58.282191233859855,\n",
       "    -68.67939547038289,\n",
       "    -60.89587298724253,\n",
       "    -84.40742356530168,\n",
       "    -72.69733718128198,\n",
       "    -68.6181077045653,\n",
       "    -67.6852901915581,\n",
       "    -66.81782298629858,\n",
       "    -75.71346284774445,\n",
       "    -81.56151570895031],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22103075389957647,\n",
       "   'mean_inference_ms': 0.5751391389288762,\n",
       "   'mean_action_processing_ms': 0.0761923642925651,\n",
       "   'mean_env_wait_ms': 1.1378249537949894,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 108000,\n",
       "  'agent_timesteps_total': 108000,\n",
       "  'timers': {'learn_time_ms': 1.467, 'learn_throughput': 68150.199},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.293378,\n",
       "     'max_q': -3.8612282,\n",
       "     'min_q': -22.895945,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 108000,\n",
       "   'num_agent_steps_sampled': 108000,\n",
       "   'num_steps_trained': 10650100,\n",
       "   'num_agent_steps_trained': 10650100,\n",
       "   'last_target_update_ts': 108000,\n",
       "   'num_target_updates': 106501},\n",
       "  'done': False,\n",
       "  'episodes_total': 1069,\n",
       "  'training_iteration': 72,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-14-43',\n",
       "  'timestamp': 1625501683,\n",
       "  'time_this_iter_s': 20.194068431854248,\n",
       "  'time_total_s': 1425.3713710308075,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1425.3713710308075,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 72,\n",
       "  'perf': {'cpu_util_percent': 12.592307692307692,\n",
       "   'ram_util_percent': 47.153846153846146,\n",
       "   'gpu_util_percent0': 0.10576923076923077,\n",
       "   'vram_util_percent0': 0.5444505634994001}},\n",
       " {'episode_reward_max': -39.46167826740754,\n",
       "  'episode_reward_min': -115.49399314044751,\n",
       "  'episode_reward_mean': -68.72588283895358,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-73.00286989429215,\n",
       "    -69.595305040884,\n",
       "    -69.2434960817763,\n",
       "    -51.78848616074407,\n",
       "    -59.05858788488524,\n",
       "    -51.51637187581709,\n",
       "    -110.94077079803134,\n",
       "    -56.775784043472036,\n",
       "    -63.35141726506677,\n",
       "    -62.968471838170345,\n",
       "    -65.60276240023859,\n",
       "    -67.97434127824522,\n",
       "    -53.58327196756974,\n",
       "    -60.31493794010647,\n",
       "    -66.83381297561193,\n",
       "    -72.79668094745652,\n",
       "    -66.34387575619114,\n",
       "    -62.55405820676121,\n",
       "    -56.68398998524689,\n",
       "    -63.41453208839491,\n",
       "    -59.24135232439338,\n",
       "    -71.27022802574756,\n",
       "    -65.98170009792311,\n",
       "    -67.6755355607271,\n",
       "    -50.58861012387705,\n",
       "    -62.784199032264354,\n",
       "    -81.40558543854533,\n",
       "    -67.37423798910457,\n",
       "    -66.83244512723698,\n",
       "    -87.57704309591246,\n",
       "    -100.27627885360825,\n",
       "    -65.88973484836892,\n",
       "    -58.77502109780637,\n",
       "    -66.19476641944333,\n",
       "    -80.28137768881363,\n",
       "    -94.67145133717747,\n",
       "    -72.1867406352445,\n",
       "    -68.70357560005584,\n",
       "    -78.20083449252459,\n",
       "    -83.52411288388686,\n",
       "    -58.817736446893015,\n",
       "    -66.65441954388689,\n",
       "    -69.57172299846563,\n",
       "    -48.48323290867855,\n",
       "    -58.83402978164545,\n",
       "    -76.68764832195022,\n",
       "    -67.72705113032497,\n",
       "    -48.49750299180549,\n",
       "    -74.62008324626308,\n",
       "    -58.98082865650065,\n",
       "    -79.564266493328,\n",
       "    -69.57772854692176,\n",
       "    -99.67556954381037,\n",
       "    -64.39485901831182,\n",
       "    -60.274337436635015,\n",
       "    -78.56598660184194,\n",
       "    -42.466087703370235,\n",
       "    -115.49399314044751,\n",
       "    -99.15422138525176,\n",
       "    -65.1998060683744,\n",
       "    -75.64719572945445,\n",
       "    -63.504001969943715,\n",
       "    -66.45255991906564,\n",
       "    -62.61559610242008,\n",
       "    -100.16427179250041,\n",
       "    -39.46167826740754,\n",
       "    -58.966728375650156,\n",
       "    -65.53362114060032,\n",
       "    -65.73089404508168,\n",
       "    -69.11596133260126,\n",
       "    -45.0532370890922,\n",
       "    -65.71778090738975,\n",
       "    -95.631036574221,\n",
       "    -64.20223931265764,\n",
       "    -69.16730075901994,\n",
       "    -58.282191233859855,\n",
       "    -68.67939547038289,\n",
       "    -60.89587298724253,\n",
       "    -84.40742356530168,\n",
       "    -72.69733718128198,\n",
       "    -68.6181077045653,\n",
       "    -67.6852901915581,\n",
       "    -66.81782298629858,\n",
       "    -75.71346284774445,\n",
       "    -81.56151570895031,\n",
       "    -71.83489948178813,\n",
       "    -69.31228413163798,\n",
       "    -82.28840864949741,\n",
       "    -40.03923328968734,\n",
       "    -92.58865257580194,\n",
       "    -75.09214163992002,\n",
       "    -65.33452200895668,\n",
       "    -69.59711433185419,\n",
       "    -60.90493524626281,\n",
       "    -43.250211921806056,\n",
       "    -66.29616066616995,\n",
       "    -71.90041222530846,\n",
       "    -68.30843493605241,\n",
       "    -59.25186364585386,\n",
       "    -67.24671888413926],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2210142242377807,\n",
       "   'mean_inference_ms': 0.5753958968865055,\n",
       "   'mean_action_processing_ms': 0.07619266823255945,\n",
       "   'mean_env_wait_ms': 1.1373852965808913,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 109500,\n",
       "  'agent_timesteps_total': 109500,\n",
       "  'timers': {'learn_time_ms': 1.463, 'learn_throughput': 68372.386},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.528774,\n",
       "     'max_q': -4.2724776,\n",
       "     'min_q': -22.449018,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 109500,\n",
       "   'num_agent_steps_sampled': 109500,\n",
       "   'num_steps_trained': 10800100,\n",
       "   'num_agent_steps_trained': 10800100,\n",
       "   'last_target_update_ts': 109500,\n",
       "   'num_target_updates': 108001},\n",
       "  'done': False,\n",
       "  'episodes_total': 1084,\n",
       "  'training_iteration': 73,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-15-03',\n",
       "  'timestamp': 1625501703,\n",
       "  'time_this_iter_s': 20.694085121154785,\n",
       "  'time_total_s': 1446.0654561519623,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1446.0654561519623,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 73,\n",
       "  'perf': {'cpu_util_percent': 12.570370370370371,\n",
       "   'ram_util_percent': 47.32592592592592,\n",
       "   'gpu_util_percent0': 0.11185185185185186,\n",
       "   'vram_util_percent0': 0.5339640330691212}},\n",
       " {'episode_reward_max': -36.60685447487495,\n",
       "  'episode_reward_min': -115.49399314044751,\n",
       "  'episode_reward_mean': -68.4519968260521,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-72.79668094745652,\n",
       "    -66.34387575619114,\n",
       "    -62.55405820676121,\n",
       "    -56.68398998524689,\n",
       "    -63.41453208839491,\n",
       "    -59.24135232439338,\n",
       "    -71.27022802574756,\n",
       "    -65.98170009792311,\n",
       "    -67.6755355607271,\n",
       "    -50.58861012387705,\n",
       "    -62.784199032264354,\n",
       "    -81.40558543854533,\n",
       "    -67.37423798910457,\n",
       "    -66.83244512723698,\n",
       "    -87.57704309591246,\n",
       "    -100.27627885360825,\n",
       "    -65.88973484836892,\n",
       "    -58.77502109780637,\n",
       "    -66.19476641944333,\n",
       "    -80.28137768881363,\n",
       "    -94.67145133717747,\n",
       "    -72.1867406352445,\n",
       "    -68.70357560005584,\n",
       "    -78.20083449252459,\n",
       "    -83.52411288388686,\n",
       "    -58.817736446893015,\n",
       "    -66.65441954388689,\n",
       "    -69.57172299846563,\n",
       "    -48.48323290867855,\n",
       "    -58.83402978164545,\n",
       "    -76.68764832195022,\n",
       "    -67.72705113032497,\n",
       "    -48.49750299180549,\n",
       "    -74.62008324626308,\n",
       "    -58.98082865650065,\n",
       "    -79.564266493328,\n",
       "    -69.57772854692176,\n",
       "    -99.67556954381037,\n",
       "    -64.39485901831182,\n",
       "    -60.274337436635015,\n",
       "    -78.56598660184194,\n",
       "    -42.466087703370235,\n",
       "    -115.49399314044751,\n",
       "    -99.15422138525176,\n",
       "    -65.1998060683744,\n",
       "    -75.64719572945445,\n",
       "    -63.504001969943715,\n",
       "    -66.45255991906564,\n",
       "    -62.61559610242008,\n",
       "    -100.16427179250041,\n",
       "    -39.46167826740754,\n",
       "    -58.966728375650156,\n",
       "    -65.53362114060032,\n",
       "    -65.73089404508168,\n",
       "    -69.11596133260126,\n",
       "    -45.0532370890922,\n",
       "    -65.71778090738975,\n",
       "    -95.631036574221,\n",
       "    -64.20223931265764,\n",
       "    -69.16730075901994,\n",
       "    -58.282191233859855,\n",
       "    -68.67939547038289,\n",
       "    -60.89587298724253,\n",
       "    -84.40742356530168,\n",
       "    -72.69733718128198,\n",
       "    -68.6181077045653,\n",
       "    -67.6852901915581,\n",
       "    -66.81782298629858,\n",
       "    -75.71346284774445,\n",
       "    -81.56151570895031,\n",
       "    -71.83489948178813,\n",
       "    -69.31228413163798,\n",
       "    -82.28840864949741,\n",
       "    -40.03923328968734,\n",
       "    -92.58865257580194,\n",
       "    -75.09214163992002,\n",
       "    -65.33452200895668,\n",
       "    -69.59711433185419,\n",
       "    -60.90493524626281,\n",
       "    -43.250211921806056,\n",
       "    -66.29616066616995,\n",
       "    -71.90041222530846,\n",
       "    -68.30843493605241,\n",
       "    -59.25186364585386,\n",
       "    -67.24671888413926,\n",
       "    -62.118387835753765,\n",
       "    -63.5696202948074,\n",
       "    -68.386581731438,\n",
       "    -66.35109870728,\n",
       "    -36.60685447487495,\n",
       "    -71.81025744527126,\n",
       "    -44.657284655080474,\n",
       "    -57.23216042220859,\n",
       "    -72.59903521083703,\n",
       "    -65.27349806564806,\n",
       "    -57.64517412656196,\n",
       "    -85.706511288547,\n",
       "    -69.14043816900711,\n",
       "    -65.2157017261321,\n",
       "    -68.84948200131441],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22098633888553693,\n",
       "   'mean_inference_ms': 0.5756601751607742,\n",
       "   'mean_action_processing_ms': 0.07618552184114097,\n",
       "   'mean_env_wait_ms': 1.137081319458266,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 111000,\n",
       "  'agent_timesteps_total': 111000,\n",
       "  'timers': {'learn_time_ms': 1.357, 'learn_throughput': 73696.765},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.971326,\n",
       "     'max_q': -3.8236356,\n",
       "     'min_q': -21.376518,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 111000,\n",
       "   'num_agent_steps_sampled': 111000,\n",
       "   'num_steps_trained': 10950100,\n",
       "   'num_agent_steps_trained': 10950100,\n",
       "   'last_target_update_ts': 111000,\n",
       "   'num_target_updates': 109501},\n",
       "  'done': False,\n",
       "  'episodes_total': 1099,\n",
       "  'training_iteration': 74,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-15-24',\n",
       "  'timestamp': 1625501724,\n",
       "  'time_this_iter_s': 20.402526378631592,\n",
       "  'time_total_s': 1466.4679825305939,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1466.4679825305939,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 74,\n",
       "  'perf': {'cpu_util_percent': 12.676923076923076,\n",
       "   'ram_util_percent': 47.400000000000006,\n",
       "   'gpu_util_percent0': 0.12538461538461537,\n",
       "   'vram_util_percent0': 0.5337411246385934}},\n",
       " {'episode_reward_max': -36.05246982909452,\n",
       "  'episode_reward_min': -115.49399314044751,\n",
       "  'episode_reward_mean': -67.94878640398272,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 14,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-87.57704309591246,\n",
       "    -100.27627885360825,\n",
       "    -65.88973484836892,\n",
       "    -58.77502109780637,\n",
       "    -66.19476641944333,\n",
       "    -80.28137768881363,\n",
       "    -94.67145133717747,\n",
       "    -72.1867406352445,\n",
       "    -68.70357560005584,\n",
       "    -78.20083449252459,\n",
       "    -83.52411288388686,\n",
       "    -58.817736446893015,\n",
       "    -66.65441954388689,\n",
       "    -69.57172299846563,\n",
       "    -48.48323290867855,\n",
       "    -58.83402978164545,\n",
       "    -76.68764832195022,\n",
       "    -67.72705113032497,\n",
       "    -48.49750299180549,\n",
       "    -74.62008324626308,\n",
       "    -58.98082865650065,\n",
       "    -79.564266493328,\n",
       "    -69.57772854692176,\n",
       "    -99.67556954381037,\n",
       "    -64.39485901831182,\n",
       "    -60.274337436635015,\n",
       "    -78.56598660184194,\n",
       "    -42.466087703370235,\n",
       "    -115.49399314044751,\n",
       "    -99.15422138525176,\n",
       "    -65.1998060683744,\n",
       "    -75.64719572945445,\n",
       "    -63.504001969943715,\n",
       "    -66.45255991906564,\n",
       "    -62.61559610242008,\n",
       "    -100.16427179250041,\n",
       "    -39.46167826740754,\n",
       "    -58.966728375650156,\n",
       "    -65.53362114060032,\n",
       "    -65.73089404508168,\n",
       "    -69.11596133260126,\n",
       "    -45.0532370890922,\n",
       "    -65.71778090738975,\n",
       "    -95.631036574221,\n",
       "    -64.20223931265764,\n",
       "    -69.16730075901994,\n",
       "    -58.282191233859855,\n",
       "    -68.67939547038289,\n",
       "    -60.89587298724253,\n",
       "    -84.40742356530168,\n",
       "    -72.69733718128198,\n",
       "    -68.6181077045653,\n",
       "    -67.6852901915581,\n",
       "    -66.81782298629858,\n",
       "    -75.71346284774445,\n",
       "    -81.56151570895031,\n",
       "    -71.83489948178813,\n",
       "    -69.31228413163798,\n",
       "    -82.28840864949741,\n",
       "    -40.03923328968734,\n",
       "    -92.58865257580194,\n",
       "    -75.09214163992002,\n",
       "    -65.33452200895668,\n",
       "    -69.59711433185419,\n",
       "    -60.90493524626281,\n",
       "    -43.250211921806056,\n",
       "    -66.29616066616995,\n",
       "    -71.90041222530846,\n",
       "    -68.30843493605241,\n",
       "    -59.25186364585386,\n",
       "    -67.24671888413926,\n",
       "    -62.118387835753765,\n",
       "    -63.5696202948074,\n",
       "    -68.386581731438,\n",
       "    -66.35109870728,\n",
       "    -36.60685447487495,\n",
       "    -71.81025744527126,\n",
       "    -44.657284655080474,\n",
       "    -57.23216042220859,\n",
       "    -72.59903521083703,\n",
       "    -65.27349806564806,\n",
       "    -57.64517412656196,\n",
       "    -85.706511288547,\n",
       "    -69.14043816900711,\n",
       "    -65.2157017261321,\n",
       "    -68.84948200131441,\n",
       "    -59.58407168780977,\n",
       "    -64.81409784176688,\n",
       "    -67.78841268776729,\n",
       "    -61.63646051787137,\n",
       "    -67.42038579395863,\n",
       "    -63.55228675260339,\n",
       "    -36.05246982909452,\n",
       "    -65.43353507519019,\n",
       "    -71.84705903296883,\n",
       "    -68.9124214448644,\n",
       "    -67.65742984193881,\n",
       "    -52.405215445496786,\n",
       "    -47.10371113736312,\n",
       "    -70.41843140823815],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22095275094042185,\n",
       "   'mean_inference_ms': 0.5758620880255378,\n",
       "   'mean_action_processing_ms': 0.07617121841063383,\n",
       "   'mean_env_wait_ms': 1.1369081917984591,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 112500,\n",
       "  'agent_timesteps_total': 112500,\n",
       "  'timers': {'learn_time_ms': 1.41, 'learn_throughput': 70918.012},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.160618,\n",
       "     'max_q': -4.607988,\n",
       "     'min_q': -22.089699,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 112500,\n",
       "   'num_agent_steps_sampled': 112500,\n",
       "   'num_steps_trained': 11100100,\n",
       "   'num_agent_steps_trained': 11100100,\n",
       "   'last_target_update_ts': 112500,\n",
       "   'num_target_updates': 111001},\n",
       "  'done': False,\n",
       "  'episodes_total': 1113,\n",
       "  'training_iteration': 75,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-15-44',\n",
       "  'timestamp': 1625501744,\n",
       "  'time_this_iter_s': 20.451740741729736,\n",
       "  'time_total_s': 1486.9197232723236,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1486.9197232723236,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 75,\n",
       "  'perf': {'cpu_util_percent': 12.503703703703705,\n",
       "   'ram_util_percent': 47.400000000000006,\n",
       "   'gpu_util_percent0': 0.08666666666666666,\n",
       "   'vram_util_percent0': 0.5332253757209011}},\n",
       " {'episode_reward_max': -36.05246982909452,\n",
       "  'episode_reward_min': -115.49399314044751,\n",
       "  'episode_reward_mean': -66.68231937592068,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-58.83402978164545,\n",
       "    -76.68764832195022,\n",
       "    -67.72705113032497,\n",
       "    -48.49750299180549,\n",
       "    -74.62008324626308,\n",
       "    -58.98082865650065,\n",
       "    -79.564266493328,\n",
       "    -69.57772854692176,\n",
       "    -99.67556954381037,\n",
       "    -64.39485901831182,\n",
       "    -60.274337436635015,\n",
       "    -78.56598660184194,\n",
       "    -42.466087703370235,\n",
       "    -115.49399314044751,\n",
       "    -99.15422138525176,\n",
       "    -65.1998060683744,\n",
       "    -75.64719572945445,\n",
       "    -63.504001969943715,\n",
       "    -66.45255991906564,\n",
       "    -62.61559610242008,\n",
       "    -100.16427179250041,\n",
       "    -39.46167826740754,\n",
       "    -58.966728375650156,\n",
       "    -65.53362114060032,\n",
       "    -65.73089404508168,\n",
       "    -69.11596133260126,\n",
       "    -45.0532370890922,\n",
       "    -65.71778090738975,\n",
       "    -95.631036574221,\n",
       "    -64.20223931265764,\n",
       "    -69.16730075901994,\n",
       "    -58.282191233859855,\n",
       "    -68.67939547038289,\n",
       "    -60.89587298724253,\n",
       "    -84.40742356530168,\n",
       "    -72.69733718128198,\n",
       "    -68.6181077045653,\n",
       "    -67.6852901915581,\n",
       "    -66.81782298629858,\n",
       "    -75.71346284774445,\n",
       "    -81.56151570895031,\n",
       "    -71.83489948178813,\n",
       "    -69.31228413163798,\n",
       "    -82.28840864949741,\n",
       "    -40.03923328968734,\n",
       "    -92.58865257580194,\n",
       "    -75.09214163992002,\n",
       "    -65.33452200895668,\n",
       "    -69.59711433185419,\n",
       "    -60.90493524626281,\n",
       "    -43.250211921806056,\n",
       "    -66.29616066616995,\n",
       "    -71.90041222530846,\n",
       "    -68.30843493605241,\n",
       "    -59.25186364585386,\n",
       "    -67.24671888413926,\n",
       "    -62.118387835753765,\n",
       "    -63.5696202948074,\n",
       "    -68.386581731438,\n",
       "    -66.35109870728,\n",
       "    -36.60685447487495,\n",
       "    -71.81025744527126,\n",
       "    -44.657284655080474,\n",
       "    -57.23216042220859,\n",
       "    -72.59903521083703,\n",
       "    -65.27349806564806,\n",
       "    -57.64517412656196,\n",
       "    -85.706511288547,\n",
       "    -69.14043816900711,\n",
       "    -65.2157017261321,\n",
       "    -68.84948200131441,\n",
       "    -59.58407168780977,\n",
       "    -64.81409784176688,\n",
       "    -67.78841268776729,\n",
       "    -61.63646051787137,\n",
       "    -67.42038579395863,\n",
       "    -63.55228675260339,\n",
       "    -36.05246982909452,\n",
       "    -65.43353507519019,\n",
       "    -71.84705903296883,\n",
       "    -68.9124214448644,\n",
       "    -67.65742984193881,\n",
       "    -52.405215445496786,\n",
       "    -47.10371113736312,\n",
       "    -70.41843140823815,\n",
       "    -65.74766158024141,\n",
       "    -64.03254029911108,\n",
       "    -65.09204308563484,\n",
       "    -66.37958526329501,\n",
       "    -67.26434907469341,\n",
       "    -65.57809579496855,\n",
       "    -73.55271536738572,\n",
       "    -65.83543526029527,\n",
       "    -66.61226579298098,\n",
       "    -68.10607860963158,\n",
       "    -45.866562265858036,\n",
       "    -71.98342071663131,\n",
       "    -60.43333277198608,\n",
       "    -55.97238123839499,\n",
       "    -70.70487892345413],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2209116453010618,\n",
       "   'mean_inference_ms': 0.5761289487466922,\n",
       "   'mean_action_processing_ms': 0.0761518093189558,\n",
       "   'mean_env_wait_ms': 1.1366770385359741,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 114000,\n",
       "  'agent_timesteps_total': 114000,\n",
       "  'timers': {'learn_time_ms': 1.39, 'learn_throughput': 71923.726},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.240927,\n",
       "     'max_q': -4.863687,\n",
       "     'min_q': -22.851969,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 114000,\n",
       "   'num_agent_steps_sampled': 114000,\n",
       "   'num_steps_trained': 11250100,\n",
       "   'num_agent_steps_trained': 11250100,\n",
       "   'last_target_update_ts': 114000,\n",
       "   'num_target_updates': 112501},\n",
       "  'done': False,\n",
       "  'episodes_total': 1128,\n",
       "  'training_iteration': 76,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-16-05',\n",
       "  'timestamp': 1625501765,\n",
       "  'time_this_iter_s': 20.319406270980835,\n",
       "  'time_total_s': 1507.2391295433044,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1507.2391295433044,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 76,\n",
       "  'perf': {'cpu_util_percent': 12.642307692307694,\n",
       "   'ram_util_percent': 47.49615384615385,\n",
       "   'gpu_util_percent0': 0.10653846153846154,\n",
       "   'vram_util_percent0': 0.5334854355565172}},\n",
       " {'episode_reward_max': -36.05246982909452,\n",
       "  'episode_reward_min': -100.16427179250041,\n",
       "  'episode_reward_mean': -66.00416215985636,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-65.1998060683744,\n",
       "    -75.64719572945445,\n",
       "    -63.504001969943715,\n",
       "    -66.45255991906564,\n",
       "    -62.61559610242008,\n",
       "    -100.16427179250041,\n",
       "    -39.46167826740754,\n",
       "    -58.966728375650156,\n",
       "    -65.53362114060032,\n",
       "    -65.73089404508168,\n",
       "    -69.11596133260126,\n",
       "    -45.0532370890922,\n",
       "    -65.71778090738975,\n",
       "    -95.631036574221,\n",
       "    -64.20223931265764,\n",
       "    -69.16730075901994,\n",
       "    -58.282191233859855,\n",
       "    -68.67939547038289,\n",
       "    -60.89587298724253,\n",
       "    -84.40742356530168,\n",
       "    -72.69733718128198,\n",
       "    -68.6181077045653,\n",
       "    -67.6852901915581,\n",
       "    -66.81782298629858,\n",
       "    -75.71346284774445,\n",
       "    -81.56151570895031,\n",
       "    -71.83489948178813,\n",
       "    -69.31228413163798,\n",
       "    -82.28840864949741,\n",
       "    -40.03923328968734,\n",
       "    -92.58865257580194,\n",
       "    -75.09214163992002,\n",
       "    -65.33452200895668,\n",
       "    -69.59711433185419,\n",
       "    -60.90493524626281,\n",
       "    -43.250211921806056,\n",
       "    -66.29616066616995,\n",
       "    -71.90041222530846,\n",
       "    -68.30843493605241,\n",
       "    -59.25186364585386,\n",
       "    -67.24671888413926,\n",
       "    -62.118387835753765,\n",
       "    -63.5696202948074,\n",
       "    -68.386581731438,\n",
       "    -66.35109870728,\n",
       "    -36.60685447487495,\n",
       "    -71.81025744527126,\n",
       "    -44.657284655080474,\n",
       "    -57.23216042220859,\n",
       "    -72.59903521083703,\n",
       "    -65.27349806564806,\n",
       "    -57.64517412656196,\n",
       "    -85.706511288547,\n",
       "    -69.14043816900711,\n",
       "    -65.2157017261321,\n",
       "    -68.84948200131441,\n",
       "    -59.58407168780977,\n",
       "    -64.81409784176688,\n",
       "    -67.78841268776729,\n",
       "    -61.63646051787137,\n",
       "    -67.42038579395863,\n",
       "    -63.55228675260339,\n",
       "    -36.05246982909452,\n",
       "    -65.43353507519019,\n",
       "    -71.84705903296883,\n",
       "    -68.9124214448644,\n",
       "    -67.65742984193881,\n",
       "    -52.405215445496786,\n",
       "    -47.10371113736312,\n",
       "    -70.41843140823815,\n",
       "    -65.74766158024141,\n",
       "    -64.03254029911108,\n",
       "    -65.09204308563484,\n",
       "    -66.37958526329501,\n",
       "    -67.26434907469341,\n",
       "    -65.57809579496855,\n",
       "    -73.55271536738572,\n",
       "    -65.83543526029527,\n",
       "    -66.61226579298098,\n",
       "    -68.10607860963158,\n",
       "    -45.866562265858036,\n",
       "    -71.98342071663131,\n",
       "    -60.43333277198608,\n",
       "    -55.97238123839499,\n",
       "    -70.70487892345413,\n",
       "    -82.87494184585428,\n",
       "    -69.75108706069916,\n",
       "    -69.38140784748984,\n",
       "    -61.078985272202935,\n",
       "    -65.9315558259163,\n",
       "    -67.32088950246127,\n",
       "    -69.92122855193438,\n",
       "    -74.88363765849341,\n",
       "    -62.92561093516224,\n",
       "    -62.66249597538543,\n",
       "    -67.0682810480731,\n",
       "    -69.03533955068522,\n",
       "    -62.59179835301462,\n",
       "    -66.76594867862859,\n",
       "    -74.50526428597678],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22087700435489455,\n",
       "   'mean_inference_ms': 0.5764467482257124,\n",
       "   'mean_action_processing_ms': 0.07613423274677966,\n",
       "   'mean_env_wait_ms': 1.1365478502490076,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 115500,\n",
       "  'agent_timesteps_total': 115500,\n",
       "  'timers': {'learn_time_ms': 1.37, 'learn_throughput': 72992.656},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.765663,\n",
       "     'max_q': -3.782373,\n",
       "     'min_q': -21.420307,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 115500,\n",
       "   'num_agent_steps_sampled': 115500,\n",
       "   'num_steps_trained': 11400100,\n",
       "   'num_agent_steps_trained': 11400100,\n",
       "   'last_target_update_ts': 115500,\n",
       "   'num_target_updates': 114001},\n",
       "  'done': False,\n",
       "  'episodes_total': 1143,\n",
       "  'training_iteration': 77,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-16-25',\n",
       "  'timestamp': 1625501785,\n",
       "  'time_this_iter_s': 20.657728910446167,\n",
       "  'time_total_s': 1527.8968584537506,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1527.8968584537506,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 77,\n",
       "  'perf': {'cpu_util_percent': 12.433333333333334,\n",
       "   'ram_util_percent': 47.5074074074074,\n",
       "   'gpu_util_percent0': 0.10148148148148148,\n",
       "   'vram_util_percent0': 0.5333106054149265}},\n",
       " {'episode_reward_max': -36.05246982909452,\n",
       "  'episode_reward_min': -92.58865257580194,\n",
       "  'episode_reward_mean': -66.14954896127449,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-69.16730075901994,\n",
       "    -58.282191233859855,\n",
       "    -68.67939547038289,\n",
       "    -60.89587298724253,\n",
       "    -84.40742356530168,\n",
       "    -72.69733718128198,\n",
       "    -68.6181077045653,\n",
       "    -67.6852901915581,\n",
       "    -66.81782298629858,\n",
       "    -75.71346284774445,\n",
       "    -81.56151570895031,\n",
       "    -71.83489948178813,\n",
       "    -69.31228413163798,\n",
       "    -82.28840864949741,\n",
       "    -40.03923328968734,\n",
       "    -92.58865257580194,\n",
       "    -75.09214163992002,\n",
       "    -65.33452200895668,\n",
       "    -69.59711433185419,\n",
       "    -60.90493524626281,\n",
       "    -43.250211921806056,\n",
       "    -66.29616066616995,\n",
       "    -71.90041222530846,\n",
       "    -68.30843493605241,\n",
       "    -59.25186364585386,\n",
       "    -67.24671888413926,\n",
       "    -62.118387835753765,\n",
       "    -63.5696202948074,\n",
       "    -68.386581731438,\n",
       "    -66.35109870728,\n",
       "    -36.60685447487495,\n",
       "    -71.81025744527126,\n",
       "    -44.657284655080474,\n",
       "    -57.23216042220859,\n",
       "    -72.59903521083703,\n",
       "    -65.27349806564806,\n",
       "    -57.64517412656196,\n",
       "    -85.706511288547,\n",
       "    -69.14043816900711,\n",
       "    -65.2157017261321,\n",
       "    -68.84948200131441,\n",
       "    -59.58407168780977,\n",
       "    -64.81409784176688,\n",
       "    -67.78841268776729,\n",
       "    -61.63646051787137,\n",
       "    -67.42038579395863,\n",
       "    -63.55228675260339,\n",
       "    -36.05246982909452,\n",
       "    -65.43353507519019,\n",
       "    -71.84705903296883,\n",
       "    -68.9124214448644,\n",
       "    -67.65742984193881,\n",
       "    -52.405215445496786,\n",
       "    -47.10371113736312,\n",
       "    -70.41843140823815,\n",
       "    -65.74766158024141,\n",
       "    -64.03254029911108,\n",
       "    -65.09204308563484,\n",
       "    -66.37958526329501,\n",
       "    -67.26434907469341,\n",
       "    -65.57809579496855,\n",
       "    -73.55271536738572,\n",
       "    -65.83543526029527,\n",
       "    -66.61226579298098,\n",
       "    -68.10607860963158,\n",
       "    -45.866562265858036,\n",
       "    -71.98342071663131,\n",
       "    -60.43333277198608,\n",
       "    -55.97238123839499,\n",
       "    -70.70487892345413,\n",
       "    -82.87494184585428,\n",
       "    -69.75108706069916,\n",
       "    -69.38140784748984,\n",
       "    -61.078985272202935,\n",
       "    -65.9315558259163,\n",
       "    -67.32088950246127,\n",
       "    -69.92122855193438,\n",
       "    -74.88363765849341,\n",
       "    -62.92561093516224,\n",
       "    -62.66249597538543,\n",
       "    -67.0682810480731,\n",
       "    -69.03533955068522,\n",
       "    -62.59179835301462,\n",
       "    -66.76594867862859,\n",
       "    -74.50526428597678,\n",
       "    -68.0734287285836,\n",
       "    -69.00916417120509,\n",
       "    -62.6010403134246,\n",
       "    -68.64213050902602,\n",
       "    -66.50142060074687,\n",
       "    -65.23530116633692,\n",
       "    -65.82368563456646,\n",
       "    -64.10718741704403,\n",
       "    -68.65304229894207,\n",
       "    -71.27958284077101,\n",
       "    -78.64217386956769,\n",
       "    -65.96940842580726,\n",
       "    -60.01463391900356,\n",
       "    -72.57255207485534,\n",
       "    -70.410536798392],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22084311339396195,\n",
       "   'mean_inference_ms': 0.5768062873920795,\n",
       "   'mean_action_processing_ms': 0.0761180115019275,\n",
       "   'mean_env_wait_ms': 1.1363647597080437,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 117000,\n",
       "  'agent_timesteps_total': 117000,\n",
       "  'timers': {'learn_time_ms': 1.492, 'learn_throughput': 67005.943},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.397189,\n",
       "     'max_q': -4.369564,\n",
       "     'min_q': -24.226,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 117000,\n",
       "   'num_agent_steps_sampled': 117000,\n",
       "   'num_steps_trained': 11550100,\n",
       "   'num_agent_steps_trained': 11550100,\n",
       "   'last_target_update_ts': 117000,\n",
       "   'num_target_updates': 115501},\n",
       "  'done': False,\n",
       "  'episodes_total': 1158,\n",
       "  'training_iteration': 78,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-16-46',\n",
       "  'timestamp': 1625501806,\n",
       "  'time_this_iter_s': 20.628307104110718,\n",
       "  'time_total_s': 1548.5251655578613,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1548.5251655578613,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 78,\n",
       "  'perf': {'cpu_util_percent': 12.444444444444445,\n",
       "   'ram_util_percent': 47.599999999999994,\n",
       "   'gpu_util_percent0': 0.09148148148148147,\n",
       "   'vram_util_percent0': 0.5331306760608728}},\n",
       " {'episode_reward_max': -36.05246982909452,\n",
       "  'episode_reward_min': -92.58865257580194,\n",
       "  'episode_reward_mean': -65.99813894333442,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-92.58865257580194,\n",
       "    -75.09214163992002,\n",
       "    -65.33452200895668,\n",
       "    -69.59711433185419,\n",
       "    -60.90493524626281,\n",
       "    -43.250211921806056,\n",
       "    -66.29616066616995,\n",
       "    -71.90041222530846,\n",
       "    -68.30843493605241,\n",
       "    -59.25186364585386,\n",
       "    -67.24671888413926,\n",
       "    -62.118387835753765,\n",
       "    -63.5696202948074,\n",
       "    -68.386581731438,\n",
       "    -66.35109870728,\n",
       "    -36.60685447487495,\n",
       "    -71.81025744527126,\n",
       "    -44.657284655080474,\n",
       "    -57.23216042220859,\n",
       "    -72.59903521083703,\n",
       "    -65.27349806564806,\n",
       "    -57.64517412656196,\n",
       "    -85.706511288547,\n",
       "    -69.14043816900711,\n",
       "    -65.2157017261321,\n",
       "    -68.84948200131441,\n",
       "    -59.58407168780977,\n",
       "    -64.81409784176688,\n",
       "    -67.78841268776729,\n",
       "    -61.63646051787137,\n",
       "    -67.42038579395863,\n",
       "    -63.55228675260339,\n",
       "    -36.05246982909452,\n",
       "    -65.43353507519019,\n",
       "    -71.84705903296883,\n",
       "    -68.9124214448644,\n",
       "    -67.65742984193881,\n",
       "    -52.405215445496786,\n",
       "    -47.10371113736312,\n",
       "    -70.41843140823815,\n",
       "    -65.74766158024141,\n",
       "    -64.03254029911108,\n",
       "    -65.09204308563484,\n",
       "    -66.37958526329501,\n",
       "    -67.26434907469341,\n",
       "    -65.57809579496855,\n",
       "    -73.55271536738572,\n",
       "    -65.83543526029527,\n",
       "    -66.61226579298098,\n",
       "    -68.10607860963158,\n",
       "    -45.866562265858036,\n",
       "    -71.98342071663131,\n",
       "    -60.43333277198608,\n",
       "    -55.97238123839499,\n",
       "    -70.70487892345413,\n",
       "    -82.87494184585428,\n",
       "    -69.75108706069916,\n",
       "    -69.38140784748984,\n",
       "    -61.078985272202935,\n",
       "    -65.9315558259163,\n",
       "    -67.32088950246127,\n",
       "    -69.92122855193438,\n",
       "    -74.88363765849341,\n",
       "    -62.92561093516224,\n",
       "    -62.66249597538543,\n",
       "    -67.0682810480731,\n",
       "    -69.03533955068522,\n",
       "    -62.59179835301462,\n",
       "    -66.76594867862859,\n",
       "    -74.50526428597678,\n",
       "    -68.0734287285836,\n",
       "    -69.00916417120509,\n",
       "    -62.6010403134246,\n",
       "    -68.64213050902602,\n",
       "    -66.50142060074687,\n",
       "    -65.23530116633692,\n",
       "    -65.82368563456646,\n",
       "    -64.10718741704403,\n",
       "    -68.65304229894207,\n",
       "    -71.27958284077101,\n",
       "    -78.64217386956769,\n",
       "    -65.96940842580726,\n",
       "    -60.01463391900356,\n",
       "    -72.57255207485534,\n",
       "    -70.410536798392,\n",
       "    -66.03287964908229,\n",
       "    -63.32987566589418,\n",
       "    -86.55496556376747,\n",
       "    -66.28881802024708,\n",
       "    -65.93600042302312,\n",
       "    -64.63328453801817,\n",
       "    -63.94876615294733,\n",
       "    -71.24898138399388,\n",
       "    -67.1297584377318,\n",
       "    -69.11112721949239,\n",
       "    -71.34719504264459,\n",
       "    -71.73409934636712,\n",
       "    -64.9754120008936,\n",
       "    -65.95606707378361,\n",
       "    -64.63231387692377],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22081211901226117,\n",
       "   'mean_inference_ms': 0.5772226163766435,\n",
       "   'mean_action_processing_ms': 0.07610410160922648,\n",
       "   'mean_env_wait_ms': 1.1361366931379615,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 118500,\n",
       "  'agent_timesteps_total': 118500,\n",
       "  'timers': {'learn_time_ms': 1.775, 'learn_throughput': 56345.518},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.589531,\n",
       "     'max_q': -6.3148727,\n",
       "     'min_q': -21.025331,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 118500,\n",
       "   'num_agent_steps_sampled': 118500,\n",
       "   'num_steps_trained': 11700100,\n",
       "   'num_agent_steps_trained': 11700100,\n",
       "   'last_target_update_ts': 118500,\n",
       "   'num_target_updates': 117001},\n",
       "  'done': False,\n",
       "  'episodes_total': 1173,\n",
       "  'training_iteration': 79,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-17-07',\n",
       "  'timestamp': 1625501827,\n",
       "  'time_this_iter_s': 20.68928599357605,\n",
       "  'time_total_s': 1569.2144515514374,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1569.2144515514374,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 79,\n",
       "  'perf': {'cpu_util_percent': 12.422222222222219,\n",
       "   'ram_util_percent': 47.599999999999994,\n",
       "   'gpu_util_percent0': 0.10851851851851851,\n",
       "   'vram_util_percent0': 0.5333863651429491}},\n",
       " {'episode_reward_max': -36.05246982909452,\n",
       "  'episode_reward_min': -86.55496556376747,\n",
       "  'episode_reward_mean': -65.82012541305664,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-36.60685447487495,\n",
       "    -71.81025744527126,\n",
       "    -44.657284655080474,\n",
       "    -57.23216042220859,\n",
       "    -72.59903521083703,\n",
       "    -65.27349806564806,\n",
       "    -57.64517412656196,\n",
       "    -85.706511288547,\n",
       "    -69.14043816900711,\n",
       "    -65.2157017261321,\n",
       "    -68.84948200131441,\n",
       "    -59.58407168780977,\n",
       "    -64.81409784176688,\n",
       "    -67.78841268776729,\n",
       "    -61.63646051787137,\n",
       "    -67.42038579395863,\n",
       "    -63.55228675260339,\n",
       "    -36.05246982909452,\n",
       "    -65.43353507519019,\n",
       "    -71.84705903296883,\n",
       "    -68.9124214448644,\n",
       "    -67.65742984193881,\n",
       "    -52.405215445496786,\n",
       "    -47.10371113736312,\n",
       "    -70.41843140823815,\n",
       "    -65.74766158024141,\n",
       "    -64.03254029911108,\n",
       "    -65.09204308563484,\n",
       "    -66.37958526329501,\n",
       "    -67.26434907469341,\n",
       "    -65.57809579496855,\n",
       "    -73.55271536738572,\n",
       "    -65.83543526029527,\n",
       "    -66.61226579298098,\n",
       "    -68.10607860963158,\n",
       "    -45.866562265858036,\n",
       "    -71.98342071663131,\n",
       "    -60.43333277198608,\n",
       "    -55.97238123839499,\n",
       "    -70.70487892345413,\n",
       "    -82.87494184585428,\n",
       "    -69.75108706069916,\n",
       "    -69.38140784748984,\n",
       "    -61.078985272202935,\n",
       "    -65.9315558259163,\n",
       "    -67.32088950246127,\n",
       "    -69.92122855193438,\n",
       "    -74.88363765849341,\n",
       "    -62.92561093516224,\n",
       "    -62.66249597538543,\n",
       "    -67.0682810480731,\n",
       "    -69.03533955068522,\n",
       "    -62.59179835301462,\n",
       "    -66.76594867862859,\n",
       "    -74.50526428597678,\n",
       "    -68.0734287285836,\n",
       "    -69.00916417120509,\n",
       "    -62.6010403134246,\n",
       "    -68.64213050902602,\n",
       "    -66.50142060074687,\n",
       "    -65.23530116633692,\n",
       "    -65.82368563456646,\n",
       "    -64.10718741704403,\n",
       "    -68.65304229894207,\n",
       "    -71.27958284077101,\n",
       "    -78.64217386956769,\n",
       "    -65.96940842580726,\n",
       "    -60.01463391900356,\n",
       "    -72.57255207485534,\n",
       "    -70.410536798392,\n",
       "    -66.03287964908229,\n",
       "    -63.32987566589418,\n",
       "    -86.55496556376747,\n",
       "    -66.28881802024708,\n",
       "    -65.93600042302312,\n",
       "    -64.63328453801817,\n",
       "    -63.94876615294733,\n",
       "    -71.24898138399388,\n",
       "    -67.1297584377318,\n",
       "    -69.11112721949239,\n",
       "    -71.34719504264459,\n",
       "    -71.73409934636712,\n",
       "    -64.9754120008936,\n",
       "    -65.95606707378361,\n",
       "    -64.63231387692377,\n",
       "    -47.924749291424035,\n",
       "    -66.1473400311454,\n",
       "    -66.53983341684524,\n",
       "    -86.0401426872659,\n",
       "    -41.5534325409933,\n",
       "    -71.01785574888297,\n",
       "    -61.75277042673402,\n",
       "    -68.51707338373136,\n",
       "    -62.47287795350829,\n",
       "    -67.30964273716144,\n",
       "    -79.00211317446332,\n",
       "    -67.59588111459394,\n",
       "    -67.69005606911631,\n",
       "    -64.72266823468692,\n",
       "    -64.10906681307337],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22077981284346151,\n",
       "   'mean_inference_ms': 0.577631688122956,\n",
       "   'mean_action_processing_ms': 0.07609168622693502,\n",
       "   'mean_env_wait_ms': 1.1357405039239143,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 120000,\n",
       "  'agent_timesteps_total': 120000,\n",
       "  'timers': {'learn_time_ms': 1.338, 'learn_throughput': 74766.11},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.99439,\n",
       "     'max_q': -3.8598123,\n",
       "     'min_q': -22.223774,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 120000,\n",
       "   'num_agent_steps_sampled': 120000,\n",
       "   'num_steps_trained': 11850100,\n",
       "   'num_agent_steps_trained': 11850100,\n",
       "   'last_target_update_ts': 120000,\n",
       "   'num_target_updates': 118501},\n",
       "  'done': False,\n",
       "  'episodes_total': 1188,\n",
       "  'training_iteration': 80,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-17-27',\n",
       "  'timestamp': 1625501847,\n",
       "  'time_this_iter_s': 20.586546182632446,\n",
       "  'time_total_s': 1589.8009977340698,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1589.8009977340698,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 80,\n",
       "  'perf': {'cpu_util_percent': 12.51923076923077,\n",
       "   'ram_util_percent': 47.68846153846154,\n",
       "   'gpu_util_percent0': 0.10884615384615384,\n",
       "   'vram_util_percent0': 0.5334460987746593}},\n",
       " {'episode_reward_max': -36.05246982909452,\n",
       "  'episode_reward_min': -86.55496556376747,\n",
       "  'episode_reward_mean': -65.68452881089556,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 14,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-61.63646051787137,\n",
       "    -67.42038579395863,\n",
       "    -63.55228675260339,\n",
       "    -36.05246982909452,\n",
       "    -65.43353507519019,\n",
       "    -71.84705903296883,\n",
       "    -68.9124214448644,\n",
       "    -67.65742984193881,\n",
       "    -52.405215445496786,\n",
       "    -47.10371113736312,\n",
       "    -70.41843140823815,\n",
       "    -65.74766158024141,\n",
       "    -64.03254029911108,\n",
       "    -65.09204308563484,\n",
       "    -66.37958526329501,\n",
       "    -67.26434907469341,\n",
       "    -65.57809579496855,\n",
       "    -73.55271536738572,\n",
       "    -65.83543526029527,\n",
       "    -66.61226579298098,\n",
       "    -68.10607860963158,\n",
       "    -45.866562265858036,\n",
       "    -71.98342071663131,\n",
       "    -60.43333277198608,\n",
       "    -55.97238123839499,\n",
       "    -70.70487892345413,\n",
       "    -82.87494184585428,\n",
       "    -69.75108706069916,\n",
       "    -69.38140784748984,\n",
       "    -61.078985272202935,\n",
       "    -65.9315558259163,\n",
       "    -67.32088950246127,\n",
       "    -69.92122855193438,\n",
       "    -74.88363765849341,\n",
       "    -62.92561093516224,\n",
       "    -62.66249597538543,\n",
       "    -67.0682810480731,\n",
       "    -69.03533955068522,\n",
       "    -62.59179835301462,\n",
       "    -66.76594867862859,\n",
       "    -74.50526428597678,\n",
       "    -68.0734287285836,\n",
       "    -69.00916417120509,\n",
       "    -62.6010403134246,\n",
       "    -68.64213050902602,\n",
       "    -66.50142060074687,\n",
       "    -65.23530116633692,\n",
       "    -65.82368563456646,\n",
       "    -64.10718741704403,\n",
       "    -68.65304229894207,\n",
       "    -71.27958284077101,\n",
       "    -78.64217386956769,\n",
       "    -65.96940842580726,\n",
       "    -60.01463391900356,\n",
       "    -72.57255207485534,\n",
       "    -70.410536798392,\n",
       "    -66.03287964908229,\n",
       "    -63.32987566589418,\n",
       "    -86.55496556376747,\n",
       "    -66.28881802024708,\n",
       "    -65.93600042302312,\n",
       "    -64.63328453801817,\n",
       "    -63.94876615294733,\n",
       "    -71.24898138399388,\n",
       "    -67.1297584377318,\n",
       "    -69.11112721949239,\n",
       "    -71.34719504264459,\n",
       "    -71.73409934636712,\n",
       "    -64.9754120008936,\n",
       "    -65.95606707378361,\n",
       "    -64.63231387692377,\n",
       "    -47.924749291424035,\n",
       "    -66.1473400311454,\n",
       "    -66.53983341684524,\n",
       "    -86.0401426872659,\n",
       "    -41.5534325409933,\n",
       "    -71.01785574888297,\n",
       "    -61.75277042673402,\n",
       "    -68.51707338373136,\n",
       "    -62.47287795350829,\n",
       "    -67.30964273716144,\n",
       "    -79.00211317446332,\n",
       "    -67.59588111459394,\n",
       "    -67.69005606911631,\n",
       "    -64.72266823468692,\n",
       "    -64.10906681307337,\n",
       "    -66.16885114464124,\n",
       "    -67.18091056094858,\n",
       "    -63.88666189291853,\n",
       "    -66.25780409312665,\n",
       "    -73.15183351159207,\n",
       "    -73.99556360201592,\n",
       "    -47.674547871669326,\n",
       "    -64.72451928686434,\n",
       "    -38.23809391260414,\n",
       "    -75.57505930067235,\n",
       "    -70.09891674632519,\n",
       "    -47.80019945119438,\n",
       "    -69.87960175755151,\n",
       "    -48.73075645459568],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22075270720468232,\n",
       "   'mean_inference_ms': 0.5781469914600877,\n",
       "   'mean_action_processing_ms': 0.07608294977793427,\n",
       "   'mean_env_wait_ms': 1.1352229654319408,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 121500,\n",
       "  'agent_timesteps_total': 121500,\n",
       "  'timers': {'learn_time_ms': 1.376, 'learn_throughput': 72677.722},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.103996,\n",
       "     'max_q': -6.1102695,\n",
       "     'min_q': -21.759384,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 121500,\n",
       "   'num_agent_steps_sampled': 121500,\n",
       "   'num_steps_trained': 12000100,\n",
       "   'num_agent_steps_trained': 12000100,\n",
       "   'last_target_update_ts': 121500,\n",
       "   'num_target_updates': 120001},\n",
       "  'done': False,\n",
       "  'episodes_total': 1202,\n",
       "  'training_iteration': 81,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-17-48',\n",
       "  'timestamp': 1625501868,\n",
       "  'time_this_iter_s': 20.943788528442383,\n",
       "  'time_total_s': 1610.7447862625122,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1610.7447862625122,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 81,\n",
       "  'perf': {'cpu_util_percent': 12.781481481481482,\n",
       "   'ram_util_percent': 47.737037037037034,\n",
       "   'gpu_util_percent0': 0.10666666666666665,\n",
       "   'vram_util_percent0': 0.5332632555849124}},\n",
       " {'episode_reward_max': -38.23809391260414,\n",
       "  'episode_reward_min': -95.73088590442056,\n",
       "  'episode_reward_mean': -66.02039538171567,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-67.26434907469341,\n",
       "    -65.57809579496855,\n",
       "    -73.55271536738572,\n",
       "    -65.83543526029527,\n",
       "    -66.61226579298098,\n",
       "    -68.10607860963158,\n",
       "    -45.866562265858036,\n",
       "    -71.98342071663131,\n",
       "    -60.43333277198608,\n",
       "    -55.97238123839499,\n",
       "    -70.70487892345413,\n",
       "    -82.87494184585428,\n",
       "    -69.75108706069916,\n",
       "    -69.38140784748984,\n",
       "    -61.078985272202935,\n",
       "    -65.9315558259163,\n",
       "    -67.32088950246127,\n",
       "    -69.92122855193438,\n",
       "    -74.88363765849341,\n",
       "    -62.92561093516224,\n",
       "    -62.66249597538543,\n",
       "    -67.0682810480731,\n",
       "    -69.03533955068522,\n",
       "    -62.59179835301462,\n",
       "    -66.76594867862859,\n",
       "    -74.50526428597678,\n",
       "    -68.0734287285836,\n",
       "    -69.00916417120509,\n",
       "    -62.6010403134246,\n",
       "    -68.64213050902602,\n",
       "    -66.50142060074687,\n",
       "    -65.23530116633692,\n",
       "    -65.82368563456646,\n",
       "    -64.10718741704403,\n",
       "    -68.65304229894207,\n",
       "    -71.27958284077101,\n",
       "    -78.64217386956769,\n",
       "    -65.96940842580726,\n",
       "    -60.01463391900356,\n",
       "    -72.57255207485534,\n",
       "    -70.410536798392,\n",
       "    -66.03287964908229,\n",
       "    -63.32987566589418,\n",
       "    -86.55496556376747,\n",
       "    -66.28881802024708,\n",
       "    -65.93600042302312,\n",
       "    -64.63328453801817,\n",
       "    -63.94876615294733,\n",
       "    -71.24898138399388,\n",
       "    -67.1297584377318,\n",
       "    -69.11112721949239,\n",
       "    -71.34719504264459,\n",
       "    -71.73409934636712,\n",
       "    -64.9754120008936,\n",
       "    -65.95606707378361,\n",
       "    -64.63231387692377,\n",
       "    -47.924749291424035,\n",
       "    -66.1473400311454,\n",
       "    -66.53983341684524,\n",
       "    -86.0401426872659,\n",
       "    -41.5534325409933,\n",
       "    -71.01785574888297,\n",
       "    -61.75277042673402,\n",
       "    -68.51707338373136,\n",
       "    -62.47287795350829,\n",
       "    -67.30964273716144,\n",
       "    -79.00211317446332,\n",
       "    -67.59588111459394,\n",
       "    -67.69005606911631,\n",
       "    -64.72266823468692,\n",
       "    -64.10906681307337,\n",
       "    -66.16885114464124,\n",
       "    -67.18091056094858,\n",
       "    -63.88666189291853,\n",
       "    -66.25780409312665,\n",
       "    -73.15183351159207,\n",
       "    -73.99556360201592,\n",
       "    -47.674547871669326,\n",
       "    -64.72451928686434,\n",
       "    -38.23809391260414,\n",
       "    -75.57505930067235,\n",
       "    -70.09891674632519,\n",
       "    -47.80019945119438,\n",
       "    -69.87960175755151,\n",
       "    -48.73075645459568,\n",
       "    -61.761267829036214,\n",
       "    -95.73088590442056,\n",
       "    -62.26348097614151,\n",
       "    -64.3739851070154,\n",
       "    -63.18722263390181,\n",
       "    -50.30055069191858,\n",
       "    -50.13743271425375,\n",
       "    -65.01800314408617,\n",
       "    -63.67122023925452,\n",
       "    -53.57736589842809,\n",
       "    -72.9205160285787,\n",
       "    -67.31208271213991,\n",
       "    -80.27482194682995,\n",
       "    -45.95772658957363,\n",
       "    -70.79133117430331],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22072233231116783,\n",
       "   'mean_inference_ms': 0.5786908631270545,\n",
       "   'mean_action_processing_ms': 0.07607490618901135,\n",
       "   'mean_env_wait_ms': 1.1346606022280072,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 123000,\n",
       "  'agent_timesteps_total': 123000,\n",
       "  'timers': {'learn_time_ms': 1.591, 'learn_throughput': 62850.139},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.640395,\n",
       "     'max_q': -4.099222,\n",
       "     'min_q': -21.04452,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 123000,\n",
       "   'num_agent_steps_sampled': 123000,\n",
       "   'num_steps_trained': 12150100,\n",
       "   'num_agent_steps_trained': 12150100,\n",
       "   'last_target_update_ts': 123000,\n",
       "   'num_target_updates': 121501},\n",
       "  'done': False,\n",
       "  'episodes_total': 1217,\n",
       "  'training_iteration': 82,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-18-09',\n",
       "  'timestamp': 1625501889,\n",
       "  'time_this_iter_s': 20.780698537826538,\n",
       "  'time_total_s': 1631.5254848003387,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1631.5254848003387,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 82,\n",
       "  'perf': {'cpu_util_percent': 12.44814814814815,\n",
       "   'ram_util_percent': 47.79999999999999,\n",
       "   'gpu_util_percent0': 0.1062962962962963,\n",
       "   'vram_util_percent0': 0.5326761176927375}},\n",
       " {'episode_reward_max': -38.23809391260414,\n",
       "  'episode_reward_min': -95.73088590442056,\n",
       "  'episode_reward_mean': -66.38359638643153,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-65.9315558259163,\n",
       "    -67.32088950246127,\n",
       "    -69.92122855193438,\n",
       "    -74.88363765849341,\n",
       "    -62.92561093516224,\n",
       "    -62.66249597538543,\n",
       "    -67.0682810480731,\n",
       "    -69.03533955068522,\n",
       "    -62.59179835301462,\n",
       "    -66.76594867862859,\n",
       "    -74.50526428597678,\n",
       "    -68.0734287285836,\n",
       "    -69.00916417120509,\n",
       "    -62.6010403134246,\n",
       "    -68.64213050902602,\n",
       "    -66.50142060074687,\n",
       "    -65.23530116633692,\n",
       "    -65.82368563456646,\n",
       "    -64.10718741704403,\n",
       "    -68.65304229894207,\n",
       "    -71.27958284077101,\n",
       "    -78.64217386956769,\n",
       "    -65.96940842580726,\n",
       "    -60.01463391900356,\n",
       "    -72.57255207485534,\n",
       "    -70.410536798392,\n",
       "    -66.03287964908229,\n",
       "    -63.32987566589418,\n",
       "    -86.55496556376747,\n",
       "    -66.28881802024708,\n",
       "    -65.93600042302312,\n",
       "    -64.63328453801817,\n",
       "    -63.94876615294733,\n",
       "    -71.24898138399388,\n",
       "    -67.1297584377318,\n",
       "    -69.11112721949239,\n",
       "    -71.34719504264459,\n",
       "    -71.73409934636712,\n",
       "    -64.9754120008936,\n",
       "    -65.95606707378361,\n",
       "    -64.63231387692377,\n",
       "    -47.924749291424035,\n",
       "    -66.1473400311454,\n",
       "    -66.53983341684524,\n",
       "    -86.0401426872659,\n",
       "    -41.5534325409933,\n",
       "    -71.01785574888297,\n",
       "    -61.75277042673402,\n",
       "    -68.51707338373136,\n",
       "    -62.47287795350829,\n",
       "    -67.30964273716144,\n",
       "    -79.00211317446332,\n",
       "    -67.59588111459394,\n",
       "    -67.69005606911631,\n",
       "    -64.72266823468692,\n",
       "    -64.10906681307337,\n",
       "    -66.16885114464124,\n",
       "    -67.18091056094858,\n",
       "    -63.88666189291853,\n",
       "    -66.25780409312665,\n",
       "    -73.15183351159207,\n",
       "    -73.99556360201592,\n",
       "    -47.674547871669326,\n",
       "    -64.72451928686434,\n",
       "    -38.23809391260414,\n",
       "    -75.57505930067235,\n",
       "    -70.09891674632519,\n",
       "    -47.80019945119438,\n",
       "    -69.87960175755151,\n",
       "    -48.73075645459568,\n",
       "    -61.761267829036214,\n",
       "    -95.73088590442056,\n",
       "    -62.26348097614151,\n",
       "    -64.3739851070154,\n",
       "    -63.18722263390181,\n",
       "    -50.30055069191858,\n",
       "    -50.13743271425375,\n",
       "    -65.01800314408617,\n",
       "    -63.67122023925452,\n",
       "    -53.57736589842809,\n",
       "    -72.9205160285787,\n",
       "    -67.31208271213991,\n",
       "    -80.27482194682995,\n",
       "    -45.95772658957363,\n",
       "    -70.79133117430331,\n",
       "    -92.56857493941283,\n",
       "    -64.81677121178208,\n",
       "    -63.359623753597134,\n",
       "    -64.98321364608017,\n",
       "    -73.74334662802676,\n",
       "    -85.90155196975344,\n",
       "    -69.66462393762308,\n",
       "    -65.70266726245701,\n",
       "    -64.09498243166912,\n",
       "    -69.24550448161992,\n",
       "    -64.01387654041024,\n",
       "    -64.18156995359281,\n",
       "    -67.86001343061182,\n",
       "    -64.73297431166246,\n",
       "    -56.44674381581356],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.220692513959344,\n",
       "   'mean_inference_ms': 0.5791628509540218,\n",
       "   'mean_action_processing_ms': 0.07606786333374436,\n",
       "   'mean_env_wait_ms': 1.134152314670267,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 124500,\n",
       "  'agent_timesteps_total': 124500,\n",
       "  'timers': {'learn_time_ms': 1.544, 'learn_throughput': 64773.895},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.350295,\n",
       "     'max_q': -4.279997,\n",
       "     'min_q': -22.988821,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 124500,\n",
       "   'num_agent_steps_sampled': 124500,\n",
       "   'num_steps_trained': 12300100,\n",
       "   'num_agent_steps_trained': 12300100,\n",
       "   'last_target_update_ts': 124500,\n",
       "   'num_target_updates': 123001},\n",
       "  'done': False,\n",
       "  'episodes_total': 1232,\n",
       "  'training_iteration': 83,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-18-29',\n",
       "  'timestamp': 1625501909,\n",
       "  'time_this_iter_s': 20.566693782806396,\n",
       "  'time_total_s': 1652.0921785831451,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1652.0921785831451,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 83,\n",
       "  'perf': {'cpu_util_percent': 12.52962962962963,\n",
       "   'ram_util_percent': 47.80370370370369,\n",
       "   'gpu_util_percent0': 0.10962962962962963,\n",
       "   'vram_util_percent0': 0.5328749869787968}},\n",
       " {'episode_reward_max': -38.23809391260414,\n",
       "  'episode_reward_min': -95.73088590442056,\n",
       "  'episode_reward_mean': -66.75726655268407,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-66.50142060074687,\n",
       "    -65.23530116633692,\n",
       "    -65.82368563456646,\n",
       "    -64.10718741704403,\n",
       "    -68.65304229894207,\n",
       "    -71.27958284077101,\n",
       "    -78.64217386956769,\n",
       "    -65.96940842580726,\n",
       "    -60.01463391900356,\n",
       "    -72.57255207485534,\n",
       "    -70.410536798392,\n",
       "    -66.03287964908229,\n",
       "    -63.32987566589418,\n",
       "    -86.55496556376747,\n",
       "    -66.28881802024708,\n",
       "    -65.93600042302312,\n",
       "    -64.63328453801817,\n",
       "    -63.94876615294733,\n",
       "    -71.24898138399388,\n",
       "    -67.1297584377318,\n",
       "    -69.11112721949239,\n",
       "    -71.34719504264459,\n",
       "    -71.73409934636712,\n",
       "    -64.9754120008936,\n",
       "    -65.95606707378361,\n",
       "    -64.63231387692377,\n",
       "    -47.924749291424035,\n",
       "    -66.1473400311454,\n",
       "    -66.53983341684524,\n",
       "    -86.0401426872659,\n",
       "    -41.5534325409933,\n",
       "    -71.01785574888297,\n",
       "    -61.75277042673402,\n",
       "    -68.51707338373136,\n",
       "    -62.47287795350829,\n",
       "    -67.30964273716144,\n",
       "    -79.00211317446332,\n",
       "    -67.59588111459394,\n",
       "    -67.69005606911631,\n",
       "    -64.72266823468692,\n",
       "    -64.10906681307337,\n",
       "    -66.16885114464124,\n",
       "    -67.18091056094858,\n",
       "    -63.88666189291853,\n",
       "    -66.25780409312665,\n",
       "    -73.15183351159207,\n",
       "    -73.99556360201592,\n",
       "    -47.674547871669326,\n",
       "    -64.72451928686434,\n",
       "    -38.23809391260414,\n",
       "    -75.57505930067235,\n",
       "    -70.09891674632519,\n",
       "    -47.80019945119438,\n",
       "    -69.87960175755151,\n",
       "    -48.73075645459568,\n",
       "    -61.761267829036214,\n",
       "    -95.73088590442056,\n",
       "    -62.26348097614151,\n",
       "    -64.3739851070154,\n",
       "    -63.18722263390181,\n",
       "    -50.30055069191858,\n",
       "    -50.13743271425375,\n",
       "    -65.01800314408617,\n",
       "    -63.67122023925452,\n",
       "    -53.57736589842809,\n",
       "    -72.9205160285787,\n",
       "    -67.31208271213991,\n",
       "    -80.27482194682995,\n",
       "    -45.95772658957363,\n",
       "    -70.79133117430331,\n",
       "    -92.56857493941283,\n",
       "    -64.81677121178208,\n",
       "    -63.359623753597134,\n",
       "    -64.98321364608017,\n",
       "    -73.74334662802676,\n",
       "    -85.90155196975344,\n",
       "    -69.66462393762308,\n",
       "    -65.70266726245701,\n",
       "    -64.09498243166912,\n",
       "    -69.24550448161992,\n",
       "    -64.01387654041024,\n",
       "    -64.18156995359281,\n",
       "    -67.86001343061182,\n",
       "    -64.73297431166246,\n",
       "    -56.44674381581356,\n",
       "    -95.00048752308457,\n",
       "    -93.6066862331683,\n",
       "    -70.78181313045624,\n",
       "    -70.10708492357445,\n",
       "    -95.19426424583779,\n",
       "    -65.24758327468132,\n",
       "    -67.6583952186906,\n",
       "    -72.17428065824768,\n",
       "    -64.89593054146704,\n",
       "    -40.29803021964885,\n",
       "    -67.01011935620723,\n",
       "    -45.182306559434345,\n",
       "    -64.80021721711493,\n",
       "    -69.13294859282678,\n",
       "    -68.21468301878362],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2206580467914446,\n",
       "   'mean_inference_ms': 0.5795385171640554,\n",
       "   'mean_action_processing_ms': 0.07605870855529931,\n",
       "   'mean_env_wait_ms': 1.1336015854887576,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 126000,\n",
       "  'agent_timesteps_total': 126000,\n",
       "  'timers': {'learn_time_ms': 1.417, 'learn_throughput': 70554.165},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -14.385573,\n",
       "     'max_q': -4.343643,\n",
       "     'min_q': -24.62043,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 126000,\n",
       "   'num_agent_steps_sampled': 126000,\n",
       "   'num_steps_trained': 12450100,\n",
       "   'num_agent_steps_trained': 12450100,\n",
       "   'last_target_update_ts': 126000,\n",
       "   'num_target_updates': 124501},\n",
       "  'done': False,\n",
       "  'episodes_total': 1247,\n",
       "  'training_iteration': 84,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-18-50',\n",
       "  'timestamp': 1625501930,\n",
       "  'time_this_iter_s': 20.309233903884888,\n",
       "  'time_total_s': 1672.40141248703,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1672.40141248703,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 84,\n",
       "  'perf': {'cpu_util_percent': 12.496153846153847,\n",
       "   'ram_util_percent': 47.8423076923077,\n",
       "   'gpu_util_percent0': 0.10615384615384617,\n",
       "   'vram_util_percent0': 0.5326200263556438}},\n",
       " {'episode_reward_max': -38.23809391260414,\n",
       "  'episode_reward_min': -95.73088590442056,\n",
       "  'episode_reward_mean': -66.11387674269318,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-65.93600042302312,\n",
       "    -64.63328453801817,\n",
       "    -63.94876615294733,\n",
       "    -71.24898138399388,\n",
       "    -67.1297584377318,\n",
       "    -69.11112721949239,\n",
       "    -71.34719504264459,\n",
       "    -71.73409934636712,\n",
       "    -64.9754120008936,\n",
       "    -65.95606707378361,\n",
       "    -64.63231387692377,\n",
       "    -47.924749291424035,\n",
       "    -66.1473400311454,\n",
       "    -66.53983341684524,\n",
       "    -86.0401426872659,\n",
       "    -41.5534325409933,\n",
       "    -71.01785574888297,\n",
       "    -61.75277042673402,\n",
       "    -68.51707338373136,\n",
       "    -62.47287795350829,\n",
       "    -67.30964273716144,\n",
       "    -79.00211317446332,\n",
       "    -67.59588111459394,\n",
       "    -67.69005606911631,\n",
       "    -64.72266823468692,\n",
       "    -64.10906681307337,\n",
       "    -66.16885114464124,\n",
       "    -67.18091056094858,\n",
       "    -63.88666189291853,\n",
       "    -66.25780409312665,\n",
       "    -73.15183351159207,\n",
       "    -73.99556360201592,\n",
       "    -47.674547871669326,\n",
       "    -64.72451928686434,\n",
       "    -38.23809391260414,\n",
       "    -75.57505930067235,\n",
       "    -70.09891674632519,\n",
       "    -47.80019945119438,\n",
       "    -69.87960175755151,\n",
       "    -48.73075645459568,\n",
       "    -61.761267829036214,\n",
       "    -95.73088590442056,\n",
       "    -62.26348097614151,\n",
       "    -64.3739851070154,\n",
       "    -63.18722263390181,\n",
       "    -50.30055069191858,\n",
       "    -50.13743271425375,\n",
       "    -65.01800314408617,\n",
       "    -63.67122023925452,\n",
       "    -53.57736589842809,\n",
       "    -72.9205160285787,\n",
       "    -67.31208271213991,\n",
       "    -80.27482194682995,\n",
       "    -45.95772658957363,\n",
       "    -70.79133117430331,\n",
       "    -92.56857493941283,\n",
       "    -64.81677121178208,\n",
       "    -63.359623753597134,\n",
       "    -64.98321364608017,\n",
       "    -73.74334662802676,\n",
       "    -85.90155196975344,\n",
       "    -69.66462393762308,\n",
       "    -65.70266726245701,\n",
       "    -64.09498243166912,\n",
       "    -69.24550448161992,\n",
       "    -64.01387654041024,\n",
       "    -64.18156995359281,\n",
       "    -67.86001343061182,\n",
       "    -64.73297431166246,\n",
       "    -56.44674381581356,\n",
       "    -95.00048752308457,\n",
       "    -93.6066862331683,\n",
       "    -70.78181313045624,\n",
       "    -70.10708492357445,\n",
       "    -95.19426424583779,\n",
       "    -65.24758327468132,\n",
       "    -67.6583952186906,\n",
       "    -72.17428065824768,\n",
       "    -64.89593054146704,\n",
       "    -40.29803021964885,\n",
       "    -67.01011935620723,\n",
       "    -45.182306559434345,\n",
       "    -64.80021721711493,\n",
       "    -69.13294859282678,\n",
       "    -68.21468301878362,\n",
       "    -62.27049864700586,\n",
       "    -39.94036466254375,\n",
       "    -61.58117458866526,\n",
       "    -69.00351958855732,\n",
       "    -58.52116640237598,\n",
       "    -71.12078275250525,\n",
       "    -67.3743058312665,\n",
       "    -67.90684934074542,\n",
       "    -62.5317097581885,\n",
       "    -65.60680154075843,\n",
       "    -71.09634204441326,\n",
       "    -73.88429402809844,\n",
       "    -78.04196321984904,\n",
       "    -58.76416789604828,\n",
       "    -59.43314264491439],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22062594009929015,\n",
       "   'mean_inference_ms': 0.5798909344775784,\n",
       "   'mean_action_processing_ms': 0.07604969113842906,\n",
       "   'mean_env_wait_ms': 1.1330184569276651,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 127500,\n",
       "  'agent_timesteps_total': 127500,\n",
       "  'timers': {'learn_time_ms': 1.343, 'learn_throughput': 74470.083},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.121033,\n",
       "     'max_q': -4.3295984,\n",
       "     'min_q': -21.543203,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 127500,\n",
       "   'num_agent_steps_sampled': 127500,\n",
       "   'num_steps_trained': 12600100,\n",
       "   'num_agent_steps_trained': 12600100,\n",
       "   'last_target_update_ts': 127500,\n",
       "   'num_target_updates': 126001},\n",
       "  'done': False,\n",
       "  'episodes_total': 1262,\n",
       "  'training_iteration': 85,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-19-11',\n",
       "  'timestamp': 1625501951,\n",
       "  'time_this_iter_s': 21.058491230010986,\n",
       "  'time_total_s': 1693.459903717041,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1693.459903717041,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 85,\n",
       "  'perf': {'cpu_util_percent': 12.496296296296295,\n",
       "   'ram_util_percent': 47.900000000000006,\n",
       "   'gpu_util_percent0': 0.11740740740740739,\n",
       "   'vram_util_percent0': 0.5326192978967205}},\n",
       " {'episode_reward_max': -38.23809391260414,\n",
       "  'episode_reward_min': -102.75119362415712,\n",
       "  'episode_reward_mean': -66.33332917448328,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-41.5534325409933,\n",
       "    -71.01785574888297,\n",
       "    -61.75277042673402,\n",
       "    -68.51707338373136,\n",
       "    -62.47287795350829,\n",
       "    -67.30964273716144,\n",
       "    -79.00211317446332,\n",
       "    -67.59588111459394,\n",
       "    -67.69005606911631,\n",
       "    -64.72266823468692,\n",
       "    -64.10906681307337,\n",
       "    -66.16885114464124,\n",
       "    -67.18091056094858,\n",
       "    -63.88666189291853,\n",
       "    -66.25780409312665,\n",
       "    -73.15183351159207,\n",
       "    -73.99556360201592,\n",
       "    -47.674547871669326,\n",
       "    -64.72451928686434,\n",
       "    -38.23809391260414,\n",
       "    -75.57505930067235,\n",
       "    -70.09891674632519,\n",
       "    -47.80019945119438,\n",
       "    -69.87960175755151,\n",
       "    -48.73075645459568,\n",
       "    -61.761267829036214,\n",
       "    -95.73088590442056,\n",
       "    -62.26348097614151,\n",
       "    -64.3739851070154,\n",
       "    -63.18722263390181,\n",
       "    -50.30055069191858,\n",
       "    -50.13743271425375,\n",
       "    -65.01800314408617,\n",
       "    -63.67122023925452,\n",
       "    -53.57736589842809,\n",
       "    -72.9205160285787,\n",
       "    -67.31208271213991,\n",
       "    -80.27482194682995,\n",
       "    -45.95772658957363,\n",
       "    -70.79133117430331,\n",
       "    -92.56857493941283,\n",
       "    -64.81677121178208,\n",
       "    -63.359623753597134,\n",
       "    -64.98321364608017,\n",
       "    -73.74334662802676,\n",
       "    -85.90155196975344,\n",
       "    -69.66462393762308,\n",
       "    -65.70266726245701,\n",
       "    -64.09498243166912,\n",
       "    -69.24550448161992,\n",
       "    -64.01387654041024,\n",
       "    -64.18156995359281,\n",
       "    -67.86001343061182,\n",
       "    -64.73297431166246,\n",
       "    -56.44674381581356,\n",
       "    -95.00048752308457,\n",
       "    -93.6066862331683,\n",
       "    -70.78181313045624,\n",
       "    -70.10708492357445,\n",
       "    -95.19426424583779,\n",
       "    -65.24758327468132,\n",
       "    -67.6583952186906,\n",
       "    -72.17428065824768,\n",
       "    -64.89593054146704,\n",
       "    -40.29803021964885,\n",
       "    -67.01011935620723,\n",
       "    -45.182306559434345,\n",
       "    -64.80021721711493,\n",
       "    -69.13294859282678,\n",
       "    -68.21468301878362,\n",
       "    -62.27049864700586,\n",
       "    -39.94036466254375,\n",
       "    -61.58117458866526,\n",
       "    -69.00351958855732,\n",
       "    -58.52116640237598,\n",
       "    -71.12078275250525,\n",
       "    -67.3743058312665,\n",
       "    -67.90684934074542,\n",
       "    -62.5317097581885,\n",
       "    -65.60680154075843,\n",
       "    -71.09634204441326,\n",
       "    -73.88429402809844,\n",
       "    -78.04196321984904,\n",
       "    -58.76416789604828,\n",
       "    -59.43314264491439,\n",
       "    -65.34702797623386,\n",
       "    -102.75119362415712,\n",
       "    -64.48471753322755,\n",
       "    -50.5078039955346,\n",
       "    -62.83792162942318,\n",
       "    -71.75066629521443,\n",
       "    -72.12569537613282,\n",
       "    -70.40537822621887,\n",
       "    -66.57363880445412,\n",
       "    -64.35574858617187,\n",
       "    -67.50665442268466,\n",
       "    -45.98107060465112,\n",
       "    -78.01683544586696,\n",
       "    -46.970926982718915,\n",
       "    -99.63503459881807],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22059552942240088,\n",
       "   'mean_inference_ms': 0.5802929390184562,\n",
       "   'mean_action_processing_ms': 0.07604068787325849,\n",
       "   'mean_env_wait_ms': 1.1325395969347303,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 129000,\n",
       "  'agent_timesteps_total': 129000,\n",
       "  'timers': {'learn_time_ms': 1.438, 'learn_throughput': 69545.747},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.961719,\n",
       "     'max_q': -4.06464,\n",
       "     'min_q': -21.01791,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 129000,\n",
       "   'num_agent_steps_sampled': 129000,\n",
       "   'num_steps_trained': 12750100,\n",
       "   'num_agent_steps_trained': 12750100,\n",
       "   'last_target_update_ts': 129000,\n",
       "   'num_target_updates': 127501},\n",
       "  'done': False,\n",
       "  'episodes_total': 1277,\n",
       "  'training_iteration': 86,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-19-31',\n",
       "  'timestamp': 1625501971,\n",
       "  'time_this_iter_s': 20.67622685432434,\n",
       "  'time_total_s': 1714.1361305713654,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1714.1361305713654,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 86,\n",
       "  'perf': {'cpu_util_percent': 12.559259259259258,\n",
       "   'ram_util_percent': 47.95185185185186,\n",
       "   'gpu_util_percent0': 0.11296296296296296,\n",
       "   'vram_util_percent0': 0.5326761176927375}},\n",
       " {'episode_reward_max': -38.23809391260414,\n",
       "  'episode_reward_min': -102.75119362415712,\n",
       "  'episode_reward_mean': -66.38780655270926,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-73.15183351159207,\n",
       "    -73.99556360201592,\n",
       "    -47.674547871669326,\n",
       "    -64.72451928686434,\n",
       "    -38.23809391260414,\n",
       "    -75.57505930067235,\n",
       "    -70.09891674632519,\n",
       "    -47.80019945119438,\n",
       "    -69.87960175755151,\n",
       "    -48.73075645459568,\n",
       "    -61.761267829036214,\n",
       "    -95.73088590442056,\n",
       "    -62.26348097614151,\n",
       "    -64.3739851070154,\n",
       "    -63.18722263390181,\n",
       "    -50.30055069191858,\n",
       "    -50.13743271425375,\n",
       "    -65.01800314408617,\n",
       "    -63.67122023925452,\n",
       "    -53.57736589842809,\n",
       "    -72.9205160285787,\n",
       "    -67.31208271213991,\n",
       "    -80.27482194682995,\n",
       "    -45.95772658957363,\n",
       "    -70.79133117430331,\n",
       "    -92.56857493941283,\n",
       "    -64.81677121178208,\n",
       "    -63.359623753597134,\n",
       "    -64.98321364608017,\n",
       "    -73.74334662802676,\n",
       "    -85.90155196975344,\n",
       "    -69.66462393762308,\n",
       "    -65.70266726245701,\n",
       "    -64.09498243166912,\n",
       "    -69.24550448161992,\n",
       "    -64.01387654041024,\n",
       "    -64.18156995359281,\n",
       "    -67.86001343061182,\n",
       "    -64.73297431166246,\n",
       "    -56.44674381581356,\n",
       "    -95.00048752308457,\n",
       "    -93.6066862331683,\n",
       "    -70.78181313045624,\n",
       "    -70.10708492357445,\n",
       "    -95.19426424583779,\n",
       "    -65.24758327468132,\n",
       "    -67.6583952186906,\n",
       "    -72.17428065824768,\n",
       "    -64.89593054146704,\n",
       "    -40.29803021964885,\n",
       "    -67.01011935620723,\n",
       "    -45.182306559434345,\n",
       "    -64.80021721711493,\n",
       "    -69.13294859282678,\n",
       "    -68.21468301878362,\n",
       "    -62.27049864700586,\n",
       "    -39.94036466254375,\n",
       "    -61.58117458866526,\n",
       "    -69.00351958855732,\n",
       "    -58.52116640237598,\n",
       "    -71.12078275250525,\n",
       "    -67.3743058312665,\n",
       "    -67.90684934074542,\n",
       "    -62.5317097581885,\n",
       "    -65.60680154075843,\n",
       "    -71.09634204441326,\n",
       "    -73.88429402809844,\n",
       "    -78.04196321984904,\n",
       "    -58.76416789604828,\n",
       "    -59.43314264491439,\n",
       "    -65.34702797623386,\n",
       "    -102.75119362415712,\n",
       "    -64.48471753322755,\n",
       "    -50.5078039955346,\n",
       "    -62.83792162942318,\n",
       "    -71.75066629521443,\n",
       "    -72.12569537613282,\n",
       "    -70.40537822621887,\n",
       "    -66.57363880445412,\n",
       "    -64.35574858617187,\n",
       "    -67.50665442268466,\n",
       "    -45.98107060465112,\n",
       "    -78.01683544586696,\n",
       "    -46.970926982718915,\n",
       "    -99.63503459881807,\n",
       "    -67.85120713869414,\n",
       "    -64.81445648644333,\n",
       "    -67.54666813140108,\n",
       "    -64.03192961603963,\n",
       "    -52.24480965605071,\n",
       "    -68.69015267353001,\n",
       "    -69.6462927113179,\n",
       "    -64.292780964002,\n",
       "    -64.76766110953714,\n",
       "    -62.556208884016314,\n",
       "    -71.63408291650798,\n",
       "    -62.144160073156996,\n",
       "    -66.38086078040861,\n",
       "    -70.34748835106352,\n",
       "    -67.73664421900915],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22056609137266547,\n",
       "   'mean_inference_ms': 0.5805794876125391,\n",
       "   'mean_action_processing_ms': 0.07602851578791212,\n",
       "   'mean_env_wait_ms': 1.1323697659810572,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 130500,\n",
       "  'agent_timesteps_total': 130500,\n",
       "  'timers': {'learn_time_ms': 1.441, 'learn_throughput': 69383.534},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.587484,\n",
       "     'max_q': -3.5177736,\n",
       "     'min_q': -22.136492,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 130500,\n",
       "   'num_agent_steps_sampled': 130500,\n",
       "   'num_steps_trained': 12900100,\n",
       "   'num_agent_steps_trained': 12900100,\n",
       "   'last_target_update_ts': 130500,\n",
       "   'num_target_updates': 129001},\n",
       "  'done': False,\n",
       "  'episodes_total': 1292,\n",
       "  'training_iteration': 87,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-19-52',\n",
       "  'timestamp': 1625501992,\n",
       "  'time_this_iter_s': 20.702261924743652,\n",
       "  'time_total_s': 1734.838392496109,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1734.838392496109,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 87,\n",
       "  'perf': {'cpu_util_percent': 12.711538461538463,\n",
       "   'ram_util_percent': 48.56153846153846,\n",
       "   'gpu_util_percent0': 0.11807692307692307,\n",
       "   'vram_util_percent0': 0.4750211435202486}},\n",
       " {'episode_reward_max': -39.94036466254375,\n",
       "  'episode_reward_min': -102.75119362415712,\n",
       "  'episode_reward_mean': -67.05147097187556,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 14,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-63.18722263390181,\n",
       "    -50.30055069191858,\n",
       "    -50.13743271425375,\n",
       "    -65.01800314408617,\n",
       "    -63.67122023925452,\n",
       "    -53.57736589842809,\n",
       "    -72.9205160285787,\n",
       "    -67.31208271213991,\n",
       "    -80.27482194682995,\n",
       "    -45.95772658957363,\n",
       "    -70.79133117430331,\n",
       "    -92.56857493941283,\n",
       "    -64.81677121178208,\n",
       "    -63.359623753597134,\n",
       "    -64.98321364608017,\n",
       "    -73.74334662802676,\n",
       "    -85.90155196975344,\n",
       "    -69.66462393762308,\n",
       "    -65.70266726245701,\n",
       "    -64.09498243166912,\n",
       "    -69.24550448161992,\n",
       "    -64.01387654041024,\n",
       "    -64.18156995359281,\n",
       "    -67.86001343061182,\n",
       "    -64.73297431166246,\n",
       "    -56.44674381581356,\n",
       "    -95.00048752308457,\n",
       "    -93.6066862331683,\n",
       "    -70.78181313045624,\n",
       "    -70.10708492357445,\n",
       "    -95.19426424583779,\n",
       "    -65.24758327468132,\n",
       "    -67.6583952186906,\n",
       "    -72.17428065824768,\n",
       "    -64.89593054146704,\n",
       "    -40.29803021964885,\n",
       "    -67.01011935620723,\n",
       "    -45.182306559434345,\n",
       "    -64.80021721711493,\n",
       "    -69.13294859282678,\n",
       "    -68.21468301878362,\n",
       "    -62.27049864700586,\n",
       "    -39.94036466254375,\n",
       "    -61.58117458866526,\n",
       "    -69.00351958855732,\n",
       "    -58.52116640237598,\n",
       "    -71.12078275250525,\n",
       "    -67.3743058312665,\n",
       "    -67.90684934074542,\n",
       "    -62.5317097581885,\n",
       "    -65.60680154075843,\n",
       "    -71.09634204441326,\n",
       "    -73.88429402809844,\n",
       "    -78.04196321984904,\n",
       "    -58.76416789604828,\n",
       "    -59.43314264491439,\n",
       "    -65.34702797623386,\n",
       "    -102.75119362415712,\n",
       "    -64.48471753322755,\n",
       "    -50.5078039955346,\n",
       "    -62.83792162942318,\n",
       "    -71.75066629521443,\n",
       "    -72.12569537613282,\n",
       "    -70.40537822621887,\n",
       "    -66.57363880445412,\n",
       "    -64.35574858617187,\n",
       "    -67.50665442268466,\n",
       "    -45.98107060465112,\n",
       "    -78.01683544586696,\n",
       "    -46.970926982718915,\n",
       "    -99.63503459881807,\n",
       "    -67.85120713869414,\n",
       "    -64.81445648644333,\n",
       "    -67.54666813140108,\n",
       "    -64.03192961603963,\n",
       "    -52.24480965605071,\n",
       "    -68.69015267353001,\n",
       "    -69.6462927113179,\n",
       "    -64.292780964002,\n",
       "    -64.76766110953714,\n",
       "    -62.556208884016314,\n",
       "    -71.63408291650798,\n",
       "    -62.144160073156996,\n",
       "    -66.38086078040861,\n",
       "    -70.34748835106352,\n",
       "    -67.73664421900915,\n",
       "    -72.7364098362781,\n",
       "    -99.86887333410559,\n",
       "    -83.67282913131172,\n",
       "    -59.74629814528838,\n",
       "    -70.19345112092434,\n",
       "    -69.96742119742727,\n",
       "    -67.45480411490394,\n",
       "    -42.398710434267144,\n",
       "    -64.40324996117859,\n",
       "    -59.70395643077282,\n",
       "    -67.98507132344541,\n",
       "    -73.82265586020593,\n",
       "    -66.18443593856536,\n",
       "    -62.22698679965538],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22053334098220723,\n",
       "   'mean_inference_ms': 0.5807337920830464,\n",
       "   'mean_action_processing_ms': 0.07601449803883525,\n",
       "   'mean_env_wait_ms': 1.1321830231120777,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 132000,\n",
       "  'agent_timesteps_total': 132000,\n",
       "  'timers': {'learn_time_ms': 1.531, 'learn_throughput': 65316.577},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.562761,\n",
       "     'max_q': -3.83949,\n",
       "     'min_q': -21.056114,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 132000,\n",
       "   'num_agent_steps_sampled': 132000,\n",
       "   'num_steps_trained': 13050100,\n",
       "   'num_agent_steps_trained': 13050100,\n",
       "   'last_target_update_ts': 132000,\n",
       "   'num_target_updates': 130501},\n",
       "  'done': False,\n",
       "  'episodes_total': 1306,\n",
       "  'training_iteration': 88,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-20-13',\n",
       "  'timestamp': 1625502013,\n",
       "  'time_this_iter_s': 20.37974977493286,\n",
       "  'time_total_s': 1755.2181422710419,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1755.2181422710419,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 88,\n",
       "  'perf': {'cpu_util_percent': 12.585185185185185,\n",
       "   'ram_util_percent': 48.67777777777779,\n",
       "   'gpu_util_percent0': 0.1025925925925926,\n",
       "   'vram_util_percent0': 0.47039215129217693}},\n",
       " {'episode_reward_max': -39.94036466254375,\n",
       "  'episode_reward_min': -102.75119362415712,\n",
       "  'episode_reward_mean': -67.1348519434274,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-73.74334662802676,\n",
       "    -85.90155196975344,\n",
       "    -69.66462393762308,\n",
       "    -65.70266726245701,\n",
       "    -64.09498243166912,\n",
       "    -69.24550448161992,\n",
       "    -64.01387654041024,\n",
       "    -64.18156995359281,\n",
       "    -67.86001343061182,\n",
       "    -64.73297431166246,\n",
       "    -56.44674381581356,\n",
       "    -95.00048752308457,\n",
       "    -93.6066862331683,\n",
       "    -70.78181313045624,\n",
       "    -70.10708492357445,\n",
       "    -95.19426424583779,\n",
       "    -65.24758327468132,\n",
       "    -67.6583952186906,\n",
       "    -72.17428065824768,\n",
       "    -64.89593054146704,\n",
       "    -40.29803021964885,\n",
       "    -67.01011935620723,\n",
       "    -45.182306559434345,\n",
       "    -64.80021721711493,\n",
       "    -69.13294859282678,\n",
       "    -68.21468301878362,\n",
       "    -62.27049864700586,\n",
       "    -39.94036466254375,\n",
       "    -61.58117458866526,\n",
       "    -69.00351958855732,\n",
       "    -58.52116640237598,\n",
       "    -71.12078275250525,\n",
       "    -67.3743058312665,\n",
       "    -67.90684934074542,\n",
       "    -62.5317097581885,\n",
       "    -65.60680154075843,\n",
       "    -71.09634204441326,\n",
       "    -73.88429402809844,\n",
       "    -78.04196321984904,\n",
       "    -58.76416789604828,\n",
       "    -59.43314264491439,\n",
       "    -65.34702797623386,\n",
       "    -102.75119362415712,\n",
       "    -64.48471753322755,\n",
       "    -50.5078039955346,\n",
       "    -62.83792162942318,\n",
       "    -71.75066629521443,\n",
       "    -72.12569537613282,\n",
       "    -70.40537822621887,\n",
       "    -66.57363880445412,\n",
       "    -64.35574858617187,\n",
       "    -67.50665442268466,\n",
       "    -45.98107060465112,\n",
       "    -78.01683544586696,\n",
       "    -46.970926982718915,\n",
       "    -99.63503459881807,\n",
       "    -67.85120713869414,\n",
       "    -64.81445648644333,\n",
       "    -67.54666813140108,\n",
       "    -64.03192961603963,\n",
       "    -52.24480965605071,\n",
       "    -68.69015267353001,\n",
       "    -69.6462927113179,\n",
       "    -64.292780964002,\n",
       "    -64.76766110953714,\n",
       "    -62.556208884016314,\n",
       "    -71.63408291650798,\n",
       "    -62.144160073156996,\n",
       "    -66.38086078040861,\n",
       "    -70.34748835106352,\n",
       "    -67.73664421900915,\n",
       "    -72.7364098362781,\n",
       "    -99.86887333410559,\n",
       "    -83.67282913131172,\n",
       "    -59.74629814528838,\n",
       "    -70.19345112092434,\n",
       "    -69.96742119742727,\n",
       "    -67.45480411490394,\n",
       "    -42.398710434267144,\n",
       "    -64.40324996117859,\n",
       "    -59.70395643077282,\n",
       "    -67.98507132344541,\n",
       "    -73.82265586020593,\n",
       "    -66.18443593856536,\n",
       "    -62.22698679965538,\n",
       "    -63.10158171162635,\n",
       "    -67.17075529082855,\n",
       "    -65.72986636290314,\n",
       "    -47.33279674426912,\n",
       "    -69.12980349138586,\n",
       "    -78.08289514131333,\n",
       "    -58.59559165687302,\n",
       "    -66.82220817793923,\n",
       "    -71.80402305305398,\n",
       "    -71.25105821591795,\n",
       "    -70.08916403238635,\n",
       "    -64.71575881552985,\n",
       "    -67.82803850317548,\n",
       "    -67.004198268574,\n",
       "    -48.556815013548345],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2204979496272139,\n",
       "   'mean_inference_ms': 0.5808878728124544,\n",
       "   'mean_action_processing_ms': 0.07599954919663218,\n",
       "   'mean_env_wait_ms': 1.1319443715486104,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 133500,\n",
       "  'agent_timesteps_total': 133500,\n",
       "  'timers': {'learn_time_ms': 1.532, 'learn_throughput': 65291.158},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.524067,\n",
       "     'max_q': -5.3517914,\n",
       "     'min_q': -23.683853,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 133500,\n",
       "   'num_agent_steps_sampled': 133500,\n",
       "   'num_steps_trained': 13200100,\n",
       "   'num_agent_steps_trained': 13200100,\n",
       "   'last_target_update_ts': 133500,\n",
       "   'num_target_updates': 132001},\n",
       "  'done': False,\n",
       "  'episodes_total': 1321,\n",
       "  'training_iteration': 89,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-20-33',\n",
       "  'timestamp': 1625502033,\n",
       "  'time_this_iter_s': 20.7464497089386,\n",
       "  'time_total_s': 1775.9645919799805,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1775.9645919799805,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 89,\n",
       "  'perf': {'cpu_util_percent': 12.642307692307693,\n",
       "   'ram_util_percent': 48.70000000000001,\n",
       "   'gpu_util_percent0': 0.11153846153846156,\n",
       "   'vram_util_percent0': 0.4701728851562654}},\n",
       " {'episode_reward_max': -39.871897933038454,\n",
       "  'episode_reward_min': -102.75119362415712,\n",
       "  'episode_reward_mean': -66.4533730261464,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-95.19426424583779,\n",
       "    -65.24758327468132,\n",
       "    -67.6583952186906,\n",
       "    -72.17428065824768,\n",
       "    -64.89593054146704,\n",
       "    -40.29803021964885,\n",
       "    -67.01011935620723,\n",
       "    -45.182306559434345,\n",
       "    -64.80021721711493,\n",
       "    -69.13294859282678,\n",
       "    -68.21468301878362,\n",
       "    -62.27049864700586,\n",
       "    -39.94036466254375,\n",
       "    -61.58117458866526,\n",
       "    -69.00351958855732,\n",
       "    -58.52116640237598,\n",
       "    -71.12078275250525,\n",
       "    -67.3743058312665,\n",
       "    -67.90684934074542,\n",
       "    -62.5317097581885,\n",
       "    -65.60680154075843,\n",
       "    -71.09634204441326,\n",
       "    -73.88429402809844,\n",
       "    -78.04196321984904,\n",
       "    -58.76416789604828,\n",
       "    -59.43314264491439,\n",
       "    -65.34702797623386,\n",
       "    -102.75119362415712,\n",
       "    -64.48471753322755,\n",
       "    -50.5078039955346,\n",
       "    -62.83792162942318,\n",
       "    -71.75066629521443,\n",
       "    -72.12569537613282,\n",
       "    -70.40537822621887,\n",
       "    -66.57363880445412,\n",
       "    -64.35574858617187,\n",
       "    -67.50665442268466,\n",
       "    -45.98107060465112,\n",
       "    -78.01683544586696,\n",
       "    -46.970926982718915,\n",
       "    -99.63503459881807,\n",
       "    -67.85120713869414,\n",
       "    -64.81445648644333,\n",
       "    -67.54666813140108,\n",
       "    -64.03192961603963,\n",
       "    -52.24480965605071,\n",
       "    -68.69015267353001,\n",
       "    -69.6462927113179,\n",
       "    -64.292780964002,\n",
       "    -64.76766110953714,\n",
       "    -62.556208884016314,\n",
       "    -71.63408291650798,\n",
       "    -62.144160073156996,\n",
       "    -66.38086078040861,\n",
       "    -70.34748835106352,\n",
       "    -67.73664421900915,\n",
       "    -72.7364098362781,\n",
       "    -99.86887333410559,\n",
       "    -83.67282913131172,\n",
       "    -59.74629814528838,\n",
       "    -70.19345112092434,\n",
       "    -69.96742119742727,\n",
       "    -67.45480411490394,\n",
       "    -42.398710434267144,\n",
       "    -64.40324996117859,\n",
       "    -59.70395643077282,\n",
       "    -67.98507132344541,\n",
       "    -73.82265586020593,\n",
       "    -66.18443593856536,\n",
       "    -62.22698679965538,\n",
       "    -63.10158171162635,\n",
       "    -67.17075529082855,\n",
       "    -65.72986636290314,\n",
       "    -47.33279674426912,\n",
       "    -69.12980349138586,\n",
       "    -78.08289514131333,\n",
       "    -58.59559165687302,\n",
       "    -66.82220817793923,\n",
       "    -71.80402305305398,\n",
       "    -71.25105821591795,\n",
       "    -70.08916403238635,\n",
       "    -64.71575881552985,\n",
       "    -67.82803850317548,\n",
       "    -67.004198268574,\n",
       "    -48.556815013548345,\n",
       "    -57.943431725785956,\n",
       "    -61.970524706302044,\n",
       "    -63.78456088119094,\n",
       "    -69.49789425452582,\n",
       "    -76.19256405881956,\n",
       "    -88.55554045440293,\n",
       "    -74.71389577290165,\n",
       "    -68.8748747277817,\n",
       "    -66.46391926268564,\n",
       "    -84.66604947958992,\n",
       "    -51.22772656367775,\n",
       "    -72.07465088919146,\n",
       "    -39.871897933038454,\n",
       "    -69.51552593695924,\n",
       "    -61.582978198568334],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2204756972667083,\n",
       "   'mean_inference_ms': 0.5811453042243377,\n",
       "   'mean_action_processing_ms': 0.07599170834800201,\n",
       "   'mean_env_wait_ms': 1.1317763483749508,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 135000,\n",
       "  'agent_timesteps_total': 135000,\n",
       "  'timers': {'learn_time_ms': 1.55, 'learn_throughput': 64496.994},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.512478,\n",
       "     'max_q': -3.6001763,\n",
       "     'min_q': -21.740255,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 135000,\n",
       "   'num_agent_steps_sampled': 135000,\n",
       "   'num_steps_trained': 13350100,\n",
       "   'num_agent_steps_trained': 13350100,\n",
       "   'last_target_update_ts': 135000,\n",
       "   'num_target_updates': 133501},\n",
       "  'done': False,\n",
       "  'episodes_total': 1336,\n",
       "  'training_iteration': 90,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-20-55',\n",
       "  'timestamp': 1625502055,\n",
       "  'time_this_iter_s': 21.248408794403076,\n",
       "  'time_total_s': 1797.2130007743835,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1797.2130007743835,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 90,\n",
       "  'perf': {'cpu_util_percent': 13.72222222222222,\n",
       "   'ram_util_percent': 48.77777777777777,\n",
       "   'gpu_util_percent0': 0.15148148148148152,\n",
       "   'vram_util_percent0': 0.4720588653086735}},\n",
       " {'episode_reward_max': -39.871897933038454,\n",
       "  'episode_reward_min': -102.75119362415712,\n",
       "  'episode_reward_mean': -67.39165164173797,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-58.52116640237598,\n",
       "    -71.12078275250525,\n",
       "    -67.3743058312665,\n",
       "    -67.90684934074542,\n",
       "    -62.5317097581885,\n",
       "    -65.60680154075843,\n",
       "    -71.09634204441326,\n",
       "    -73.88429402809844,\n",
       "    -78.04196321984904,\n",
       "    -58.76416789604828,\n",
       "    -59.43314264491439,\n",
       "    -65.34702797623386,\n",
       "    -102.75119362415712,\n",
       "    -64.48471753322755,\n",
       "    -50.5078039955346,\n",
       "    -62.83792162942318,\n",
       "    -71.75066629521443,\n",
       "    -72.12569537613282,\n",
       "    -70.40537822621887,\n",
       "    -66.57363880445412,\n",
       "    -64.35574858617187,\n",
       "    -67.50665442268466,\n",
       "    -45.98107060465112,\n",
       "    -78.01683544586696,\n",
       "    -46.970926982718915,\n",
       "    -99.63503459881807,\n",
       "    -67.85120713869414,\n",
       "    -64.81445648644333,\n",
       "    -67.54666813140108,\n",
       "    -64.03192961603963,\n",
       "    -52.24480965605071,\n",
       "    -68.69015267353001,\n",
       "    -69.6462927113179,\n",
       "    -64.292780964002,\n",
       "    -64.76766110953714,\n",
       "    -62.556208884016314,\n",
       "    -71.63408291650798,\n",
       "    -62.144160073156996,\n",
       "    -66.38086078040861,\n",
       "    -70.34748835106352,\n",
       "    -67.73664421900915,\n",
       "    -72.7364098362781,\n",
       "    -99.86887333410559,\n",
       "    -83.67282913131172,\n",
       "    -59.74629814528838,\n",
       "    -70.19345112092434,\n",
       "    -69.96742119742727,\n",
       "    -67.45480411490394,\n",
       "    -42.398710434267144,\n",
       "    -64.40324996117859,\n",
       "    -59.70395643077282,\n",
       "    -67.98507132344541,\n",
       "    -73.82265586020593,\n",
       "    -66.18443593856536,\n",
       "    -62.22698679965538,\n",
       "    -63.10158171162635,\n",
       "    -67.17075529082855,\n",
       "    -65.72986636290314,\n",
       "    -47.33279674426912,\n",
       "    -69.12980349138586,\n",
       "    -78.08289514131333,\n",
       "    -58.59559165687302,\n",
       "    -66.82220817793923,\n",
       "    -71.80402305305398,\n",
       "    -71.25105821591795,\n",
       "    -70.08916403238635,\n",
       "    -64.71575881552985,\n",
       "    -67.82803850317548,\n",
       "    -67.004198268574,\n",
       "    -48.556815013548345,\n",
       "    -57.943431725785956,\n",
       "    -61.970524706302044,\n",
       "    -63.78456088119094,\n",
       "    -69.49789425452582,\n",
       "    -76.19256405881956,\n",
       "    -88.55554045440293,\n",
       "    -74.71389577290165,\n",
       "    -68.8748747277817,\n",
       "    -66.46391926268564,\n",
       "    -84.66604947958992,\n",
       "    -51.22772656367775,\n",
       "    -72.07465088919146,\n",
       "    -39.871897933038454,\n",
       "    -69.51552593695924,\n",
       "    -61.582978198568334,\n",
       "    -65.94306278662113,\n",
       "    -74.82205390462627,\n",
       "    -52.179320475057416,\n",
       "    -79.93184192152323,\n",
       "    -66.8804829502741,\n",
       "    -72.50507945555879,\n",
       "    -99.19663684033787,\n",
       "    -84.68309213651733,\n",
       "    -65.32604180911085,\n",
       "    -67.71026887156025,\n",
       "    -62.158831394804984,\n",
       "    -65.45006236000623,\n",
       "    -68.98710186272389,\n",
       "    -42.95662405279316,\n",
       "    -77.70167712735545],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22045644860247798,\n",
       "   'mean_inference_ms': 0.5814346603313291,\n",
       "   'mean_action_processing_ms': 0.0759853449715064,\n",
       "   'mean_env_wait_ms': 1.1318256122573498,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 136500,\n",
       "  'agent_timesteps_total': 136500,\n",
       "  'timers': {'learn_time_ms': 1.419, 'learn_throughput': 70493.689},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.693042,\n",
       "     'max_q': -3.9136114,\n",
       "     'min_q': -20.082714,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 136500,\n",
       "   'num_agent_steps_sampled': 136500,\n",
       "   'num_steps_trained': 13500100,\n",
       "   'num_agent_steps_trained': 13500100,\n",
       "   'last_target_update_ts': 136500,\n",
       "   'num_target_updates': 135001},\n",
       "  'done': False,\n",
       "  'episodes_total': 1351,\n",
       "  'training_iteration': 91,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-21-15',\n",
       "  'timestamp': 1625502075,\n",
       "  'time_this_iter_s': 20.649832010269165,\n",
       "  'time_total_s': 1817.8628327846527,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1817.8628327846527,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 91,\n",
       "  'perf': {'cpu_util_percent': 12.303703703703706,\n",
       "   'ram_util_percent': 48.79999999999999,\n",
       "   'gpu_util_percent0': 0.09703703703703702,\n",
       "   'vram_util_percent0': 0.47381080901919576}},\n",
       " {'episode_reward_max': -39.871897933038454,\n",
       "  'episode_reward_min': -99.86887333410559,\n",
       "  'episode_reward_mean': -67.14845121527296,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-62.83792162942318,\n",
       "    -71.75066629521443,\n",
       "    -72.12569537613282,\n",
       "    -70.40537822621887,\n",
       "    -66.57363880445412,\n",
       "    -64.35574858617187,\n",
       "    -67.50665442268466,\n",
       "    -45.98107060465112,\n",
       "    -78.01683544586696,\n",
       "    -46.970926982718915,\n",
       "    -99.63503459881807,\n",
       "    -67.85120713869414,\n",
       "    -64.81445648644333,\n",
       "    -67.54666813140108,\n",
       "    -64.03192961603963,\n",
       "    -52.24480965605071,\n",
       "    -68.69015267353001,\n",
       "    -69.6462927113179,\n",
       "    -64.292780964002,\n",
       "    -64.76766110953714,\n",
       "    -62.556208884016314,\n",
       "    -71.63408291650798,\n",
       "    -62.144160073156996,\n",
       "    -66.38086078040861,\n",
       "    -70.34748835106352,\n",
       "    -67.73664421900915,\n",
       "    -72.7364098362781,\n",
       "    -99.86887333410559,\n",
       "    -83.67282913131172,\n",
       "    -59.74629814528838,\n",
       "    -70.19345112092434,\n",
       "    -69.96742119742727,\n",
       "    -67.45480411490394,\n",
       "    -42.398710434267144,\n",
       "    -64.40324996117859,\n",
       "    -59.70395643077282,\n",
       "    -67.98507132344541,\n",
       "    -73.82265586020593,\n",
       "    -66.18443593856536,\n",
       "    -62.22698679965538,\n",
       "    -63.10158171162635,\n",
       "    -67.17075529082855,\n",
       "    -65.72986636290314,\n",
       "    -47.33279674426912,\n",
       "    -69.12980349138586,\n",
       "    -78.08289514131333,\n",
       "    -58.59559165687302,\n",
       "    -66.82220817793923,\n",
       "    -71.80402305305398,\n",
       "    -71.25105821591795,\n",
       "    -70.08916403238635,\n",
       "    -64.71575881552985,\n",
       "    -67.82803850317548,\n",
       "    -67.004198268574,\n",
       "    -48.556815013548345,\n",
       "    -57.943431725785956,\n",
       "    -61.970524706302044,\n",
       "    -63.78456088119094,\n",
       "    -69.49789425452582,\n",
       "    -76.19256405881956,\n",
       "    -88.55554045440293,\n",
       "    -74.71389577290165,\n",
       "    -68.8748747277817,\n",
       "    -66.46391926268564,\n",
       "    -84.66604947958992,\n",
       "    -51.22772656367775,\n",
       "    -72.07465088919146,\n",
       "    -39.871897933038454,\n",
       "    -69.51552593695924,\n",
       "    -61.582978198568334,\n",
       "    -65.94306278662113,\n",
       "    -74.82205390462627,\n",
       "    -52.179320475057416,\n",
       "    -79.93184192152323,\n",
       "    -66.8804829502741,\n",
       "    -72.50507945555879,\n",
       "    -99.19663684033787,\n",
       "    -84.68309213651733,\n",
       "    -65.32604180911085,\n",
       "    -67.71026887156025,\n",
       "    -62.158831394804984,\n",
       "    -65.45006236000623,\n",
       "    -68.98710186272389,\n",
       "    -42.95662405279316,\n",
       "    -77.70167712735545,\n",
       "    -50.094527439623334,\n",
       "    -71.17160469813541,\n",
       "    -68.39457478577283,\n",
       "    -65.7181604498476,\n",
       "    -72.34883792641396,\n",
       "    -58.082324444511634,\n",
       "    -64.11864736696673,\n",
       "    -66.78008028527726,\n",
       "    -68.56965016487212,\n",
       "    -67.10102223516017,\n",
       "    -66.65682640251903,\n",
       "    -67.87626636452353,\n",
       "    -62.87547018580804,\n",
       "    -75.59651594770818,\n",
       "    -67.66771724467624],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22043961199850975,\n",
       "   'mean_inference_ms': 0.5817027949585756,\n",
       "   'mean_action_processing_ms': 0.07597783613127784,\n",
       "   'mean_env_wait_ms': 1.132172368371084,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 138000,\n",
       "  'agent_timesteps_total': 138000,\n",
       "  'timers': {'learn_time_ms': 1.449, 'learn_throughput': 69029.542},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -12.919765,\n",
       "     'max_q': -4.12698,\n",
       "     'min_q': -22.191036,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 138000,\n",
       "   'num_agent_steps_sampled': 138000,\n",
       "   'num_steps_trained': 13650100,\n",
       "   'num_agent_steps_trained': 13650100,\n",
       "   'last_target_update_ts': 138000,\n",
       "   'num_target_updates': 136501},\n",
       "  'done': False,\n",
       "  'episodes_total': 1366,\n",
       "  'training_iteration': 92,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-21-36',\n",
       "  'timestamp': 1625502096,\n",
       "  'time_this_iter_s': 20.529109954833984,\n",
       "  'time_total_s': 1838.3919427394867,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1838.3919427394867,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 92,\n",
       "  'perf': {'cpu_util_percent': 12.319230769230767,\n",
       "   'ram_util_percent': 48.86538461538461,\n",
       "   'gpu_util_percent0': 0.09884615384615382,\n",
       "   'vram_util_percent0': 0.4736345219597585}},\n",
       " {'episode_reward_max': -39.871897933038454,\n",
       "  'episode_reward_min': -99.86887333410559,\n",
       "  'episode_reward_mean': -67.12313906921139,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-52.24480965605071,\n",
       "    -68.69015267353001,\n",
       "    -69.6462927113179,\n",
       "    -64.292780964002,\n",
       "    -64.76766110953714,\n",
       "    -62.556208884016314,\n",
       "    -71.63408291650798,\n",
       "    -62.144160073156996,\n",
       "    -66.38086078040861,\n",
       "    -70.34748835106352,\n",
       "    -67.73664421900915,\n",
       "    -72.7364098362781,\n",
       "    -99.86887333410559,\n",
       "    -83.67282913131172,\n",
       "    -59.74629814528838,\n",
       "    -70.19345112092434,\n",
       "    -69.96742119742727,\n",
       "    -67.45480411490394,\n",
       "    -42.398710434267144,\n",
       "    -64.40324996117859,\n",
       "    -59.70395643077282,\n",
       "    -67.98507132344541,\n",
       "    -73.82265586020593,\n",
       "    -66.18443593856536,\n",
       "    -62.22698679965538,\n",
       "    -63.10158171162635,\n",
       "    -67.17075529082855,\n",
       "    -65.72986636290314,\n",
       "    -47.33279674426912,\n",
       "    -69.12980349138586,\n",
       "    -78.08289514131333,\n",
       "    -58.59559165687302,\n",
       "    -66.82220817793923,\n",
       "    -71.80402305305398,\n",
       "    -71.25105821591795,\n",
       "    -70.08916403238635,\n",
       "    -64.71575881552985,\n",
       "    -67.82803850317548,\n",
       "    -67.004198268574,\n",
       "    -48.556815013548345,\n",
       "    -57.943431725785956,\n",
       "    -61.970524706302044,\n",
       "    -63.78456088119094,\n",
       "    -69.49789425452582,\n",
       "    -76.19256405881956,\n",
       "    -88.55554045440293,\n",
       "    -74.71389577290165,\n",
       "    -68.8748747277817,\n",
       "    -66.46391926268564,\n",
       "    -84.66604947958992,\n",
       "    -51.22772656367775,\n",
       "    -72.07465088919146,\n",
       "    -39.871897933038454,\n",
       "    -69.51552593695924,\n",
       "    -61.582978198568334,\n",
       "    -65.94306278662113,\n",
       "    -74.82205390462627,\n",
       "    -52.179320475057416,\n",
       "    -79.93184192152323,\n",
       "    -66.8804829502741,\n",
       "    -72.50507945555879,\n",
       "    -99.19663684033787,\n",
       "    -84.68309213651733,\n",
       "    -65.32604180911085,\n",
       "    -67.71026887156025,\n",
       "    -62.158831394804984,\n",
       "    -65.45006236000623,\n",
       "    -68.98710186272389,\n",
       "    -42.95662405279316,\n",
       "    -77.70167712735545,\n",
       "    -50.094527439623334,\n",
       "    -71.17160469813541,\n",
       "    -68.39457478577283,\n",
       "    -65.7181604498476,\n",
       "    -72.34883792641396,\n",
       "    -58.082324444511634,\n",
       "    -64.11864736696673,\n",
       "    -66.78008028527726,\n",
       "    -68.56965016487212,\n",
       "    -67.10102223516017,\n",
       "    -66.65682640251903,\n",
       "    -67.87626636452353,\n",
       "    -62.87547018580804,\n",
       "    -75.59651594770818,\n",
       "    -67.66771724467624,\n",
       "    -62.07655811892277,\n",
       "    -68.02884287625731,\n",
       "    -56.81950486321733,\n",
       "    -70.82758405064298,\n",
       "    -68.8300953710209,\n",
       "    -66.32934740355135,\n",
       "    -73.81472444810191,\n",
       "    -64.45427348786903,\n",
       "    -67.1244021174828,\n",
       "    -64.22294869743547,\n",
       "    -67.19425533524833,\n",
       "    -65.26871357908263,\n",
       "    -66.80925357123846,\n",
       "    -76.5389582872134,\n",
       "    -69.53315553149045],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22042349556573895,\n",
       "   'mean_inference_ms': 0.5819532406766642,\n",
       "   'mean_action_processing_ms': 0.07597213337478845,\n",
       "   'mean_env_wait_ms': 1.1326027172380468,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 139500,\n",
       "  'agent_timesteps_total': 139500,\n",
       "  'timers': {'learn_time_ms': 1.491, 'learn_throughput': 67063.797},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.752398,\n",
       "     'max_q': -5.4318466,\n",
       "     'min_q': -21.219843,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 139500,\n",
       "   'num_agent_steps_sampled': 139500,\n",
       "   'num_steps_trained': 13800100,\n",
       "   'num_agent_steps_trained': 13800100,\n",
       "   'last_target_update_ts': 139500,\n",
       "   'num_target_updates': 138001},\n",
       "  'done': False,\n",
       "  'episodes_total': 1381,\n",
       "  'training_iteration': 93,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-21-57',\n",
       "  'timestamp': 1625502117,\n",
       "  'time_this_iter_s': 21.123704195022583,\n",
       "  'time_total_s': 1859.5156469345093,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1859.5156469345093,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 93,\n",
       "  'perf': {'cpu_util_percent': 12.570370370370368,\n",
       "   'ram_util_percent': 48.900000000000006,\n",
       "   'gpu_util_percent0': 0.10222222222222223,\n",
       "   'vram_util_percent0': 0.473479360209097}},\n",
       " {'episode_reward_max': -39.871897933038454,\n",
       "  'episode_reward_min': -99.19663684033787,\n",
       "  'episode_reward_mean': -67.09336421929649,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-70.19345112092434,\n",
       "    -69.96742119742727,\n",
       "    -67.45480411490394,\n",
       "    -42.398710434267144,\n",
       "    -64.40324996117859,\n",
       "    -59.70395643077282,\n",
       "    -67.98507132344541,\n",
       "    -73.82265586020593,\n",
       "    -66.18443593856536,\n",
       "    -62.22698679965538,\n",
       "    -63.10158171162635,\n",
       "    -67.17075529082855,\n",
       "    -65.72986636290314,\n",
       "    -47.33279674426912,\n",
       "    -69.12980349138586,\n",
       "    -78.08289514131333,\n",
       "    -58.59559165687302,\n",
       "    -66.82220817793923,\n",
       "    -71.80402305305398,\n",
       "    -71.25105821591795,\n",
       "    -70.08916403238635,\n",
       "    -64.71575881552985,\n",
       "    -67.82803850317548,\n",
       "    -67.004198268574,\n",
       "    -48.556815013548345,\n",
       "    -57.943431725785956,\n",
       "    -61.970524706302044,\n",
       "    -63.78456088119094,\n",
       "    -69.49789425452582,\n",
       "    -76.19256405881956,\n",
       "    -88.55554045440293,\n",
       "    -74.71389577290165,\n",
       "    -68.8748747277817,\n",
       "    -66.46391926268564,\n",
       "    -84.66604947958992,\n",
       "    -51.22772656367775,\n",
       "    -72.07465088919146,\n",
       "    -39.871897933038454,\n",
       "    -69.51552593695924,\n",
       "    -61.582978198568334,\n",
       "    -65.94306278662113,\n",
       "    -74.82205390462627,\n",
       "    -52.179320475057416,\n",
       "    -79.93184192152323,\n",
       "    -66.8804829502741,\n",
       "    -72.50507945555879,\n",
       "    -99.19663684033787,\n",
       "    -84.68309213651733,\n",
       "    -65.32604180911085,\n",
       "    -67.71026887156025,\n",
       "    -62.158831394804984,\n",
       "    -65.45006236000623,\n",
       "    -68.98710186272389,\n",
       "    -42.95662405279316,\n",
       "    -77.70167712735545,\n",
       "    -50.094527439623334,\n",
       "    -71.17160469813541,\n",
       "    -68.39457478577283,\n",
       "    -65.7181604498476,\n",
       "    -72.34883792641396,\n",
       "    -58.082324444511634,\n",
       "    -64.11864736696673,\n",
       "    -66.78008028527726,\n",
       "    -68.56965016487212,\n",
       "    -67.10102223516017,\n",
       "    -66.65682640251903,\n",
       "    -67.87626636452353,\n",
       "    -62.87547018580804,\n",
       "    -75.59651594770818,\n",
       "    -67.66771724467624,\n",
       "    -62.07655811892277,\n",
       "    -68.02884287625731,\n",
       "    -56.81950486321733,\n",
       "    -70.82758405064298,\n",
       "    -68.8300953710209,\n",
       "    -66.32934740355135,\n",
       "    -73.81472444810191,\n",
       "    -64.45427348786903,\n",
       "    -67.1244021174828,\n",
       "    -64.22294869743547,\n",
       "    -67.19425533524833,\n",
       "    -65.26871357908263,\n",
       "    -66.80925357123846,\n",
       "    -76.5389582872134,\n",
       "    -69.53315553149045,\n",
       "    -59.19015629941167,\n",
       "    -67.83908092742982,\n",
       "    -85.89685285350107,\n",
       "    -72.34513777824918,\n",
       "    -72.71320626635777,\n",
       "    -69.23450231942785,\n",
       "    -62.310842765751175,\n",
       "    -93.20710848776974,\n",
       "    -58.95634173815677,\n",
       "    -46.0082361303177,\n",
       "    -74.20071751093421,\n",
       "    -68.84320743858859,\n",
       "    -69.95413036059932,\n",
       "    -63.99906869019352,\n",
       "    -68.78947822740632],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.2204092160563729,\n",
       "   'mean_inference_ms': 0.5822054330972086,\n",
       "   'mean_action_processing_ms': 0.07596817227491842,\n",
       "   'mean_env_wait_ms': 1.1329689694177956,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 141000,\n",
       "  'agent_timesteps_total': 141000,\n",
       "  'timers': {'learn_time_ms': 1.417, 'learn_throughput': 70593.352},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.417123,\n",
       "     'max_q': -5.1495705,\n",
       "     'min_q': -21.419085,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 141000,\n",
       "   'num_agent_steps_sampled': 141000,\n",
       "   'num_steps_trained': 13950100,\n",
       "   'num_agent_steps_trained': 13950100,\n",
       "   'last_target_update_ts': 141000,\n",
       "   'num_target_updates': 139501},\n",
       "  'done': False,\n",
       "  'episodes_total': 1396,\n",
       "  'training_iteration': 94,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-22-18',\n",
       "  'timestamp': 1625502138,\n",
       "  'time_this_iter_s': 20.88617706298828,\n",
       "  'time_total_s': 1880.4018239974976,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1880.4018239974976,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 94,\n",
       "  'perf': {'cpu_util_percent': 12.522222222222224,\n",
       "   'ram_util_percent': 48.922222222222224,\n",
       "   'gpu_util_percent0': 0.12518518518518518,\n",
       "   'vram_util_percent0': 0.47372557932517023}},\n",
       " {'episode_reward_max': -39.871897933038454,\n",
       "  'episode_reward_min': -99.19663684033787,\n",
       "  'episode_reward_mean': -67.75722867524519,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 14,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-69.12980349138586,\n",
       "    -78.08289514131333,\n",
       "    -58.59559165687302,\n",
       "    -66.82220817793923,\n",
       "    -71.80402305305398,\n",
       "    -71.25105821591795,\n",
       "    -70.08916403238635,\n",
       "    -64.71575881552985,\n",
       "    -67.82803850317548,\n",
       "    -67.004198268574,\n",
       "    -48.556815013548345,\n",
       "    -57.943431725785956,\n",
       "    -61.970524706302044,\n",
       "    -63.78456088119094,\n",
       "    -69.49789425452582,\n",
       "    -76.19256405881956,\n",
       "    -88.55554045440293,\n",
       "    -74.71389577290165,\n",
       "    -68.8748747277817,\n",
       "    -66.46391926268564,\n",
       "    -84.66604947958992,\n",
       "    -51.22772656367775,\n",
       "    -72.07465088919146,\n",
       "    -39.871897933038454,\n",
       "    -69.51552593695924,\n",
       "    -61.582978198568334,\n",
       "    -65.94306278662113,\n",
       "    -74.82205390462627,\n",
       "    -52.179320475057416,\n",
       "    -79.93184192152323,\n",
       "    -66.8804829502741,\n",
       "    -72.50507945555879,\n",
       "    -99.19663684033787,\n",
       "    -84.68309213651733,\n",
       "    -65.32604180911085,\n",
       "    -67.71026887156025,\n",
       "    -62.158831394804984,\n",
       "    -65.45006236000623,\n",
       "    -68.98710186272389,\n",
       "    -42.95662405279316,\n",
       "    -77.70167712735545,\n",
       "    -50.094527439623334,\n",
       "    -71.17160469813541,\n",
       "    -68.39457478577283,\n",
       "    -65.7181604498476,\n",
       "    -72.34883792641396,\n",
       "    -58.082324444511634,\n",
       "    -64.11864736696673,\n",
       "    -66.78008028527726,\n",
       "    -68.56965016487212,\n",
       "    -67.10102223516017,\n",
       "    -66.65682640251903,\n",
       "    -67.87626636452353,\n",
       "    -62.87547018580804,\n",
       "    -75.59651594770818,\n",
       "    -67.66771724467624,\n",
       "    -62.07655811892277,\n",
       "    -68.02884287625731,\n",
       "    -56.81950486321733,\n",
       "    -70.82758405064298,\n",
       "    -68.8300953710209,\n",
       "    -66.32934740355135,\n",
       "    -73.81472444810191,\n",
       "    -64.45427348786903,\n",
       "    -67.1244021174828,\n",
       "    -64.22294869743547,\n",
       "    -67.19425533524833,\n",
       "    -65.26871357908263,\n",
       "    -66.80925357123846,\n",
       "    -76.5389582872134,\n",
       "    -69.53315553149045,\n",
       "    -59.19015629941167,\n",
       "    -67.83908092742982,\n",
       "    -85.89685285350107,\n",
       "    -72.34513777824918,\n",
       "    -72.71320626635777,\n",
       "    -69.23450231942785,\n",
       "    -62.310842765751175,\n",
       "    -93.20710848776974,\n",
       "    -58.95634173815677,\n",
       "    -46.0082361303177,\n",
       "    -74.20071751093421,\n",
       "    -68.84320743858859,\n",
       "    -69.95413036059932,\n",
       "    -63.99906869019352,\n",
       "    -68.78947822740632,\n",
       "    -79.11870739500677,\n",
       "    -65.230471304254,\n",
       "    -65.1290970617845,\n",
       "    -72.29081783444398,\n",
       "    -70.36924673267713,\n",
       "    -67.02815321978645,\n",
       "    -63.07790765840881,\n",
       "    -66.13947403204122,\n",
       "    -69.27822890087539,\n",
       "    -70.383473560302,\n",
       "    -42.110770465654625,\n",
       "    -67.9640902641894,\n",
       "    -68.0792869698613,\n",
       "    -87.86246348655735],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22040164004892404,\n",
       "   'mean_inference_ms': 0.5824635504998648,\n",
       "   'mean_action_processing_ms': 0.07596737551106976,\n",
       "   'mean_env_wait_ms': 1.133480642246048,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 142500,\n",
       "  'agent_timesteps_total': 142500,\n",
       "  'timers': {'learn_time_ms': 1.365, 'learn_throughput': 73270.631},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.099646,\n",
       "     'max_q': -4.209894,\n",
       "     'min_q': -22.313961,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 142500,\n",
       "   'num_agent_steps_sampled': 142500,\n",
       "   'num_steps_trained': 14100100,\n",
       "   'num_agent_steps_trained': 14100100,\n",
       "   'last_target_update_ts': 142500,\n",
       "   'num_target_updates': 141001},\n",
       "  'done': False,\n",
       "  'episodes_total': 1410,\n",
       "  'training_iteration': 95,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-22-39',\n",
       "  'timestamp': 1625502159,\n",
       "  'time_this_iter_s': 20.990960359573364,\n",
       "  'time_total_s': 1901.392784357071,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1901.392784357071,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 95,\n",
       "  'perf': {'cpu_util_percent': 12.68148148148148,\n",
       "   'ram_util_percent': 49.0,\n",
       "   'gpu_util_percent0': 0.11851851851851852,\n",
       "   'vram_util_percent0': 0.47185999602261436}},\n",
       " {'episode_reward_max': -37.26297785457169,\n",
       "  'episode_reward_min': -99.19663684033787,\n",
       "  'episode_reward_mean': -67.47146026172402,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-76.19256405881956,\n",
       "    -88.55554045440293,\n",
       "    -74.71389577290165,\n",
       "    -68.8748747277817,\n",
       "    -66.46391926268564,\n",
       "    -84.66604947958992,\n",
       "    -51.22772656367775,\n",
       "    -72.07465088919146,\n",
       "    -39.871897933038454,\n",
       "    -69.51552593695924,\n",
       "    -61.582978198568334,\n",
       "    -65.94306278662113,\n",
       "    -74.82205390462627,\n",
       "    -52.179320475057416,\n",
       "    -79.93184192152323,\n",
       "    -66.8804829502741,\n",
       "    -72.50507945555879,\n",
       "    -99.19663684033787,\n",
       "    -84.68309213651733,\n",
       "    -65.32604180911085,\n",
       "    -67.71026887156025,\n",
       "    -62.158831394804984,\n",
       "    -65.45006236000623,\n",
       "    -68.98710186272389,\n",
       "    -42.95662405279316,\n",
       "    -77.70167712735545,\n",
       "    -50.094527439623334,\n",
       "    -71.17160469813541,\n",
       "    -68.39457478577283,\n",
       "    -65.7181604498476,\n",
       "    -72.34883792641396,\n",
       "    -58.082324444511634,\n",
       "    -64.11864736696673,\n",
       "    -66.78008028527726,\n",
       "    -68.56965016487212,\n",
       "    -67.10102223516017,\n",
       "    -66.65682640251903,\n",
       "    -67.87626636452353,\n",
       "    -62.87547018580804,\n",
       "    -75.59651594770818,\n",
       "    -67.66771724467624,\n",
       "    -62.07655811892277,\n",
       "    -68.02884287625731,\n",
       "    -56.81950486321733,\n",
       "    -70.82758405064298,\n",
       "    -68.8300953710209,\n",
       "    -66.32934740355135,\n",
       "    -73.81472444810191,\n",
       "    -64.45427348786903,\n",
       "    -67.1244021174828,\n",
       "    -64.22294869743547,\n",
       "    -67.19425533524833,\n",
       "    -65.26871357908263,\n",
       "    -66.80925357123846,\n",
       "    -76.5389582872134,\n",
       "    -69.53315553149045,\n",
       "    -59.19015629941167,\n",
       "    -67.83908092742982,\n",
       "    -85.89685285350107,\n",
       "    -72.34513777824918,\n",
       "    -72.71320626635777,\n",
       "    -69.23450231942785,\n",
       "    -62.310842765751175,\n",
       "    -93.20710848776974,\n",
       "    -58.95634173815677,\n",
       "    -46.0082361303177,\n",
       "    -74.20071751093421,\n",
       "    -68.84320743858859,\n",
       "    -69.95413036059932,\n",
       "    -63.99906869019352,\n",
       "    -68.78947822740632,\n",
       "    -79.11870739500677,\n",
       "    -65.230471304254,\n",
       "    -65.1290970617845,\n",
       "    -72.29081783444398,\n",
       "    -70.36924673267713,\n",
       "    -67.02815321978645,\n",
       "    -63.07790765840881,\n",
       "    -66.13947403204122,\n",
       "    -69.27822890087539,\n",
       "    -70.383473560302,\n",
       "    -42.110770465654625,\n",
       "    -67.9640902641894,\n",
       "    -68.0792869698613,\n",
       "    -87.86246348655735,\n",
       "    -71.3907574259973,\n",
       "    -56.95453630430934,\n",
       "    -44.17055455886252,\n",
       "    -69.88934512030842,\n",
       "    -68.80273895322918,\n",
       "    -77.27559330246012,\n",
       "    -69.89246829252644,\n",
       "    -61.74832782413638,\n",
       "    -66.80304548254752,\n",
       "    -73.77718266011003,\n",
       "    -76.5347124556839,\n",
       "    -71.69120235439318,\n",
       "    -48.88566552570263,\n",
       "    -37.26297785457169,\n",
       "    -63.420016470547495],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22038900017429405,\n",
       "   'mean_inference_ms': 0.5828758264337774,\n",
       "   'mean_action_processing_ms': 0.07596640472538473,\n",
       "   'mean_env_wait_ms': 1.133899964052574,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 144000,\n",
       "  'agent_timesteps_total': 144000,\n",
       "  'timers': {'learn_time_ms': 1.43, 'learn_throughput': 69942.369},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.237029,\n",
       "     'max_q': -4.069939,\n",
       "     'min_q': -21.895802,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 144000,\n",
       "   'num_agent_steps_sampled': 144000,\n",
       "   'num_steps_trained': 14250100,\n",
       "   'num_agent_steps_trained': 14250100,\n",
       "   'last_target_update_ts': 144000,\n",
       "   'num_target_updates': 142501},\n",
       "  'done': False,\n",
       "  'episodes_total': 1425,\n",
       "  'training_iteration': 96,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-23-00',\n",
       "  'timestamp': 1625502180,\n",
       "  'time_this_iter_s': 20.895400762557983,\n",
       "  'time_total_s': 1922.288185119629,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1922.288185119629,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 96,\n",
       "  'perf': {'cpu_util_percent': 12.481481481481481,\n",
       "   'ram_util_percent': 49.02592592592592,\n",
       "   'gpu_util_percent0': 0.10925925925925926,\n",
       "   'vram_util_percent0': 0.46959667414793976}},\n",
       " {'episode_reward_max': -37.26297785457169,\n",
       "  'episode_reward_min': -105.43012626398507,\n",
       "  'episode_reward_mean': -67.21557749495331,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-66.8804829502741,\n",
       "    -72.50507945555879,\n",
       "    -99.19663684033787,\n",
       "    -84.68309213651733,\n",
       "    -65.32604180911085,\n",
       "    -67.71026887156025,\n",
       "    -62.158831394804984,\n",
       "    -65.45006236000623,\n",
       "    -68.98710186272389,\n",
       "    -42.95662405279316,\n",
       "    -77.70167712735545,\n",
       "    -50.094527439623334,\n",
       "    -71.17160469813541,\n",
       "    -68.39457478577283,\n",
       "    -65.7181604498476,\n",
       "    -72.34883792641396,\n",
       "    -58.082324444511634,\n",
       "    -64.11864736696673,\n",
       "    -66.78008028527726,\n",
       "    -68.56965016487212,\n",
       "    -67.10102223516017,\n",
       "    -66.65682640251903,\n",
       "    -67.87626636452353,\n",
       "    -62.87547018580804,\n",
       "    -75.59651594770818,\n",
       "    -67.66771724467624,\n",
       "    -62.07655811892277,\n",
       "    -68.02884287625731,\n",
       "    -56.81950486321733,\n",
       "    -70.82758405064298,\n",
       "    -68.8300953710209,\n",
       "    -66.32934740355135,\n",
       "    -73.81472444810191,\n",
       "    -64.45427348786903,\n",
       "    -67.1244021174828,\n",
       "    -64.22294869743547,\n",
       "    -67.19425533524833,\n",
       "    -65.26871357908263,\n",
       "    -66.80925357123846,\n",
       "    -76.5389582872134,\n",
       "    -69.53315553149045,\n",
       "    -59.19015629941167,\n",
       "    -67.83908092742982,\n",
       "    -85.89685285350107,\n",
       "    -72.34513777824918,\n",
       "    -72.71320626635777,\n",
       "    -69.23450231942785,\n",
       "    -62.310842765751175,\n",
       "    -93.20710848776974,\n",
       "    -58.95634173815677,\n",
       "    -46.0082361303177,\n",
       "    -74.20071751093421,\n",
       "    -68.84320743858859,\n",
       "    -69.95413036059932,\n",
       "    -63.99906869019352,\n",
       "    -68.78947822740632,\n",
       "    -79.11870739500677,\n",
       "    -65.230471304254,\n",
       "    -65.1290970617845,\n",
       "    -72.29081783444398,\n",
       "    -70.36924673267713,\n",
       "    -67.02815321978645,\n",
       "    -63.07790765840881,\n",
       "    -66.13947403204122,\n",
       "    -69.27822890087539,\n",
       "    -70.383473560302,\n",
       "    -42.110770465654625,\n",
       "    -67.9640902641894,\n",
       "    -68.0792869698613,\n",
       "    -87.86246348655735,\n",
       "    -71.3907574259973,\n",
       "    -56.95453630430934,\n",
       "    -44.17055455886252,\n",
       "    -69.88934512030842,\n",
       "    -68.80273895322918,\n",
       "    -77.27559330246012,\n",
       "    -69.89246829252644,\n",
       "    -61.74832782413638,\n",
       "    -66.80304548254752,\n",
       "    -73.77718266011003,\n",
       "    -76.5347124556839,\n",
       "    -71.69120235439318,\n",
       "    -48.88566552570263,\n",
       "    -37.26297785457169,\n",
       "    -63.420016470547495,\n",
       "    -63.99329464175443,\n",
       "    -70.72019078713072,\n",
       "    -67.92948308801242,\n",
       "    -63.40530836741573,\n",
       "    -65.17902804119228,\n",
       "    -40.74775676047822,\n",
       "    -105.43012626398507,\n",
       "    -59.941640757364674,\n",
       "    -62.494020313336165,\n",
       "    -64.99380662726749,\n",
       "    -68.29409697063605,\n",
       "    -53.13212786840404,\n",
       "    -67.53089707786381,\n",
       "    -83.3357942605605,\n",
       "    -63.90005386297097],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22036426554016514,\n",
       "   'mean_inference_ms': 0.5832617411484334,\n",
       "   'mean_action_processing_ms': 0.07596173763823888,\n",
       "   'mean_env_wait_ms': 1.1342217018466918,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 145500,\n",
       "  'agent_timesteps_total': 145500,\n",
       "  'timers': {'learn_time_ms': 1.421, 'learn_throughput': 70360.062},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.151445,\n",
       "     'max_q': -3.4563003,\n",
       "     'min_q': -22.477585,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 145500,\n",
       "   'num_agent_steps_sampled': 145500,\n",
       "   'num_steps_trained': 14400100,\n",
       "   'num_agent_steps_trained': 14400100,\n",
       "   'last_target_update_ts': 145500,\n",
       "   'num_target_updates': 144001},\n",
       "  'done': False,\n",
       "  'episodes_total': 1440,\n",
       "  'training_iteration': 97,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-23-21',\n",
       "  'timestamp': 1625502201,\n",
       "  'time_this_iter_s': 21.121066331863403,\n",
       "  'time_total_s': 1943.4092514514923,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1943.4092514514923,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 97,\n",
       "  'perf': {'cpu_util_percent': 12.444444444444446,\n",
       "   'ram_util_percent': 49.099999999999994,\n",
       "   'gpu_util_percent0': 0.10851851851851853,\n",
       "   'vram_util_percent0': 0.4694640946239002}},\n",
       " {'episode_reward_max': -37.26297785457169,\n",
       "  'episode_reward_min': -105.43012626398507,\n",
       "  'episode_reward_mean': -67.21106372485411,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-72.34883792641396,\n",
       "    -58.082324444511634,\n",
       "    -64.11864736696673,\n",
       "    -66.78008028527726,\n",
       "    -68.56965016487212,\n",
       "    -67.10102223516017,\n",
       "    -66.65682640251903,\n",
       "    -67.87626636452353,\n",
       "    -62.87547018580804,\n",
       "    -75.59651594770818,\n",
       "    -67.66771724467624,\n",
       "    -62.07655811892277,\n",
       "    -68.02884287625731,\n",
       "    -56.81950486321733,\n",
       "    -70.82758405064298,\n",
       "    -68.8300953710209,\n",
       "    -66.32934740355135,\n",
       "    -73.81472444810191,\n",
       "    -64.45427348786903,\n",
       "    -67.1244021174828,\n",
       "    -64.22294869743547,\n",
       "    -67.19425533524833,\n",
       "    -65.26871357908263,\n",
       "    -66.80925357123846,\n",
       "    -76.5389582872134,\n",
       "    -69.53315553149045,\n",
       "    -59.19015629941167,\n",
       "    -67.83908092742982,\n",
       "    -85.89685285350107,\n",
       "    -72.34513777824918,\n",
       "    -72.71320626635777,\n",
       "    -69.23450231942785,\n",
       "    -62.310842765751175,\n",
       "    -93.20710848776974,\n",
       "    -58.95634173815677,\n",
       "    -46.0082361303177,\n",
       "    -74.20071751093421,\n",
       "    -68.84320743858859,\n",
       "    -69.95413036059932,\n",
       "    -63.99906869019352,\n",
       "    -68.78947822740632,\n",
       "    -79.11870739500677,\n",
       "    -65.230471304254,\n",
       "    -65.1290970617845,\n",
       "    -72.29081783444398,\n",
       "    -70.36924673267713,\n",
       "    -67.02815321978645,\n",
       "    -63.07790765840881,\n",
       "    -66.13947403204122,\n",
       "    -69.27822890087539,\n",
       "    -70.383473560302,\n",
       "    -42.110770465654625,\n",
       "    -67.9640902641894,\n",
       "    -68.0792869698613,\n",
       "    -87.86246348655735,\n",
       "    -71.3907574259973,\n",
       "    -56.95453630430934,\n",
       "    -44.17055455886252,\n",
       "    -69.88934512030842,\n",
       "    -68.80273895322918,\n",
       "    -77.27559330246012,\n",
       "    -69.89246829252644,\n",
       "    -61.74832782413638,\n",
       "    -66.80304548254752,\n",
       "    -73.77718266011003,\n",
       "    -76.5347124556839,\n",
       "    -71.69120235439318,\n",
       "    -48.88566552570263,\n",
       "    -37.26297785457169,\n",
       "    -63.420016470547495,\n",
       "    -63.99329464175443,\n",
       "    -70.72019078713072,\n",
       "    -67.92948308801242,\n",
       "    -63.40530836741573,\n",
       "    -65.17902804119228,\n",
       "    -40.74775676047822,\n",
       "    -105.43012626398507,\n",
       "    -59.941640757364674,\n",
       "    -62.494020313336165,\n",
       "    -64.99380662726749,\n",
       "    -68.29409697063605,\n",
       "    -53.13212786840404,\n",
       "    -67.53089707786381,\n",
       "    -83.3357942605605,\n",
       "    -63.90005386297097,\n",
       "    -71.88924177263394,\n",
       "    -61.37540983861882,\n",
       "    -77.15989381808124,\n",
       "    -41.741221021582724,\n",
       "    -59.11314198185806,\n",
       "    -84.43402617266231,\n",
       "    -75.20650786379649,\n",
       "    -77.41489796056413,\n",
       "    -78.09866275633593,\n",
       "    -81.05519769441588,\n",
       "    -55.573846833061175,\n",
       "    -68.42218489585213,\n",
       "    -64.20455993770389,\n",
       "    -67.44097309571349,\n",
       "    -65.35362358162288],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22033806869402742,\n",
       "   'mean_inference_ms': 0.5836985481418833,\n",
       "   'mean_action_processing_ms': 0.07595746965906498,\n",
       "   'mean_env_wait_ms': 1.1345442211475965,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 147000,\n",
       "  'agent_timesteps_total': 147000,\n",
       "  'timers': {'learn_time_ms': 1.464, 'learn_throughput': 68293.344},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.868596,\n",
       "     'max_q': -5.4307747,\n",
       "     'min_q': -22.92005,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 147000,\n",
       "   'num_agent_steps_sampled': 147000,\n",
       "   'num_steps_trained': 14550100,\n",
       "   'num_agent_steps_trained': 14550100,\n",
       "   'last_target_update_ts': 147000,\n",
       "   'num_target_updates': 145501},\n",
       "  'done': False,\n",
       "  'episodes_total': 1455,\n",
       "  'training_iteration': 98,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-23-42',\n",
       "  'timestamp': 1625502222,\n",
       "  'time_this_iter_s': 20.960411310195923,\n",
       "  'time_total_s': 1964.3696627616882,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1964.3696627616882,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 98,\n",
       "  'perf': {'cpu_util_percent': 12.58148148148148,\n",
       "   'ram_util_percent': 49.12962962962964,\n",
       "   'gpu_util_percent0': 0.10962962962962963,\n",
       "   'vram_util_percent0': 0.4699944127200585}},\n",
       " {'episode_reward_max': -37.26297785457169,\n",
       "  'episode_reward_min': -105.43012626398507,\n",
       "  'episode_reward_mean': -67.45571553922416,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-68.8300953710209,\n",
       "    -66.32934740355135,\n",
       "    -73.81472444810191,\n",
       "    -64.45427348786903,\n",
       "    -67.1244021174828,\n",
       "    -64.22294869743547,\n",
       "    -67.19425533524833,\n",
       "    -65.26871357908263,\n",
       "    -66.80925357123846,\n",
       "    -76.5389582872134,\n",
       "    -69.53315553149045,\n",
       "    -59.19015629941167,\n",
       "    -67.83908092742982,\n",
       "    -85.89685285350107,\n",
       "    -72.34513777824918,\n",
       "    -72.71320626635777,\n",
       "    -69.23450231942785,\n",
       "    -62.310842765751175,\n",
       "    -93.20710848776974,\n",
       "    -58.95634173815677,\n",
       "    -46.0082361303177,\n",
       "    -74.20071751093421,\n",
       "    -68.84320743858859,\n",
       "    -69.95413036059932,\n",
       "    -63.99906869019352,\n",
       "    -68.78947822740632,\n",
       "    -79.11870739500677,\n",
       "    -65.230471304254,\n",
       "    -65.1290970617845,\n",
       "    -72.29081783444398,\n",
       "    -70.36924673267713,\n",
       "    -67.02815321978645,\n",
       "    -63.07790765840881,\n",
       "    -66.13947403204122,\n",
       "    -69.27822890087539,\n",
       "    -70.383473560302,\n",
       "    -42.110770465654625,\n",
       "    -67.9640902641894,\n",
       "    -68.0792869698613,\n",
       "    -87.86246348655735,\n",
       "    -71.3907574259973,\n",
       "    -56.95453630430934,\n",
       "    -44.17055455886252,\n",
       "    -69.88934512030842,\n",
       "    -68.80273895322918,\n",
       "    -77.27559330246012,\n",
       "    -69.89246829252644,\n",
       "    -61.74832782413638,\n",
       "    -66.80304548254752,\n",
       "    -73.77718266011003,\n",
       "    -76.5347124556839,\n",
       "    -71.69120235439318,\n",
       "    -48.88566552570263,\n",
       "    -37.26297785457169,\n",
       "    -63.420016470547495,\n",
       "    -63.99329464175443,\n",
       "    -70.72019078713072,\n",
       "    -67.92948308801242,\n",
       "    -63.40530836741573,\n",
       "    -65.17902804119228,\n",
       "    -40.74775676047822,\n",
       "    -105.43012626398507,\n",
       "    -59.941640757364674,\n",
       "    -62.494020313336165,\n",
       "    -64.99380662726749,\n",
       "    -68.29409697063605,\n",
       "    -53.13212786840404,\n",
       "    -67.53089707786381,\n",
       "    -83.3357942605605,\n",
       "    -63.90005386297097,\n",
       "    -71.88924177263394,\n",
       "    -61.37540983861882,\n",
       "    -77.15989381808124,\n",
       "    -41.741221021582724,\n",
       "    -59.11314198185806,\n",
       "    -84.43402617266231,\n",
       "    -75.20650786379649,\n",
       "    -77.41489796056413,\n",
       "    -78.09866275633593,\n",
       "    -81.05519769441588,\n",
       "    -55.573846833061175,\n",
       "    -68.42218489585213,\n",
       "    -64.20455993770389,\n",
       "    -67.44097309571349,\n",
       "    -65.35362358162288,\n",
       "    -65.54917791060288,\n",
       "    -62.69616770774414,\n",
       "    -67.43668623537023,\n",
       "    -54.765777949851554,\n",
       "    -67.07045753588459,\n",
       "    -88.42246607689343,\n",
       "    -67.21408205616143,\n",
       "    -65.76198760896095,\n",
       "    -57.60183295647716,\n",
       "    -44.074143568744994,\n",
       "    -69.66624276411719,\n",
       "    -87.29129489184496,\n",
       "    -63.01502198906115,\n",
       "    -65.70254706209086,\n",
       "    -93.62314360067515],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22031159673145248,\n",
       "   'mean_inference_ms': 0.5840845841462058,\n",
       "   'mean_action_processing_ms': 0.07595423802992818,\n",
       "   'mean_env_wait_ms': 1.134703248577513,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 148500,\n",
       "  'agent_timesteps_total': 148500,\n",
       "  'timers': {'learn_time_ms': 1.439, 'learn_throughput': 69483.533},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.613736,\n",
       "     'max_q': -6.3058844,\n",
       "     'min_q': -22.602053,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 148500,\n",
       "   'num_agent_steps_sampled': 148500,\n",
       "   'num_steps_trained': 14700100,\n",
       "   'num_agent_steps_trained': 14700100,\n",
       "   'last_target_update_ts': 148500,\n",
       "   'num_target_updates': 147001},\n",
       "  'done': False,\n",
       "  'episodes_total': 1470,\n",
       "  'training_iteration': 99,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-24-03',\n",
       "  'timestamp': 1625502243,\n",
       "  'time_this_iter_s': 20.790117025375366,\n",
       "  'time_total_s': 1985.1597797870636,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 1985.1597797870636,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 99,\n",
       "  'perf': {'cpu_util_percent': 12.7,\n",
       "   'ram_util_percent': 49.20000000000001,\n",
       "   'gpu_util_percent0': 0.11333333333333331,\n",
       "   'vram_util_percent0': 0.4699754727880528}},\n",
       " {'episode_reward_max': -36.26854829711897,\n",
       "  'episode_reward_min': -105.43012626398507,\n",
       "  'episode_reward_mean': -66.82994369253254,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 15,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-72.71320626635777,\n",
       "    -69.23450231942785,\n",
       "    -62.310842765751175,\n",
       "    -93.20710848776974,\n",
       "    -58.95634173815677,\n",
       "    -46.0082361303177,\n",
       "    -74.20071751093421,\n",
       "    -68.84320743858859,\n",
       "    -69.95413036059932,\n",
       "    -63.99906869019352,\n",
       "    -68.78947822740632,\n",
       "    -79.11870739500677,\n",
       "    -65.230471304254,\n",
       "    -65.1290970617845,\n",
       "    -72.29081783444398,\n",
       "    -70.36924673267713,\n",
       "    -67.02815321978645,\n",
       "    -63.07790765840881,\n",
       "    -66.13947403204122,\n",
       "    -69.27822890087539,\n",
       "    -70.383473560302,\n",
       "    -42.110770465654625,\n",
       "    -67.9640902641894,\n",
       "    -68.0792869698613,\n",
       "    -87.86246348655735,\n",
       "    -71.3907574259973,\n",
       "    -56.95453630430934,\n",
       "    -44.17055455886252,\n",
       "    -69.88934512030842,\n",
       "    -68.80273895322918,\n",
       "    -77.27559330246012,\n",
       "    -69.89246829252644,\n",
       "    -61.74832782413638,\n",
       "    -66.80304548254752,\n",
       "    -73.77718266011003,\n",
       "    -76.5347124556839,\n",
       "    -71.69120235439318,\n",
       "    -48.88566552570263,\n",
       "    -37.26297785457169,\n",
       "    -63.420016470547495,\n",
       "    -63.99329464175443,\n",
       "    -70.72019078713072,\n",
       "    -67.92948308801242,\n",
       "    -63.40530836741573,\n",
       "    -65.17902804119228,\n",
       "    -40.74775676047822,\n",
       "    -105.43012626398507,\n",
       "    -59.941640757364674,\n",
       "    -62.494020313336165,\n",
       "    -64.99380662726749,\n",
       "    -68.29409697063605,\n",
       "    -53.13212786840404,\n",
       "    -67.53089707786381,\n",
       "    -83.3357942605605,\n",
       "    -63.90005386297097,\n",
       "    -71.88924177263394,\n",
       "    -61.37540983861882,\n",
       "    -77.15989381808124,\n",
       "    -41.741221021582724,\n",
       "    -59.11314198185806,\n",
       "    -84.43402617266231,\n",
       "    -75.20650786379649,\n",
       "    -77.41489796056413,\n",
       "    -78.09866275633593,\n",
       "    -81.05519769441588,\n",
       "    -55.573846833061175,\n",
       "    -68.42218489585213,\n",
       "    -64.20455993770389,\n",
       "    -67.44097309571349,\n",
       "    -65.35362358162288,\n",
       "    -65.54917791060288,\n",
       "    -62.69616770774414,\n",
       "    -67.43668623537023,\n",
       "    -54.765777949851554,\n",
       "    -67.07045753588459,\n",
       "    -88.42246607689343,\n",
       "    -67.21408205616143,\n",
       "    -65.76198760896095,\n",
       "    -57.60183295647716,\n",
       "    -44.074143568744994,\n",
       "    -69.66624276411719,\n",
       "    -87.29129489184496,\n",
       "    -63.01502198906115,\n",
       "    -65.70254706209086,\n",
       "    -93.62314360067515,\n",
       "    -70.05034016538241,\n",
       "    -75.92657935168762,\n",
       "    -70.15252862917978,\n",
       "    -69.31363159949822,\n",
       "    -71.69733588562359,\n",
       "    -68.55913701535745,\n",
       "    -36.26854829711897,\n",
       "    -38.888631448802954,\n",
       "    -89.49666113320072,\n",
       "    -44.608680069669155,\n",
       "    -65.79918944599973,\n",
       "    -60.80127642084834,\n",
       "    -63.70049543850993,\n",
       "    -82.49226875380704,\n",
       "    -65.05886736447982],\n",
       "   'episode_lengths': [101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101,\n",
       "    101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.22028249599231697,\n",
       "   'mean_inference_ms': 0.5844995236523616,\n",
       "   'mean_action_processing_ms': 0.07594985780262875,\n",
       "   'mean_env_wait_ms': 1.1346122809156614,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 0,\n",
       "  'timesteps_total': 150000,\n",
       "  'agent_timesteps_total': 150000,\n",
       "  'timers': {'learn_time_ms': 1.409, 'learn_throughput': 70993.636},\n",
       "  'info': {'learner': {'default_policy': {'mean_q': -13.53396,\n",
       "     'max_q': -2.4798307,\n",
       "     'min_q': -23.509975,\n",
       "     'model': {}}},\n",
       "   'num_steps_sampled': 150000,\n",
       "   'num_agent_steps_sampled': 150000,\n",
       "   'num_steps_trained': 14850100,\n",
       "   'num_agent_steps_trained': 14850100,\n",
       "   'last_target_update_ts': 150000,\n",
       "   'num_target_updates': 148501},\n",
       "  'done': False,\n",
       "  'episodes_total': 1485,\n",
       "  'training_iteration': 100,\n",
       "  'experiment_id': '16fc43087ecc4e118a677299f6ec5a79',\n",
       "  'date': '2021-07-05_18-24-23',\n",
       "  'timestamp': 1625502263,\n",
       "  'time_this_iter_s': 20.492512702941895,\n",
       "  'time_total_s': 2005.6522924900055,\n",
       "  'pid': 86170,\n",
       "  'hostname': 'Yan-ThinkBook',\n",
       "  'node_ip': '128.179.140.160',\n",
       "  'config': {'num_workers': 0,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 1,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'train_batch_size': 100,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': True,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'GyroscopeEnv-v1',\n",
       "   'env_config': {'simu_args': {'dt': 0.05, 'ep_len': 100, 'seed': 2},\n",
       "    'reward_func': 'Quadratic',\n",
       "    'reward_args': {'qx1': 1,\n",
       "     'qx2': 0,\n",
       "     'qx3': 1,\n",
       "     'qx4': 0,\n",
       "     'pu1': 0,\n",
       "     'pu2': 0}},\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 0.01,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'tf',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'OrnsteinUhlenbeckNoise',\n",
       "    'random_timesteps': 1000,\n",
       "    'ou_base_scale': 0.1,\n",
       "    'ou_theta': 0.15,\n",
       "    'ou_sigma': 0.2,\n",
       "    'initial_scale': 1.0,\n",
       "    'final_scale': 1.0,\n",
       "    'scale_timesteps': 10000},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 100,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 1,\n",
       "   'timesteps_per_iteration': 1500,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'simple_optimizer': True,\n",
       "   'monitor': -1,\n",
       "   'twin_q': False,\n",
       "   'policy_delay': 1,\n",
       "   'smooth_target_policy': False,\n",
       "   'target_noise': 0.1,\n",
       "   'target_noise_clip': 0.5,\n",
       "   'use_state_preprocessor': False,\n",
       "   'actor_hiddens': [128, 32],\n",
       "   'actor_hidden_activation': 'relu',\n",
       "   'critic_hiddens': [128, 32],\n",
       "   'critic_hidden_activation': 'relu',\n",
       "   'n_step': 1,\n",
       "   'buffer_size': 1000000,\n",
       "   'prioritized_replay': True,\n",
       "   'prioritized_replay_alpha': 0.6,\n",
       "   'prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       "   'final_prioritized_replay_beta': 0.4,\n",
       "   'prioritized_replay_eps': 1e-06,\n",
       "   'training_intensity': None,\n",
       "   'critic_lr': 0.0025,\n",
       "   'actor_lr': 0.0025,\n",
       "   'target_network_update_freq': 0,\n",
       "   'tau': 0.002,\n",
       "   'use_huber': False,\n",
       "   'huber_threshold': 1.0,\n",
       "   'l2_reg': 1e-06,\n",
       "   'grad_clip': None,\n",
       "   'learning_starts': 1500,\n",
       "   'worker_side_prioritization': False},\n",
       "  'time_since_restore': 2005.6522924900055,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 100,\n",
       "  'perf': {'cpu_util_percent': 12.642307692307694,\n",
       "   'ram_util_percent': 49.223076923076924,\n",
       "   'gpu_util_percent0': 0.09807692307692309,\n",
       "   'vram_util_percent0': 0.46952382825561034}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dab14587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4c1abb5668>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = result[\"hist_stats\"]\n",
    "b = a[\"episode_reward\"]\n",
    "\n",
    "plt.plot(b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa72b360",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n': 0,\n",
       "  'episode_reward_min': -104.15944801994365,\n",
       "  'episode_reward_mean': -74.16342953198993,\n",
       "  'episode_reward_max': -44.29764357780588,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 1,\n",
       "  'episode_reward_min': -121.16195954708573,\n",
       "  'episode_reward_mean': -71.8574517549739,\n",
       "  'episode_reward_max': -36.293007601338914,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 2,\n",
       "  'episode_reward_min': -121.16195954708573,\n",
       "  'episode_reward_mean': -69.1280269839091,\n",
       "  'episode_reward_max': -36.293007601338914,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 3,\n",
       "  'episode_reward_min': -121.16195954708573,\n",
       "  'episode_reward_mean': -69.01784228820527,\n",
       "  'episode_reward_max': -36.293007601338914,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 4,\n",
       "  'episode_reward_min': -121.16195954708573,\n",
       "  'episode_reward_mean': -69.00023566118287,\n",
       "  'episode_reward_max': -36.293007601338914,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 5,\n",
       "  'episode_reward_min': -121.16195954708573,\n",
       "  'episode_reward_mean': -68.40649928614187,\n",
       "  'episode_reward_max': -36.293007601338914,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 6,\n",
       "  'episode_reward_min': -121.16195954708573,\n",
       "  'episode_reward_mean': -68.14296795662415,\n",
       "  'episode_reward_max': -33.27495644827692,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 7,\n",
       "  'episode_reward_min': -121.16195954708573,\n",
       "  'episode_reward_mean': -67.06346811174328,\n",
       "  'episode_reward_max': -33.27495644827692,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 8,\n",
       "  'episode_reward_min': -106.42380385613262,\n",
       "  'episode_reward_mean': -67.69651563092536,\n",
       "  'episode_reward_max': -33.27495644827692,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 9,\n",
       "  'episode_reward_min': -106.42380385613262,\n",
       "  'episode_reward_mean': -68.29438668069183,\n",
       "  'episode_reward_max': -33.27495644827692,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 10,\n",
       "  'episode_reward_min': -106.42380385613262,\n",
       "  'episode_reward_mean': -67.51251905994411,\n",
       "  'episode_reward_max': -33.27495644827692,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 11,\n",
       "  'episode_reward_min': -118.76138410679755,\n",
       "  'episode_reward_mean': -67.75484556157036,\n",
       "  'episode_reward_max': -33.27495644827692,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 12,\n",
       "  'episode_reward_min': -118.76138410679755,\n",
       "  'episode_reward_mean': -68.4256972561449,\n",
       "  'episode_reward_max': -33.27495644827692,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 13,\n",
       "  'episode_reward_min': -118.76138410679755,\n",
       "  'episode_reward_mean': -69.39779398027741,\n",
       "  'episode_reward_max': -34.549179634175566,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 14,\n",
       "  'episode_reward_min': -118.76138410679755,\n",
       "  'episode_reward_mean': -68.11766933623122,\n",
       "  'episode_reward_max': -34.549179634175566,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 15,\n",
       "  'episode_reward_min': -118.76138410679755,\n",
       "  'episode_reward_mean': -67.72816474275787,\n",
       "  'episode_reward_max': -35.66860863643257,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 16,\n",
       "  'episode_reward_min': -118.76138410679755,\n",
       "  'episode_reward_mean': -67.78768614164807,\n",
       "  'episode_reward_max': -35.66860863643257,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 17,\n",
       "  'episode_reward_min': -116.19519670871938,\n",
       "  'episode_reward_mean': -67.93204786969395,\n",
       "  'episode_reward_max': -35.66860863643257,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 18,\n",
       "  'episode_reward_min': -116.19519670871938,\n",
       "  'episode_reward_mean': -68.5220582361839,\n",
       "  'episode_reward_max': -37.91465152547477,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 19,\n",
       "  'episode_reward_min': -116.19519670871938,\n",
       "  'episode_reward_mean': -67.78607873276506,\n",
       "  'episode_reward_max': -37.91465152547477,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 20,\n",
       "  'episode_reward_min': -116.19519670871938,\n",
       "  'episode_reward_mean': -68.30671152544224,\n",
       "  'episode_reward_max': -37.91465152547477,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 21,\n",
       "  'episode_reward_min': -116.19519670871938,\n",
       "  'episode_reward_mean': -68.61772951369343,\n",
       "  'episode_reward_max': -37.91465152547477,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 22,\n",
       "  'episode_reward_min': -116.19519670871938,\n",
       "  'episode_reward_mean': -69.22126478682567,\n",
       "  'episode_reward_max': -37.91465152547477,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 23,\n",
       "  'episode_reward_min': -116.19519670871938,\n",
       "  'episode_reward_mean': -68.76919486010914,\n",
       "  'episode_reward_max': -37.91465152547477,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 24,\n",
       "  'episode_reward_min': -110.56071007622492,\n",
       "  'episode_reward_mean': -69.08409990590623,\n",
       "  'episode_reward_max': -38.483153025240355,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 25,\n",
       "  'episode_reward_min': -110.56071007622492,\n",
       "  'episode_reward_mean': -68.47154028525219,\n",
       "  'episode_reward_max': -37.6925120278722,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 26,\n",
       "  'episode_reward_min': -110.56071007622492,\n",
       "  'episode_reward_mean': -68.40457850452079,\n",
       "  'episode_reward_max': -36.672992186962155,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 27,\n",
       "  'episode_reward_min': -110.56071007622492,\n",
       "  'episode_reward_mean': -67.67033351748711,\n",
       "  'episode_reward_max': -36.672992186962155,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 28,\n",
       "  'episode_reward_min': -110.56071007622492,\n",
       "  'episode_reward_mean': -68.04295288474168,\n",
       "  'episode_reward_max': -36.672992186962155,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 29,\n",
       "  'episode_reward_min': -107.99519027940168,\n",
       "  'episode_reward_mean': -67.1523240195088,\n",
       "  'episode_reward_max': -36.672992186962155,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 30,\n",
       "  'episode_reward_min': -107.99519027940168,\n",
       "  'episode_reward_mean': -68.01986239773129,\n",
       "  'episode_reward_max': -33.39665900047392,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 31,\n",
       "  'episode_reward_min': -107.99519027940168,\n",
       "  'episode_reward_mean': -68.11381844059099,\n",
       "  'episode_reward_max': -33.39665900047392,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 32,\n",
       "  'episode_reward_min': -106.2743953763872,\n",
       "  'episode_reward_mean': -67.35976136028644,\n",
       "  'episode_reward_max': -33.39665900047392,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 33,\n",
       "  'episode_reward_min': -106.2743953763872,\n",
       "  'episode_reward_mean': -67.65793280698644,\n",
       "  'episode_reward_max': -33.39665900047392,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 34,\n",
       "  'episode_reward_min': -106.2743953763872,\n",
       "  'episode_reward_mean': -67.72633779518912,\n",
       "  'episode_reward_max': -33.39665900047392,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 35,\n",
       "  'episode_reward_min': -106.2743953763872,\n",
       "  'episode_reward_mean': -67.33452964782171,\n",
       "  'episode_reward_max': -33.39665900047392,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 36,\n",
       "  'episode_reward_min': -106.2743953763872,\n",
       "  'episode_reward_mean': -66.89319806605202,\n",
       "  'episode_reward_max': -33.39665900047392,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 37,\n",
       "  'episode_reward_min': -97.13563454212671,\n",
       "  'episode_reward_mean': -65.93536056065074,\n",
       "  'episode_reward_max': -35.18365072171996,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 38,\n",
       "  'episode_reward_min': -88.92140680896807,\n",
       "  'episode_reward_mean': -66.22494586877399,\n",
       "  'episode_reward_max': -37.747639697115204,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 39,\n",
       "  'episode_reward_min': -88.92140680896807,\n",
       "  'episode_reward_mean': -67.31819644475742,\n",
       "  'episode_reward_max': -37.747639697115204,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 40,\n",
       "  'episode_reward_min': -88.92140680896807,\n",
       "  'episode_reward_mean': -67.17156906544234,\n",
       "  'episode_reward_max': -37.747639697115204,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 41,\n",
       "  'episode_reward_min': -88.92140680896807,\n",
       "  'episode_reward_mean': -66.53269850865007,\n",
       "  'episode_reward_max': -34.11397507377022,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 42,\n",
       "  'episode_reward_min': -88.92140680896807,\n",
       "  'episode_reward_mean': -66.65564622171145,\n",
       "  'episode_reward_max': -34.11397507377022,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 43,\n",
       "  'episode_reward_min': -109.8198102691455,\n",
       "  'episode_reward_mean': -66.27437607944127,\n",
       "  'episode_reward_max': -34.11397507377022,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 44,\n",
       "  'episode_reward_min': -126.84991304492816,\n",
       "  'episode_reward_mean': -66.50540548552024,\n",
       "  'episode_reward_max': -30.15886793138822,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 45,\n",
       "  'episode_reward_min': -126.84991304492816,\n",
       "  'episode_reward_mean': -66.87663799326073,\n",
       "  'episode_reward_max': -30.15886793138822,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 46,\n",
       "  'episode_reward_min': -126.84991304492816,\n",
       "  'episode_reward_mean': -66.30909083829165,\n",
       "  'episode_reward_max': -30.15886793138822,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 47,\n",
       "  'episode_reward_min': -126.84991304492816,\n",
       "  'episode_reward_mean': -66.18153252839987,\n",
       "  'episode_reward_max': -30.15886793138822,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 48,\n",
       "  'episode_reward_min': -126.84991304492816,\n",
       "  'episode_reward_mean': -67.25308358653338,\n",
       "  'episode_reward_max': -30.15886793138822,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 49,\n",
       "  'episode_reward_min': -126.84991304492816,\n",
       "  'episode_reward_mean': -67.28657854377961,\n",
       "  'episode_reward_max': -30.15886793138822,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 50,\n",
       "  'episode_reward_min': -126.84991304492816,\n",
       "  'episode_reward_mean': -67.55038761337698,\n",
       "  'episode_reward_max': -30.15886793138822,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 51,\n",
       "  'episode_reward_min': -113.19121790305353,\n",
       "  'episode_reward_mean': -67.6759085644249,\n",
       "  'episode_reward_max': -33.11370969328171,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 52,\n",
       "  'episode_reward_min': -113.19121790305353,\n",
       "  'episode_reward_mean': -67.55989107794845,\n",
       "  'episode_reward_max': -33.11370969328171,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 53,\n",
       "  'episode_reward_min': -113.19121790305353,\n",
       "  'episode_reward_mean': -67.91546109955308,\n",
       "  'episode_reward_max': -36.54636489706553,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 54,\n",
       "  'episode_reward_min': -113.19121790305353,\n",
       "  'episode_reward_mean': -67.81825003306048,\n",
       "  'episode_reward_max': -36.54636489706553,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 55,\n",
       "  'episode_reward_min': -116.1494655720994,\n",
       "  'episode_reward_mean': -68.47934023851444,\n",
       "  'episode_reward_max': -36.54636489706553,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 56,\n",
       "  'episode_reward_min': -116.1494655720994,\n",
       "  'episode_reward_mean': -68.4845923655641,\n",
       "  'episode_reward_max': -36.54636489706553,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 57,\n",
       "  'episode_reward_min': -117.14890305530149,\n",
       "  'episode_reward_mean': -68.42070196108686,\n",
       "  'episode_reward_max': -37.84637615904659,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 58,\n",
       "  'episode_reward_min': -117.14890305530149,\n",
       "  'episode_reward_mean': -69.02810669950021,\n",
       "  'episode_reward_max': -40.3743439790754,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 59,\n",
       "  'episode_reward_min': -117.14890305530149,\n",
       "  'episode_reward_mean': -68.82312454763854,\n",
       "  'episode_reward_max': -38.11275716816903,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 60,\n",
       "  'episode_reward_min': -117.14890305530149,\n",
       "  'episode_reward_mean': -68.10991385523522,\n",
       "  'episode_reward_max': -35.06967786924983,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 61,\n",
       "  'episode_reward_min': -117.14890305530149,\n",
       "  'episode_reward_mean': -67.4017752412056,\n",
       "  'episode_reward_max': -35.06967786924983,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 62,\n",
       "  'episode_reward_min': -117.14890305530149,\n",
       "  'episode_reward_mean': -66.43691146788098,\n",
       "  'episode_reward_max': -35.06967786924983,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 63,\n",
       "  'episode_reward_min': -116.8125856203505,\n",
       "  'episode_reward_mean': -67.52476609368598,\n",
       "  'episode_reward_max': -35.06967786924983,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 64,\n",
       "  'episode_reward_min': -115.75136708347257,\n",
       "  'episode_reward_mean': -66.41170620722721,\n",
       "  'episode_reward_max': -35.06967786924983,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 65,\n",
       "  'episode_reward_min': -115.75136708347257,\n",
       "  'episode_reward_mean': -66.17297421545148,\n",
       "  'episode_reward_max': -35.06967786924983,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 66,\n",
       "  'episode_reward_min': -115.75136708347257,\n",
       "  'episode_reward_mean': -66.18264925204232,\n",
       "  'episode_reward_max': -35.06967786924983,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 67,\n",
       "  'episode_reward_min': -115.75136708347257,\n",
       "  'episode_reward_mean': -66.20081334465952,\n",
       "  'episode_reward_max': -35.57419946966036,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 68,\n",
       "  'episode_reward_min': -115.75136708347257,\n",
       "  'episode_reward_mean': -68.31411288448375,\n",
       "  'episode_reward_max': -35.57419946966036,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 69,\n",
       "  'episode_reward_min': -115.75136708347257,\n",
       "  'episode_reward_mean': -68.67444575818342,\n",
       "  'episode_reward_max': -36.80115849134961,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 70,\n",
       "  'episode_reward_min': -115.49399314044751,\n",
       "  'episode_reward_mean': -68.02177719465114,\n",
       "  'episode_reward_max': -36.80115849134961,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 71,\n",
       "  'episode_reward_min': -115.49399314044751,\n",
       "  'episode_reward_mean': -68.79005845925289,\n",
       "  'episode_reward_max': -39.46167826740754,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 72,\n",
       "  'episode_reward_min': -115.49399314044751,\n",
       "  'episode_reward_mean': -68.72588283895358,\n",
       "  'episode_reward_max': -39.46167826740754,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 73,\n",
       "  'episode_reward_min': -115.49399314044751,\n",
       "  'episode_reward_mean': -68.4519968260521,\n",
       "  'episode_reward_max': -36.60685447487495,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 74,\n",
       "  'episode_reward_min': -115.49399314044751,\n",
       "  'episode_reward_mean': -67.94878640398272,\n",
       "  'episode_reward_max': -36.05246982909452,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 75,\n",
       "  'episode_reward_min': -115.49399314044751,\n",
       "  'episode_reward_mean': -66.68231937592068,\n",
       "  'episode_reward_max': -36.05246982909452,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 76,\n",
       "  'episode_reward_min': -100.16427179250041,\n",
       "  'episode_reward_mean': -66.00416215985636,\n",
       "  'episode_reward_max': -36.05246982909452,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 77,\n",
       "  'episode_reward_min': -92.58865257580194,\n",
       "  'episode_reward_mean': -66.14954896127449,\n",
       "  'episode_reward_max': -36.05246982909452,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 78,\n",
       "  'episode_reward_min': -92.58865257580194,\n",
       "  'episode_reward_mean': -65.99813894333442,\n",
       "  'episode_reward_max': -36.05246982909452,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 79,\n",
       "  'episode_reward_min': -86.55496556376747,\n",
       "  'episode_reward_mean': -65.82012541305664,\n",
       "  'episode_reward_max': -36.05246982909452,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 80,\n",
       "  'episode_reward_min': -86.55496556376747,\n",
       "  'episode_reward_mean': -65.68452881089556,\n",
       "  'episode_reward_max': -36.05246982909452,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 81,\n",
       "  'episode_reward_min': -95.73088590442056,\n",
       "  'episode_reward_mean': -66.02039538171567,\n",
       "  'episode_reward_max': -38.23809391260414,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 82,\n",
       "  'episode_reward_min': -95.73088590442056,\n",
       "  'episode_reward_mean': -66.38359638643153,\n",
       "  'episode_reward_max': -38.23809391260414,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 83,\n",
       "  'episode_reward_min': -95.73088590442056,\n",
       "  'episode_reward_mean': -66.75726655268407,\n",
       "  'episode_reward_max': -38.23809391260414,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 84,\n",
       "  'episode_reward_min': -95.73088590442056,\n",
       "  'episode_reward_mean': -66.11387674269318,\n",
       "  'episode_reward_max': -38.23809391260414,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 85,\n",
       "  'episode_reward_min': -102.75119362415712,\n",
       "  'episode_reward_mean': -66.33332917448328,\n",
       "  'episode_reward_max': -38.23809391260414,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 86,\n",
       "  'episode_reward_min': -102.75119362415712,\n",
       "  'episode_reward_mean': -66.38780655270926,\n",
       "  'episode_reward_max': -38.23809391260414,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 87,\n",
       "  'episode_reward_min': -102.75119362415712,\n",
       "  'episode_reward_mean': -67.05147097187556,\n",
       "  'episode_reward_max': -39.94036466254375,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 88,\n",
       "  'episode_reward_min': -102.75119362415712,\n",
       "  'episode_reward_mean': -67.1348519434274,\n",
       "  'episode_reward_max': -39.94036466254375,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 89,\n",
       "  'episode_reward_min': -102.75119362415712,\n",
       "  'episode_reward_mean': -66.4533730261464,\n",
       "  'episode_reward_max': -39.871897933038454,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 90,\n",
       "  'episode_reward_min': -102.75119362415712,\n",
       "  'episode_reward_mean': -67.39165164173797,\n",
       "  'episode_reward_max': -39.871897933038454,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 91,\n",
       "  'episode_reward_min': -99.86887333410559,\n",
       "  'episode_reward_mean': -67.14845121527296,\n",
       "  'episode_reward_max': -39.871897933038454,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 92,\n",
       "  'episode_reward_min': -99.86887333410559,\n",
       "  'episode_reward_mean': -67.12313906921139,\n",
       "  'episode_reward_max': -39.871897933038454,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 93,\n",
       "  'episode_reward_min': -99.19663684033787,\n",
       "  'episode_reward_mean': -67.09336421929649,\n",
       "  'episode_reward_max': -39.871897933038454,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 94,\n",
       "  'episode_reward_min': -99.19663684033787,\n",
       "  'episode_reward_mean': -67.75722867524519,\n",
       "  'episode_reward_max': -39.871897933038454,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 95,\n",
       "  'episode_reward_min': -99.19663684033787,\n",
       "  'episode_reward_mean': -67.47146026172402,\n",
       "  'episode_reward_max': -37.26297785457169,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 96,\n",
       "  'episode_reward_min': -105.43012626398507,\n",
       "  'episode_reward_mean': -67.21557749495331,\n",
       "  'episode_reward_max': -37.26297785457169,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 97,\n",
       "  'episode_reward_min': -105.43012626398507,\n",
       "  'episode_reward_mean': -67.21106372485411,\n",
       "  'episode_reward_max': -37.26297785457169,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 98,\n",
       "  'episode_reward_min': -105.43012626398507,\n",
       "  'episode_reward_mean': -67.45571553922416,\n",
       "  'episode_reward_max': -37.26297785457169,\n",
       "  'episode_len_mean': 101.0},\n",
       " {'n': 99,\n",
       "  'episode_reward_min': -105.43012626398507,\n",
       "  'episode_reward_mean': -66.82994369253254,\n",
       "  'episode_reward_max': -36.26854829711897,\n",
       "  'episode_len_mean': 101.0}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6531d20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 1,\n",
       " 'episode_reward_min': -121.16195954708573,\n",
       " 'episode_reward_mean': -71.8574517549739,\n",
       " 'episode_reward_max': -36.293007601338914,\n",
       " 'episode_len_mean': 101.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0788b253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-74.16342953198993,\n",
       " -71.8574517549739,\n",
       " -69.1280269839091,\n",
       " -69.01784228820527,\n",
       " -69.00023566118287,\n",
       " -68.40649928614187,\n",
       " -68.14296795662415,\n",
       " -67.06346811174328,\n",
       " -67.69651563092536,\n",
       " -68.29438668069183,\n",
       " -67.51251905994411,\n",
       " -67.75484556157036,\n",
       " -68.4256972561449,\n",
       " -69.39779398027741,\n",
       " -68.11766933623122,\n",
       " -67.72816474275787,\n",
       " -67.78768614164807,\n",
       " -67.93204786969395,\n",
       " -68.5220582361839,\n",
       " -67.78607873276506,\n",
       " -68.30671152544224,\n",
       " -68.61772951369343,\n",
       " -69.22126478682567,\n",
       " -68.76919486010914,\n",
       " -69.08409990590623,\n",
       " -68.47154028525219,\n",
       " -68.40457850452079,\n",
       " -67.67033351748711,\n",
       " -68.04295288474168,\n",
       " -67.1523240195088,\n",
       " -68.01986239773129,\n",
       " -68.11381844059099,\n",
       " -67.35976136028644,\n",
       " -67.65793280698644,\n",
       " -67.72633779518912,\n",
       " -67.33452964782171,\n",
       " -66.89319806605202,\n",
       " -65.93536056065074,\n",
       " -66.22494586877399,\n",
       " -67.31819644475742,\n",
       " -67.17156906544234,\n",
       " -66.53269850865007,\n",
       " -66.65564622171145,\n",
       " -66.27437607944127,\n",
       " -66.50540548552024,\n",
       " -66.87663799326073,\n",
       " -66.30909083829165,\n",
       " -66.18153252839987,\n",
       " -67.25308358653338,\n",
       " -67.28657854377961,\n",
       " -67.55038761337698,\n",
       " -67.6759085644249,\n",
       " -67.55989107794845,\n",
       " -67.91546109955308,\n",
       " -67.81825003306048,\n",
       " -68.47934023851444,\n",
       " -68.4845923655641,\n",
       " -68.42070196108686,\n",
       " -69.02810669950021,\n",
       " -68.82312454763854,\n",
       " -68.10991385523522,\n",
       " -67.4017752412056,\n",
       " -66.43691146788098,\n",
       " -67.52476609368598,\n",
       " -66.41170620722721,\n",
       " -66.17297421545148,\n",
       " -66.18264925204232,\n",
       " -66.20081334465952,\n",
       " -68.31411288448375,\n",
       " -68.67444575818342,\n",
       " -68.02177719465114,\n",
       " -68.79005845925289,\n",
       " -68.72588283895358,\n",
       " -68.4519968260521,\n",
       " -67.94878640398272,\n",
       " -66.68231937592068,\n",
       " -66.00416215985636,\n",
       " -66.14954896127449,\n",
       " -65.99813894333442,\n",
       " -65.82012541305664,\n",
       " -65.68452881089556,\n",
       " -66.02039538171567,\n",
       " -66.38359638643153,\n",
       " -66.75726655268407,\n",
       " -66.11387674269318,\n",
       " -66.33332917448328,\n",
       " -66.38780655270926,\n",
       " -67.05147097187556,\n",
       " -67.1348519434274,\n",
       " -66.4533730261464,\n",
       " -67.39165164173797,\n",
       " -67.14845121527296,\n",
       " -67.12313906921139,\n",
       " -67.09336421929649,\n",
       " -67.75722867524519,\n",
       " -67.47146026172402,\n",
       " -67.21557749495331,\n",
       " -67.21106372485411,\n",
       " -67.45571553922416,\n",
       " -66.82994369253254]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aacd0eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4c1ab05438>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rewards_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd358e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ede9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aebef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae5f5f69",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c0350f55cc70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# init_state = np.array([0,0,0,0,45/180*np.pi,-60/180*np.pi,200/60*2*np.pi])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0magent_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ddpg_q_i0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ddpg_q_i001'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ddpg_q_i01'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ddpg_q_i1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_env' is not defined"
     ]
    }
   ],
   "source": [
    "# Test paramaters\n",
    "env_name = \"GyroscopeEnv-v1\"\n",
    "\n",
    "# init_state = np.array([0,0,0,0,45/180*np.pi,-60/180*np.pi,200/60*2*np.pi])\n",
    "env = create_env(env_name,state=None)\n",
    "\n",
    "agent_paths = ['ddpg_q_i0','ddpg_q_i001','ddpg_q_i01','ddpg_q_i1']\n",
    "\n",
    "agent.restore(checkpoint_path)\n",
    "\n",
    "agent = load_agent(agent_paths[0])\n",
    "t_end = 10\n",
    "\n",
    "score, state_record, obs_record, action_record, reward_record = test_agent(env,agent,t_end)\n",
    "plot_test(state_record, action_record, t_end, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c74ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda64737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d3e732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

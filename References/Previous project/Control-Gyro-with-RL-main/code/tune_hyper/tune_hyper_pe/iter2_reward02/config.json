{
    "ac_kwargs":	{
        "activation":	"ReLU",
        "hidden_sizes":	[
            128,
            32
        ]
    },
    "act_noise":	0.1,
    "actor_critic":	"MLPActorCritic",
    "batch_size":	100,
    "env_fn":	"functools.partial(<function env_fn at 0x2b4e8ab738c8>, 'GyroscopeEnv-v1', simu_args={'dt': 0.05, 'ep_len': 100, 'seed': 2}, reward_func='PE', reward_args={'qx1': 1, 'qx2': 0.25, 'qx3': 1, 'qx4': 0.25, 'pu1': 0.1, 'pu2': 0.1, 'p': 0.1, 'e': 40})",
    "epochs":	2000,
    "exp_name":	"iter2_reward02",
    "gamma":	0.95,
    "logger":	{
        "<spinup.utils.logx.EpochLogger object at 0x2b4df9a441d0>":	{
            "epoch_dict":	{},
            "exp_name":	"iter2_reward02",
            "first_row":	true,
            "log_current_row":	{},
            "log_headers":	[],
            "output_dir":	"iter2_reward02",
            "output_file":	{
                "<_io.TextIOWrapper name='iter2_reward02/progress.txt' mode='w' encoding='UTF-8'>":	{
                    "mode":	"w"
                }
            }
        }
    },
    "logger_kwargs":	{
        "exp_name":	"iter2_reward02",
        "output_dir":	"iter2_reward02"
    },
    "max_ep_len":	100,
    "num_test_episodes":	10,
    "pi_lr":	0.002,
    "polyak":	0.999,
    "q_lr":	0.002,
    "replay_size":	8000000,
    "save_freq":	1,
    "seed":	0,
    "start_steps":	15000,
    "steps_per_epoch":	1500,
    "update_after":	1000,
    "update_every":	50
}